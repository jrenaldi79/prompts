{
  "name": "InterviewGrader",
  "nodes": [
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "1c200e8c-422f-4afa-a81b-5b2dbb2a9b27",
              "name": "laddering_technique",
              "value": "=<laddering_technique>\nWhat is the Laddering Technique?\nLaddering is a technique used in qualitative research to understand the link between product attributes in a brand, the advantages it offers to the consumer, and finally, the end emotional benefits derived from these advantages. Laddering is a point of view and method of asking questions that drive deeper into the user’s thinking.\n\n“Laddering and probing are used to understand the way in which the informant sees the world.” (Reynolds & Gutman, 1988)\n\nWhy is laddering important for a Designer/Researcher to understand?\nThe ways our users see the world are essential to understand and key for Designers to understand deeply. If a Designer doesn’t understand their users, they rapidly run the risk of making foolish or even dangerous assumptions.\n\nHow does laddering work?\nLaddering is a qualitative questioning process that attempts to draw out more connective tissue between 4 factors.\n\nAn illustration digram of the laddering technique. A drawing of a ladder with rungs showing Attributes (concrete/abstrate), Consequences (psychosocial/functional), Affordances (Hidden, Perceptual, false), and Values.\nLaddering Technique\nAttributes\nThey are factors or “properties” of a product or system that are recognizable.\nTwo types of attributes:\n• Concrete Attributes: A tangible product feature. e.g., Appearance, Brand, Affordance, or Flavor.\n• Abstract Attributes: The perception of an idea. e.g., Simple, Modern, User-friendly, or Tasty.\nConsequences\nThey are feedback loops to attributes and elicit an emotional or physical response in users.\nTwo types of consequences:\n• Psychosocial Consequences: Emotional benefits achieved from experiences with a product or system. e.g., I feel secure, or I trust the truthfulness of the content, etc.\n• Functional Consequences: Real-time benefits achieved from an experience with a product or system. e.g., Password is obfuscated, The content includes a date, time, and source link, etc.\nAffordances\nAn affordance is what a user can do with an object based on the user’s capabilities. The concept is from Donald Norman’s book Design of Everyday Things. Affordances are the combination of attributes and consequences and are linked with the concept of form-follows-function. e.g., A coffee mug has a handle, a dropdown has an arrow, etc.\nThree types of technology affordances: (source: William Gaver 1977)\n• Perceptible: Perceptual characteristics of the object itself indicate what action possibilities are available and desired — e.g., a door handle. These obvious properties prompt users to use the affordance in an intended way.\n• Hidden: In user interfaces without obvious affordances, users often must rely on experience and/or trial and error to determine possible actions — e.g., they hover/click on suspected drop-down menus, or swipe a screen to see if there are more images, etc.\n• False: An object’s characteristics suggest users can do something they can’t — e.g., underlined text that isn’t a link, or a save button for autosave actions, etc.\nValues\nAttributes lead to consequences and inform affordances which ramp up into values that are held by a person. Values are a state of mind that users are attempting to achieve in action and through experience e.g., Independence, dignity, gratitude, etc.\nBy driving qualitative interviews through the laddering technique, and asking questions that move from attributes into user values, Designers can seek clarity of the why. The more we seek “the why” the more confidence we can have that our solutions are aligned with our user’s values. If you do not understand how your products align with your user’s values, then you will have a harder time reaching any viable solutions. You will not be good at this technique the first time you try it so… Practice, practice, practice!\n\nA qualitative laddering sample\nFor example, let’s assume we work at Sherwin-William Paints, and we’re trying to understand why people choose our paint. We have recruited people who have purchased our product in the past.\n\n- Q: Why did you purchase our interior paint instead of other options?\n\n- A: The website said they are less toxic than other options (attribute)\n\n- Q: Interesting. Why do you like them because they are less toxic?\n\n- A: I am sensitive to fumes and have small children, which is important to consider. (functional consequence)\n\n- Q: Why are low fumes important to you?\n\n- A: I worry about exposing my 2-year-old as our place is old and probably has lead paint which is why we needed to paint in the first place. (functional consequence)\n\n- Q: How does having lead paint and small kids impact your paint decisions?\n\n- A: Well, They take priority! I need to protect them as much as I can but we need to paint his room before he starts licking the walls. (psychological consequence)\n\n- Q: So your paint choices are about your kids environment?\n\n- A: It is important for me to improve their environment to keep them safe as well as add some color to their rooms. (core value)\n\nNot every interview will lead to a core value this quickly, but hopefully, you get the point of how this drives up the ladder. With laddering in mind, it is easier to pick up on attributes, consequences, affordance and, ultimately, get to someone’s core value behind their actions or thoughts.\n</laddering_technique>",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        660,
        0
      ],
      "id": "3c7af8c3-7ab0-4bac-a4fd-d4ab770b7b50",
      "name": "Load Laddering Technique"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "abbfdbcc-ed88-445c-a769-d329f2182ccb",
              "name": "interviewing_users",
              "value": "=<interviewing_users>\n# HOW TO USE THIS BOOK\n\n# Who Should Read This Book?\n\nThis book is for everyone who talks to customers in order to do a better job of making something for them. With this book’s guidance, you’ll be able to gather more accurate and more finely nuanced information, whether you’re a designer who brings insights into the design process, an engineer wanting to connect with how “real people” do their work, a strategist seeking a better way of identifying new opportunities, or a marketer who knows the value of data. Even if you’ve never formally gone out to your users in order to inform your work, this book will guide you in the process of planning and executing a successful user research study. This book provides some very detailed best practices for studying people, and it encourages you to reflect on your own points of view. And if you just like to ask questions, there’s plenty of information here for you, too!\n\n# What’s in This Book?\n\nChapter 1, “The Importance of Interviewing in Design,” sets the stage, looking at why you learn about users and how interviewing compares with other methods.\n\nChapter 2, “A Framework for Interviewing,” defines an approach—a way of being—for interviewing. All the tactical best practices emerge from this framework.\n\nChapter 3, “Getting Ready to Conduct Your Interviews,” describes the steps to prepare for a user research study, from identifying the problem to finding participants and preparing your questions.\n\nChapter 4, “More Than Just Asking Questions,” introduces a range of methods that can enhance your interviews, including artifacts you prepare and take with you, activities you ask participants to engage in, or materials you develop together with them.\n\nChapter 5, “Key Stages of the Interview,” describes how to manage the roles of the team in the field, as well as the different stages that most interviews go through and how to prepare for and respond to those stages.\n\nChapter 6, “How to Ask Questions,” gets into the details of asking questions, with positive and negative examples that illustrate how simple word choices can make a big difference.\n---\n# Chapter 7, “Documenting the Interview,”\n\nreviews how to capture all the data from interviews, the limitations (and unique strengths) of taking notes, and the necessity of a proper recording.\n\n# Chapter 8, “Optimizing the Interview,”\n\nlooks at common variations, typical breakdowns, and how to improve as an interviewer.\n\n# Chapter 9, “Making an Impact with Your Research,”\n\naddresses what happens next: what you do with all that data and how to take the results back to the rest of the organization.\n\n# What Comes with This Book?\n\nThis book’s companion website (rosenfeldmedia.com/books/user-interviews/) contains a blog, sample documents, related articles, interviews, and presentations. The book’s diagrams and other illustrations are available under a Creative Commons license (when possible) for you to download and include in your own presentations. You can find these on Flickr at www.flickr.com/photos/rosenfeldmedia/sets/.\n\nHow to Use This Book\n---\n# FREQUENTLY ASKED QUESTIONS\n\n# Why is this even a book? Isn’t this really just talking to people? I already know how to do that!\n\nTo learn something new requires interviewing, not just chatting. Poor interviews produce inaccurate information that can take your business in the wrong direction. Interviewing is a skill that at times can be fundamentally different than what you do normally in conversation. Great interviewers leverage their natural style of interacting with people but make deliberate, specific choices about what to say, when to say it, how to say it, and when to say nothing. Doing this well is hard and takes years of practice. Chapter 6 is devoted entirely to techniques for asking questions.\n\n# Why would we bother to talk to our users?\n\nWe use our products every single day and know exactly what we need to build. People who make a product think and talk about it fundamentally differently than people who don’t. While both groups may use the same product, their context—understanding, language, expectations, and so on—is completely different. From a user’s point of view, a Big Mac eaten in Moscow is hardly the same product as a Big Mac eaten in San Jose, CA. And neither one is very much like a Big Mac eaten at McDonald’s Hamburger University in Oak Grove, IL. A strong product vision is important, but understanding what that vision means when it leaves your bubble is make-or-break stuff. In Chapter 1, I examine the impact that interviewing has on project teams.\n\n# We don’t have time in our development process to interview our users, so what should we do?\n\nDeveloping insights about users doesn’t always have to be a milestone in a product development process. Insights can be an organizational asset that is assembled quarterly (or whenever) to feed into all aspects of product development, marketing, and so on. Once a baseline is established, subsequent research can enhance and expand that body of knowledge. Within time constraints, I’m constantly impressed by people I meet who are so hungry to bring user information into their work that they find ways to do whatever they can. In Chapter 9, I discuss the trade-offs when time is the constraining resource.\n---\n# Which team members should interview users?\n\nWhile more design organizations are staffing a research role, the designated researchers aren’t the only ones who go out and meet customers. I’ve seen many times that as companies buy in to the value of research insights, the researchers shift from struggling for acceptance to being overwhelmed by demand. It’s not unusual to see them scaling up their own teams, working with outside partners, and training their colleagues to be better researchers themselves. Ultimately, who shouldn’t be interviewing users? There will always be a range of strengths in interviewing skills; leading research is a specialized function, but user research is something that everyone can and should participate in. In most cases, this will exclude functions unrelated to key aspects of the business, but given the cultural value of understanding the customer, everyone could be involved in consuming the results of interviewing users, even if they aren’t directly speaking to those users themselves. In Chapter 5, I look at how to manage a team composed of seasoned interviewers and less-savvy colleagues.\n\n# We interviewed users and didn’t learn anything new. How does that happen?\n\nSometimes it’s perfectly appropriate to validate hypotheses or to confirm the findings from previous research. But often when stakeholders report they didn’t hear anything new, that’s a symptom of something else. Were stakeholders fully involved in planning the research? Did the researchers develop a rich understanding of what these stakeholders already believed and what burning questions they had? Not hearing anything new may be a result of not digging into the research data enough to pull out more nuanced insights. Finally, if customers are still expressing the same needs they’ve expressed before, it begs the question, “Why haven’t you done something about that?” In Chapter 3, I discuss working with stakeholders to establish project objectives.\n\n\n---\n# INTRODUCTION\n\nI had my first experience in user research more than 30 years ago, going on-site to classrooms and homes to see if people of various ages could tell the difference— blindfolded—between different colors of Smarties candy (a candy from Canada, where I grew up, that is similar to M&M’s but with a broader color palette). It turned out that the youngest people, with their taste buds least affected by age, could tell instantly.1\n\nAs a tween, the initial impact of this science fair project was only on my snacking behavior. Implications for my career arc did not surface until many years later when I found myself in Silicon Valley with a fresh master’s degree in HCI. This was an awkward point for me: I had no design portfolio. I hadn’t conducted any usability tests. I hadn’t created any interfaces. I had no design process. I had no awareness of how software (or any other product or service) was produced. All I had was a nascent point-of-view about people and technology. I was very lucky to end up working in an industrial design firm that was experimenting with actually talking to users, whether to validate design ideas or to work at the “fuzzy front-end” where innovation could take place, “left of the idea.”\n\nEven as the company was exploring how to do this sort of work, I was invited to apprentice in the emergent practice. At first, I was allowed to review videos but wasn’t sent out on interviews. Then I was sent into the field but only to hold the camera and observe. Then I was allowed to ask just one or two questions at the end. And so it went. After a while, I was leading interviews myself, training other staff, and even lecturing to students and clients.\n\nWhile it’s tempting for me to be nostalgic about that time period as one that had a special focus on learning, I don’t think anything has changed for me. Nowadays, I travel widely to interview users and to teach others how to interview users. In the past few weeks, I’ve led a number of training workshops and interviewed a bunch of fascinating people. (I called home from the field to report that, once again, “This is the most interesting project I’ve ever worked on!”) Maybe it’s my researcher nature, but having fresh stories from the field to share in the workshops and having refined thoughts about how to interview to take with me into the field is pretty damn wonderful.\n\nMy best wish for you is that learning about how you learn about users will fuel your own passions in some similar measure.\n\n—Steve Portigal, March 6, 2013, Montara, California\n\n1 You can read the entire research report at www.portigal.com/Reports/AreYouASmartie_Portigal.pdf.\n---\nNO_CONTENT_HERE\n---\n# CHAPTER 1\n\n# The Importance of Interviewing in Design\n\n# User Insight in the Design Process\n\n3\n\n# When to Use Interviewing\n\n7\n\n# To Interview Well, One Must Study\n\n9\n\n# The Impact of Interviewing\n\n10\n\n# Summary\n\n11\n---\nThis is a great time for the design researcher. Within user-experience design, service design, and to a lesser extent, industrial design, user research has gone from being an outsider activity, to being tolerated, to being the norm. Across industry events, conferences, online forums, school curricula, and professional practice, there’s a tacit agreement that designing for the user is the preferred way to think about design. As with any generalization, there are exceptions. Maybe you aren’t feeling the love right now, but you probably can agree that things are much better than they were in the past. To design for users, you must begin with a deep understanding of users. If you don’t already have that understanding, you need to do some form of user research.\n\n# TIP\n\nYOU ARE NOT YOUR USER\n\nYou may be a user, but be careful of being seduced into designing for yourself. Jared Spool calls that “self design” and identifies the benefits and risks at www.uie.com/brainsparks/2010/07/22/uietips-self-design/. I think he’s too easy on self design. Lots of niche companies make the snowboards, outdoor equipment, and mixing gear that they, as enthusiasts, would want. But some have trouble expanding their offering in an innovative way, because they are so caught up in being the user.\n\n# NOTE\n\nGAINING INSIGHT VS. PERSUADING THE ORGANIZATION\n\nWhile doing ethnographic research in Japan, I sat with my clients while they conducted another study. They brought users into a facility and showed them the most elegantly designed forms for printer ink cartridges. They were smooth, teardrop shapes that were shiny and coated with the color of the ink. They also showed users the existing ink cartridges: black rectangles with text-heavy stickers.\n\nCan you guess what the research revealed? Of course. People loved the new designs, exclaiming enthusiastically and caressing them. Regardless of methodology, there was no insight to be gained here. I’ve gone back and forth about whether this was good research or bad research. It didn’t reveal new information, but it provided tangible evidence to persuade someone else in the organization. This team’s approach suggests that there are other issues with their design process, and while their research might have been the best solution in that situation, ideally this isn’t the best use of a research study.\n\n# Chapter 1\n---\n# User Insight in the Design Process\n\nAlthough there isn’t a clear alignment about how much time and effort to invest and what approach to use, at least we, as user researchers, share a common goal: to gather information about users in order to support the organization when creating products, services, and more.\n\nWhat I’m calling interviewing is also referred to by other names: user research, site visits, contextual research, design research, and ethnography, to name a few. Regardless of nomenclature, these are the key steps in the process:\n\n- Deeply studying people, ideally in their context\n- Exploring not only their behaviors but also the meaning behind those behaviors\n- Making sense of the data using inference, interpretation, analysis, and synthesis\n- Using those insights to point toward a design, service, product, or other solution\n\nWe go to visit our users (in their homes, their offices, their cars, their parks, and so on) most of the time, but not always. When planning a project, we ask ourselves if it’s more insightful to bring participants in to see our stuff (say, prototypes we’ve set up in a facility meeting room) than it is for us to go out and see their stuff. Overall, our objective is to learn something profoundly new. There are points in the design process where quickly obtained, if shallow, information is beneficial, but that’s not what we’re focusing on here.\n\nNOTE IS THIS ETHNOGRAPHY?\n\nIf you are interviewing users, are you doing ethnography? I don’t know. What I do know is that if you refer to your use of interviewing of people as ethnography, someone will inevitably tell you that no, you aren’t doing ethnography (you are doing contextual inquiry, or site visits, or in-depth interviews, and so on). The term ethnography seems to be particularly contentious for some folks, but...whatever! That’s really their problem, isn’t it? I’d rather we move on from definition wars and focus on what it is I’m getting at when I say interviewing—which means conducting contextual research and analyzing it to reveal a deep understanding of people that informs design and business problems.\n\n# The Importance of Interviewing in Design\n---\nOf course, there are varying perspectives on any “best practice.” Everyone from Henry Ford to Sony to 37 Signals has offered up their reasons not to incorporate direct customer input into the development process. The sub-text of those claims is that people in those organizations possess an innate talent for building stuff that people love. Yet some companies that publicly make those claims have hired me to interview their users. The insights that come from studying users not only inform design but also inspire it. Across organizations, different design cultures have more or less of an appetite for inspiration or information, although in my experience it’s hard to interview users without taking away a hearty dose of both.\n\nSometimes, the stated goal of interviewing users is to uncover their pain points (often known as needs). Embedded in this mindset is the mistaken notion that research with users is a sort of scooping activity, where if you take the effort to leave your office and enter some environment where users congregate, you’ll be headed home with a heap of fresh needs. People need an X and Y, so all the designer has to do is include X and Y in their product and all will be good. What? No one really thinks that, do they? Well, take a look at Figure 1.1.\n\nMicrosoft’s ad campaign for Windows 7 implies an unlikely approach to research, design, and product development. The customer asks for some feature—in this case, for the OS to use less memory. Microsoft, seemingly unaware of the need—or opportunity—to optimize the memory footprint, smacks their corporate forehead as they see the light, sending their engineers scurrying to fulfill this surprising new need.\n\nWithout endlessly debating what Microsoft and their ad agency knew and when they knew it, suffice it to say that this advertisement reinforces this semi-mythical scooping model of user research.\n\nFIGURE 1.1: Microsoft’s ad for Windows 7 suggests that their approach to innovation comes from fulfilling user requests.\n\n# 4 Chapter 1\n---\nI’m calling it a semi-mythical model because this is exactly what some teams do. Although it may be better than nothing, the fact is that a lot of important information gets left behind. Insights don’t simply leap out at you. You need to work hard and dig for them, which takes planning and deliberation. Further complicating the scooping model is the fact that what the designers and engineers see as “pain points” aren’t necessarily that painful for people.\n\nThe term satisficing, coined by Herbert Simon in 1956 (combining satisfy and suffice), refers to people’s tolerance—if not overall embracing—of “good enough” solutions (see Figure 1.2).\n\nFrankly, I discover satisficing in every research project: the unfiled MP3s sitting on the desktop, ill-fitting food container lids, and tangled, too-short cables connecting products are all “good enough” examples of satisficing. In other words, people find the pain of the problem to be less annoying than the effort to solve it. What you observe as a need may actually be something that your customer is perfectly tolerant of. Would they like all their food in tightly sealed containers? Of course. But are they going to make much effort to accomplish that? Probably not.\n\nBeyond simply gathering data, I believe that interviewing customers is tremendous for driving reframes, which are crucial shifts in perspective that flip an initial problem on its head. These new frameworks (which come from rigorous analysis and synthesis of your data) are critical. They can point the way to significant, previously unrealized possibilities for design and\n\nFIGURE 1.2\nIn my family room, you can see a telephone (with cord askew) stored near the floor on a VHS rack that I also use to store CDs (which don’t fit) and empty CD cases. (Why am I keeping them?) Incidentally, the orange cord goes through the floor to an outdoor sump pump. And why do I even have these nearly-obsolete VHS tapes and CDs?\n\n# The Importance of Interviewing in Design\n---\ninnovation. Even if innovation (whatever you consider that to be) isn’t your goal, these frames also help you understand where (and why) your solutions will likely fail and where they will hopefully succeed. To that end, you can (and should!) interview users at different points in the development process. Here are some situations where interviewing can be valuable:\n\n- As a way to identify new opportunities, before you know what could be designed\n- To refine design hypotheses, when you have some ideas about what will be designed\n- To redesign and relaunch existing products and services, when you have history in the marketplace\n\n# NOTE THE CASE OF THE iPOD PEOPLE\n\nOur company began working with a client after they had completed a quantitative study about where people used iPods. They had a list of top environments (such as Home, Work, In the Car, and so on), and they asked us to uncover the unmet needs that people had in those particular environments. It turned out that the specific within-environment needs people had were just not that big a deal, but what people really struggled with was moving between environments, or moving between contexts: from being alone to being in a social situation, from being stationary to being mobile, and so on. These were the real challenges for people. For example, if you’ve worn one earbud and let the other dangle so you could stay somewhat engaged, you’ve dealt with this particular issue.\n\nSo, we excitedly reported to our client that we had found the “real” problem for them to solve. We were met with uncomfortable silence before they told us that they had committed organizational resources to addressing the problem as it currently stood. In our enthusiasm, we had trouble hearing them, and for a few minutes, the conversation was tense.\n\nFinally, we stated definitively that we had learned some specific things about the environments, and we saw a rich and complex opportunity in this new problem. And that was all it took. We delivered findings about each environment, and then we delved into the harder problem. It turns out that our client was eager to innovate, but they just needed to have their initial brief addressed. It became an important lesson for me: Reframing the problem extends it; it doesn’t replace the original question.\n\n# 6 Chapter 1\n---\n# When to Use Interviewing\n\nThere are numerous ways to gather data about users: usability testing, A/B testing, quantitative surveys, Web analytics, interviewing, focus groups, and so on. For the closest thing to a “Grand Unified Field Theory of User Research,” see these examples by Elizabeth B. N. Sanders (see Figure 1.3) and Steve Mulder (see Figure 1.4). Both do a nice job of creating an organizing structure around the surfeit of research techniques we are blessed with.\n\n# CRITICAL DESIGN\n\n# GENERATIVE DESIGN AND EMOTION\n\n# USER-GEIGTERED DESIGN\n\n# PARTICIPATORY DESIGN\n\n| |QUALITATIVE|(Insights)| | |\n|---|---|---|---|---|\n|Diary/journal studies| | | | |\n|User interviews (contextual inquiry)| |Usability testing| | |\n| | | |Field studies|Participatory design|\n|Focus groups| |Eye tracking| | |\n| |Card sorting| | | |\n\n# GOALS & ATTITUDES\n\n(What people say)\n\n# BEHAVIORS\n\n(What people do)\n\n|Customer support data analysis|Automated usability testing|\n|---|---|\n|(e.g., Vividence; Keynote WebEffective)| |\n\n# QUANTITATIVE\n\n(Validation)\n\n# A/B testing\n\nSTEVE MULDER\n\n# The Importance of Interviewing in Design\n---\n# EXAMPLES OF USER RESEARCH APPROACHES\n\n- Usability testing: Typically done in a controlled environment such as a lab, users interact with a product (or a simulation of a product) and various factors (time to complete a task, error rate, preference for alternate solutions) are measured.\n- A/B testing: Comparing the effectiveness of two different versions of the same design (e.g., advertisement, website landing page) by launching them both under similar circumstances.\n- Quantitative survey: A questionnaire, primarily using closed-ended questions, distributed to a larger sample in order to obtain statistically significant results.\n- Web analytics: Measurement and analysis of various data points obtained from Web servers, tracking cookies, and so on. Aggregated over a large number of users, Web analytics can highlight patterns in navigation, user types, the impact of day and time on usage, and so on.\n- Focus group: A moderated discussion with 4 to 12 participants in a research facility, often used to explore preferences (and the reasons for those preferences) among different solutions.\n- Central location test: In a market research facility, groups of 15 to 50 people watch a demo and complete a survey to measure their grasp of the concept, the appeal of various features, the desirability of the product, and so on.\n\nInterviewing isn’t the right approach for every problem. Because it favors depth over sample size, it’s not a source for statistically significant data. Being semi-structured, each interview will be unique, making it hard to objectively tally data points across the sample. Although we are typically interviewing in context, it’s not fully naturalistic. A tool that intercepts and observes users who visit a website is capturing their actual behavior, but sitting with users and having them show you how they use a website is an artifice.\n\nInterviews are not good at predicting future behavior, especially future purchase intent or uncovering price expectations. Asking those questions in an interview will reveal mental models that exist today, which can be insightful, but won’t necessarily be accurate.\n\nBut interviewing can be used in combination with other techniques. In a note earlier in this chapter, I described how a quantitative study helped focus our contextual interviewing and observations. In other situations, we’ve used an exploratory interviewing study to identify topics for a global quantitative segmentation study. We’ve combined a Central Location Test (where larger groups watched a demo in a single location such as a research).\n---\nfacility and filled out a survey) with in-home interviews simultaneously and used the results of both studies to get a deeper understanding of the potential for the product. It can be valuable to combine a set of approaches and get the advantages of each.\n\nIs interviewing considered to be user research? Is it market research? Is it design research? I can’t answer those questions any better than you can! The answer is: it depends. Whether or not you ally yourself or your methods with any one of those areas, you can still do great work uncovering new meaning and bringing it into the organization to drive improvement and growth. At the end of the day, isn’t that what we care about? I’ll let someone else argue about the overarching definition matrix.\n\n# To Interview Well, One Must Study\n\nMuch of the technique of interviewing is based on one of our earliest developmental skills: asking questions (see Figure 1.5). We all know how to ask questions, but if we asked questions in interviews the way we ask questions in typical interactions, we would fall short. In a conversational setting, we are perhaps striving to talk at least 50 percent of the time, and mostly to talk about ourselves. But interviewing is not a social conversation. Falling back on your social defaults is going to get you into trouble!\n\nFIGURE 1.5\n\nChildhood is marked by frequent, inevitable question-asking.\n\n# The Importance of Interviewing in Design\n---\nInterviewing users involves a special set of skills. It takes work to develop these skills. The fact that it looks like an everyday act can actually make it harder to learn how to conduct a good interview because it’s easy to take false refuge in existing conversational approaches. Developing your interviewing skills is different than developing a technical skill (say, milkshake-machine recalibration) because you would have nothing to fall back on if learning about milkshake machines. With interviewing, you may need to learn how to override something you already know. Think of other professionals who use verbal inquiry to succeed in their work: whether it is police officers interrogating a suspect or a lawyer cross-examining an opposing witness or a reference librarian helping a patron, the verbal exchange is a deliberate, learned specialty that goes beyond what happens in everyday conversation. For you as an interviewer, it’s the same thing.\n\n# The Impact of Interviewing\n\nInterviewing creates a shared experience, often a galvanizing one, for the product development team (which can include researchers, designers, engineers, marketers, product management, and beyond). In addition to the information we learn from people and the inspiration we gain from meeting them, there’s a whole other set of transformations we go through. You might call it empathy—say a more specific understanding of the experience and emotions of the customer—which might even be as simple as seeing “the user” or “the customer” as a real live person in all their glorious complexity. But what happens when people develop empathy for a series of individuals they might meet in interviews? They experience an increase in their overall capacity for empathy.1\n\nThis evolution in how individual team members view themselves, their design work, and the world around them starts to drive shifts in the organizational culture (see Figure 1.6). This capacity for empathy is not sufficient to change a culture, but it is necessary. More tactically, these enlightened folks are better advocates for customers and better champions for the findings and implications of what has been learned in interviews. The wonderful thing about these impacts is that they come for free (or nearly). Being deliberate in your efforts to interview users will pay tremendous dividends for your products, as well as the people who produce it.\n\n1 In http://rfld.me/SzBioQ, William Hamilton Bishop describes a process for interactions between couples that sounds a lot like many of the best practices for judgment-free listening that I’ll outline here. He observes that as his clients go through this process, their overall capacity for empathy increases significantly. If we substitute user interviews for the process Bishop outlines, it’s good evidence that we can expect our own empathy to increase as well.\n---\n# IEAM\n\n# TEY\n\n# E\n\n# M\n\n# HO\n\n# TED\n\n# IAM\n\n# IR\n\n# M\n\n# FIGURE 1.6\n\nTeam experiences that are challenging and out-of-the-ordinary create goodwill and a common sense of purpose.\n\n# Summary\n\nIt’s become increasingly common, perhaps even required, for companies to include user research in their design and development process. Among many different approaches to user research, interviewing (by whatever name you want to call it) is a deep dive into the lives of customers.\n\n- Interviewing can be used in combination with other techniques, such as identifying key themes through interviews and then validating them quantitatively in a subsequent study.\n- At a distance, interviewing looks just like the everyday act of talking to people, but interviewing well is a real skill that takes work to develop.\n- Interviewing can reveal new “frames” or models that flip the problem on its head. These new ways of looking at the problem are crucial to identifying new, innovative opportunities.\n- Interviewing can be used to help identify what could be designed, to help refine hypotheses about a possible solution that is being considered, or to guide the redesign of an existing product that is already in the marketplace.\n- Teams who share the experience of meeting their users are enlightened, aligned, and more empathetic.\n\n# The Importance of Interviewing in Design\n---\n45\n Hps\n---\n# CHAPTER 2\n\n# A Framework for Interviewing\n\n- Check Your Worldview at the Door &nbsp;&nbsp;&nbsp;&nbsp; 14\n- Embrace How Other People See the World &nbsp;&nbsp;&nbsp;&nbsp; 17\n- Building Rapport &nbsp;&nbsp;&nbsp;&nbsp; 20\n- Listening &nbsp;&nbsp;&nbsp;&nbsp; 24\n- Summary &nbsp;&nbsp;&nbsp;&nbsp; 27\n---\nWhen Wayne Gretzky apocryphally explained his hockey success going to be,” he identified a key characteristic of many experts: the underlying framework that drives everything. This platonically idealized Gretzky could have revealed any number of tactics such as his grip, or the way he shifts his weight when he skates. Keith Richards explains his guitar sound, which involves removing the 6th string, tuning to open G, and using a particular fretting pattern, as “five strings, three notes, two fingers, and one asshole.” Even though Keith is explaining the tactics, he’s also revealing something ineffable about where he’s coming from. The higher-level operating principles that drive these experts are compelling and illustrative. Expert researchers also have their own operating principles. In this chapter, I’ll outline mine, and I hope to inspire you to develop your own interviewing framework. As you develop, the process evolves from a toolkit for asking questions into a way of being, and you’ll find that many of the tactical problems to solve in interviewing are simply no-brainers. As George Clinton sang, “Free your mind…and your ass will follow.”\n\n# Check Your Worldview at the Door\n\nI’ve been asked, “What was the most surprising thing you ever learned while doing fieldwork?” I scratch my head over that one because I don’t go out into the field with a very strong point of view. Of course, I’m informed by my own experiences, my suspicions, and what my clients have told me, but I approach the interviews with a sense of what I can only call a bland curiosity.\n\nAs the researcher, it’s my responsibility to find out what’s going on; I’m not invested in a particular outcome. Even more (and this is where the blandness comes from), I’m not fully invested in a specific set of answers. Sure, we’ve got specific things we want to learn—questions we have to answer in order to fulfill our brief. But my hunger to learn from my participant is broad, not specific. I’m curious, but I don’t know yet what I’m curious about. My own expectations are muted, blunted, and distributed. Although I will absolutely find the information I’m tasked with uncovering, I also bring a general curiosity. Now, the people I work with don’t have the luxury of bland curiosity. Whether they are marketers, product managers, engineers, or designers (or even other researchers), they often have their own beliefs about what is going on with people. This makes sense: if there’s enough organizational momentum to convene a research project, someone has been thinking hard about the issues and the opportunities, and has come to a point of view.\n\n1 In fact, it was Walter Gretzky, Wayne’s dad, who said it, as “Go to where the puck is going, not where it has been,” according to Fast Company’s Consultant Debunking Unit. http://rfld.me/Rj6XpR\n\n# Chapter 2\n---\n# The Brain Dump\n\nAt the beginning of the project, convene a brain dump (see Figure 2.1). Get what’s in everyone’s heads out on the table. Whether it’s real-time, face-to-face, in front of a whiteboard, or asynchronously across offices on a wiki, talk through assumptions, expectations, closely-held beliefs, perspectives, and hypotheses. Contradictions are inevitable and should even be encouraged. The point is not establishing consensus; it’s to surface what’s implicit. By saying it aloud and writing it down, the issues leave the group specifically and enter an external, neutral space.\n\nK (2012)\n\nC O T KS C A L LENA B BY O T PHO\n\n# FIGURE 2.1\n\nCapture everything that everyone thinks they know so that it’s not stuck in their heads.\n\nIt’s also not about being right or wrong; I encourage you to anonymize all the input so that people don’t feel sheepish about expressing themselves. I wouldn’t even go back and validate the brain dump against the resulting data. The objective is to shake up what is in your mind and free you to see new things. Think about it as a transitional ritual of unburdening, like men emptying their pockets of keys, change, and wallet as soon as they return home (Figure 2.2).\n\n# A Framework for Interviewing\n\n15\n---\n# FIGURE 2.2\n\nTransitional rituals are actions we take to remind ourselves that we are shifting from one mode of being to another.\n\nTIP WORK IT OUT\nChicago’s DD+D (who bill themselves as “a theater-based design team”) offers a Design Empathy workshop. Using improv and other theater techniques, this workshop “helps designers to check in and acknowledge their own biases and to explore assumptions before going out and doing research.”2\n\n2 Touchpoint, the Service Design Network publication, Volume 4, Issue 2.\n\n# Chapter 2\n---\n# Make the Interview About the Interview\n\nAnother transitional ritual is to make a small declaration to yourself and your fellow fieldworkers in the moments before you begin an interview. If you are outside someone’s apartment or entering their workspace, turn to each other and state what you are there to accomplish. If you were in a movie, you’d probably growl purposefully “Let’s do this thing.” Sadly, fieldwork is not quite that glamorous, so you might want to clarify what you mean by “this thing.” Remember, even if you consider the fieldwork part of a larger corporate initiative to “identify next-gen opportunities for Q3 roadmap,” that’s not where you should be focusing as you start your interview. Set aside the underlying goals for the duration of the session. “This thing” might instead be learning about Paul and how he uses his smartphone or GlobeCorp’s IT department and how they deploy new routers. It’s important to take that moment to tangibly confirm—and affirm—your immediate objective.\n\n# Embrace How Other People See the World\n\nIf you’ve effectively purged yourself of your own worldview, you are now a hollow vessel waiting to be filled with insights. Lovely image, isn’t it? It’s not quite accurate. You need to not only be ready to hear your participant’s take on things, but you should also be hungry for it. This willingness to embrace is an active, deliberate state.\n\n# Go Where the People Are\n\nRather than asking people to come to you to be interviewed, go where they are. In order to embrace their world, you have to be in their world. Inviting them into your realm (and let’s face it, even if a neutral market research facility isn’t technically your realm, that’s how your participants will perceive it) won’t cut it. You’ll benefit by interviewing them in their own environment—this is the environment you are interested in, where the artifacts and behaviors you want to learn about are rooted. By the same token, you’ll also benefit from your own first-hand experience in that environment. The information you learn when going into other people’s worlds is different from what you learn when bringing them into yours.\n\nTo that end, try not to bring your world into theirs. Leave the company-logo clothing (and accessories) at home. Wearing your colors is fine when you’re rooting for the home team or taking your hog to Sturgis, but it has no place in the interviewing room (see Figure 2.3).\n\nA Framework for Interviewing   17\n---\n# ION (2.0)\n\n# Be Ready to Ask Questions for Which You Think You Know the Answer\n\nYou already know how you plan a balanced meal, prepare your taxes, or select an aspect ratio on your HDTV. You may already have an idea about how your participant does those things (because of what you’ve learned about them during the screening process, or implied by something they said earlier in the interview, or assumed by what you’ve seen other people do in the past). However, you need to be open to asking for details anyway. I’ll have more to say in subsequent chapters about asking questions, but for now keep in mind that to embrace their world you need to explore the details of their world. Some people fear that they are being false by asking a question if they think they know the answer. But don’t be so confident with your own presumptions. Interesting tidbits can emerge when you ask these questions, as this hypothetical example suggests:\n\nQuestion: When are your taxes due?\n\nThe answer (which you already know): April 15\n\n18 Chapter 2\n---\nThe response you fear: Why are you asking me this stuff? Everyone knows that it’s April 15. Get out of my house, jerk face!\n\nThe type of answer you are just as likely to get if you swallow your discomfort and ask the question anyway: I always complete everything by March 1. I think it’s April 15 this year, but I never really pay attention to that.\n\nThe goal here is to make it clear to the participant (and to yourself) that they are the expert and you are the novice. This definitely pays off. When I conduct research overseas, people tangibly extend themselves to answer my necessarily naïve questions. Although it’s most apparent in those extreme situations, it applies to all interviews. Respect for their expertise coupled with your own humility serves as a powerful invitation to the participant.\n\n# Nip Distractions in the Bud\n\nTactically, make sure that you are not distracted when you arrive. Take care of your food, drink, and restroom needs in advance. When I meet up with colleagues who are coming to the interview from a different location, we pick an easy location (such as a Starbucks) for a pre-interview briefing. It gives us time to acclimate into interview mode, review the participant’s profile, catch up on what’s been happening in the field to date, and address our personal needs. If your brain is chattering, “Lord, am I famished! When’s lunch?” you are at a disadvantage when it comes to tuning into what’s going on in the interview.\n\nNeedless to say, silence your mobile phone and don’t plan on taking calls or checking texts or emails during the interview. I say “needless,” but I met a team that took a different approach. Sensitive to the commitment their internal clients were making in leaving the office for fieldwork, they allowed mobile device usage during the interview, within limits. Although they were inspired by one colleague who had the stealth-check-below-the-table move down cold, most people weren’t able to handle it quite so deftly. It was a good lesson to learn; they won’t be allowing cell phones in the future. Mind you, even if one were successfully stealthy, that’s beside the point. Figure 2.4 is an evocative depiction of the multitasking potential of technology, but during an interview (and probably during a date), you should be fully engaged with the other person.\n\nA Framework for Interviewing\n---\n# Nokia Nseries\n\n# Figure 2.4\n\nA connection can happen anywhere\n\nJust because you can multitask doesn’t mean you should.\n\n# Building Rapport\n\nI often leave an interview with my head slightly swimming, in a state between energized and exhausted. In addition to all the useful information that will impact the project, I’ve just made an intense connection with a new person. I’ve established a rapport with someone. That’s a powerful feeling, and likely as not, my participant is feeling the same way. Our quotidian transaction to learn about breakfast making has turned into something else. The rapport is what makes for great interviews. You won’t leave every interview walking on a cloud, but getting to that state with your interviewee is something to strive for.\n\nIt’s your job to develop that rapport over the course of the interview. By all means, recruit participants who are articulate, outgoing, and eager to be part of the interview, but remember that creating that connection falls to you, the interviewer. As in life, you’ll meet some people who you’ll connect with easily, and others who you’ll have to work hard for. Some of my best interviews have been with people who are visibly uncomfortable or disinterested at the outset.\n\n# Chapter 2\n---\n# Be Selective About Social Graces\n\nYour participants have no framework for “ethnographic interview,” so they will likely be mapping this experience onto something more familiar like “having company” (when being interviewed at home) or “giving a demo” (when being interviewed about their work). Sometimes when you visit people in their homes, they will offer you a drink. For years, I resisted taking the drink, trying to minimize the inconvenience I was causing. I was well intentioned but naïve; one time I declined a proffered drink and met an ongoing undercurrent of hostility. The drink offer was made again, so I accepted, and suddenly everything thawed. The issue wasn’t my pursuit or denial of refreshment, it was acknowledging my participant’s social expectations—guests should act like guests. This experience took place in the U.S.; in other parts of the world (say, Japan), these rituals are even more inflexible and failure to adhere to them will likely doom the interview. Be sure that you’re aware of the social expectations in the country in which you conduct your interviews.\n\nIn addition to accepting a drink, allow for some small talk as you get settled. But don’t dwell on the chitchat, because your participant may find this confusing.\n\n# Be Selective When Talking About Yourself\n\nYou are bound to hear stories in the field that you strongly identify with, whether it’s someone’s frustration with a broken part of Windows or their passion for Pre-Code Hollywood. Although it’s important to connect with your participant, it’s not the best idea to get there by sharing your common interest. Remember that the interview isn’t about you. If you also love Pre-Code Hollywood, you may think “OMG! Another fellow Pre-Code Hollywood enthusiast!” But you don’t have to say that! Think about when to reveal some-thing about yourself (and when not to). Putting a “me too!” out there changes the dynamic of the interview. It may work to develop some rapport in a difficult situation, or it may imply you are more interested in talking about yourself than listening to the other person. Although this approach might work in social settings, where “see how interesting I am!” is a way we establish our worth in new situations, it can be detrimental in an interview.\n\nYou should definitely talk about yourself if doing so gives the other person permission to share something. As an example, early on in my career I was part of an interview team where my role was to hold the video camera and ask only a few supporting questions. As our participant was telling us about her family and their history, she stopped and looked at both of us and said, “Well, you know, my family is Jewish.” She was hesitant to continue. I piped up, explaining “My family is Jewish as well.” She said to me, “Well, then you understand.” She then turned to my colleague and proceeded to explain the specific details she wanted to convey. I don’t always tell my Jewish interviewees, “Hey, I’m Jewish, too! I have a menorah, too!” but in this case a small revelation gave the interviewee permission to move forward with the interview.\n\n# A Framework for Interviewing\n---\n# Adventures in Rapport Building\n\nAs we rang the doorbell, my colleague and I unconsciously straightened, preparing ourselves for that all-important first impression, that moment when our research participant would come to the door and size us up. We waited for a moment, looking at each other as we heard footsteps, mustering a smile as the inside door opened.\n\n“Hello,” I offered, “Are you Brian?”\n\nAs I began to state the obvious, that we were here for the interview, he grunted, opened the screen door, and as we took hold, he turned around and walked back into the house. We glanced at each other and stepped into the foyer. What did we know about Brian? Our recruiting screener told us he was 22, lived with his parents and brother, and was employed part-time. The rest would be up to us to discover.\n\nIt was 7:30 in the morning, and we were taking our shoes off in a strange house. Eventually, someone beckoned from the kitchen, and we went in. But already we were out of sync. The kitchen was small, with an L-shaped counter and a small table for dining. Brian’s mother was at the end of the L, working with bowls and dishes and burners on the stove. Brian’s father was perched against the counter, while Brian and his younger brother sat at the table. His father was a small man, while the other three were quite large. The room wasn’t big enough for the six of us, so we managed to set up for the interview in the only place we could—at the far end of the counter. We wedged ourselves (one behind the other) on small chairs, pulling our knees in, our paraphernalia of notepads, documents, video cameras, tapes, batteries, and so on clutched in close. It wasn’t ideal, but we hoped we could make it work.\n\nThe real challenge quickly became clear: Although Brian had agreed to be interviewed, he was actively disinterested. We had recruited Brian specifically, but here we were with the entire family. We pressed ahead, explaining our study, and starting in with our planned questions. Since Brian was the person with whom we had the arrangement, we focused our attention on him. He responded with one-word answers (which sounded more like grunts) and the occasional glance at his brother, causing them both to giggle.\n\nMy colleague and I avoided looking at each other (it may not have been physically possible, given the tight quarters) for fear of displaying our despair. Sure, we had arranged this interview, but the cues we were receiving were making it clear the arrangement wasn’t worth much. At this point, we had already awoken quite early to conduct this interview, so there was no point in giving up. If they changed their mind explicitly, they’d let us know, and we’d leave. Meanwhile, what else was there to do but press on? I asked questions with very little response. I tried the brother, at which point Brian bolted out of the room for a few minutes, without a word. The brother was only slightly more amenable than Brian, mostly interested in making critical comments about his parents (to Brian’s great grunting enjoyment), rather than providing any actual information.\n\nIndeed, it appeared that Brian had not informed his parents that we were coming. Although I directed some of the questioning toward his mom, she reacted with pretty serious hostility, informing us (in the context of an answer to a question) that they did not welcome strangers.\n---\ninto their house, and (while she was preparing food) highlighted the intimate nature of food preparation as a symbol, which was even less open to strangers. The message was very clear.\n\nBut again, what could we do? Pressing on until we were specifically asked to leave, under the explicit agreement we had made, seemed the best approach. We asked our questions, following up on the information they had shared, listening closely, looking for clarification, offering up as much space as we could for them to talk, all in trying to build some flow and dialogue.\n\nEven though the message was negative, at least the parents were willing to talk to us. And so the young men faded out of the conversation, and the interview eventually switched over to the parents. Two hours later, it turned out that we had completed an excellent interview with them; they each had great stories about our topic area and revealed a lot of background about their family, about growing up, about their activities, and even their perspectives on what made the United States the country it had become. By not giving up, by ignoring our own discomfort, and by being patient in building rapport, a near-failure turned into a triumph.\n\nIndeed, before we left the house, the mother insisted on cooking up some fried bread, fresh and hot for us. She stated that “No one comes here and doesn’t get food,” thus reiterating the intimate nature of food she had mentioned at the beginning, but this time as a compliment rather than a warning.\n\nAs soon as we left the house, my colleague turned to me and said, “I don’t know how you pulled that off; I thought we were done for and would have to leave.” I was very pleased with how the interview turned out, especially because it began so poorly, but there was little magic to it. I didn’t try to solve the big problem of the complex dynamic we had walked into; I just focused (especially at first) on the next problem—the immediate challenge of what to say next. I was certainly keeping the larger goals in mind of how to cover all the areas we were interested in, but I was focusing my energy as an interviewer on the next point. And by working at it in small pieces, bit by bit, the dynamic shifted. As interviewers, we had to compartmentalize the social experience of the event—the extreme discomfort and awkwardness of the early part of the interview—and stick to our jobs. We didn’t handle the situation that differently than any other interview, and it served as a testament to our approach—listening, following up (and showing that we were listening by the way we followed up), building rapport and trust bit by bit, until there was a great deal of openness and great information.\n\nLooking back on this experience years later, it’s obvious that there are better ways to communicate with the participants ahead of time to screen out the unwilling. I should have spoken directly to the person we were visiting before the day of the interview, in order to get that person-to-person communication started early. But, given the diversity of people, there’s still a good chance that you’ll end up with someone sometime who isn’t initially comfortable with the interview process, and it’s your job to make them comfortable. Doing so may make you uncomfortable, but with practice, you’ll learn to set aside social dynamics and focus on the question asking and listening that will make the interview a success. See Chapter 8, “Optimizing the Interview,” for more on troubleshooting this type of common interview problem.\n\nA Framework for Interviewing\n\n23\n---\n# Work Toward the Tipping Point\n\nThere’s often a visceral point in the interview where the exchange shifts from a back-and-forth of question-and-answer, question-and-answer to a question-story setup. It’s such a tangible shift in the interview that I feel as if I can point to it when it happens. Stories are where the richest insights lie, and your objective is to get to this point in every interview.\n\nThe thing about this tipping point is that you don’t know when it’s coming. So you have to be patient in the question-and-answer part of the interview because you don’t necessarily know that what you’re doing to build rapport is getting you anywhere. You have to trust in the process, which is easier with experience.\n\n# Acknowledge That the Interview Is . . . Something Unusual\n\nAlthough your participants are using “social call” or “vendor meeting” as their initial framework for their experience with you, it’s not a perfect model. Strangers don’t typically visit us and take video of us grinding coffee beans. Falling back on naturalistic observation is disingenuous; it’s not easy for participants to pretend you aren’t there and just go on as they would normally. If we make the generous assumption that people on reality TV shows are in fact behaving naturally, that is typically due to an extensive amount of time surrounded by cameras, where what is natural shifts to something different. You won’t have enough time in your interview to accomplish that. Instead, leverage the constructed nature of your shared experience. You are empowered to ask silly-seeming detailed questions about the mundane because you are joined together in this uncommon interaction. Frame some of your questions with phrases such as “What I want to learn today is…” as an explicit reminder that you have different roles in this shared, unnatural experience.\n\n# Listening\n\nWhen you engage in conversation, you’re often thinking about what you want to say next and listening for the breathing cues that indicate it’s your turn to speak. As you jockey for your 51% of the conversation space, listening becomes a limited resource. Although we all like to consider ourselves “good listeners,” for interviewing you must rely on a very special form of listening that goes beyond the fundamentals, such as “don’t interrupt.” Listening is the most effective way you can build rapport. It’s how you demonstrate tangibly to your participants that what they have to say is important to you.\n\n# 24 Chapter 2\n---\n# Listen by Asking Questions\n\nIn addition to demonstrating listening by what you don’t say, you can also demonstrate that you are listening by what you do say. The questions you ask are signifiers that you are listening. Try to construct each question as a follow-up to a previous answer. If you are following up on something other than what the participant just said, indicate where your question comes from. For example, “Earlier, you told us that…” or “I want to go back to something else you said….” Not only does this help the person know that you’re looping back, it also indicates that you are really paying attention to what they are telling you, that you remember it, and that you are interested. If you are going to change topics, just signal your transitions: “Great. Now I’d like to move on to a totally different topic.”\n\n# Be Aware of Your Body Language\n\nMake and maintain eye contact with your participant. If you find eye contact personally challenging, take breaks and aim your gaze at their face, their hands, and items they are showing you. Use your eyes to signal your commitment to the interview. Acknowledge their comments with head nods or simple “mm-hmm” sounds. Be conscious of your body position. When you are listening, you should be leaning forward and visibly engaged (see Figure 2.5). When you aren’t listening, your body tells that story, too (see Figure 2.6).\n\n# FIGURE 2.5\n\nGood listening body language.\n\n# FIGURE 2.6\n\nNot so much.\n\nA Framework for Interviewing  25\n---\nThe listening body language is important because it not only gets you in the state, or reflects the state that you’re in, but it also very clearly tells the person you’re talking to that you are listening.\n\nIf your brain is listening, your body will naturally follow. But it works the other way, too! Just as therapists and life coaches encourage people to “act as if,” you can also put your body into a listening posture and your brain will follow. Consider the example described by Malcolm Gladwell in his article The Naked Face. He describes the work of psychologists who developed a coding system for facial expressions. As they identified the muscle groups and what different combinations signified, they realized that in moving those muscles, they were inducing the actual feelings. He writes:\n\nEmotion doesn’t just go from the inside out. It goes from the outside in…In the facial-feedback system, an expression you do not even know that you have can create an emotion you did not choose to feel.\n\nTIP FEEDBACK IS BACK\n\nIf you are recording your interviews on video for later editing, you may find the “mm-hmm” noises incredibly aggravating. Unless you are miking your participants, your affirmations may be much louder than their responses (see Figure 2.7). For novice interviewers in particular, it’s still good to let the “mm-hmm” fly and really work on developing rapport, even if the resulting video is going to suffer a bit. It’s better to have abrupt audio changes in the deliverable than fail to achieve the maximum possible rapport in the interview. As you gain experience interviewing, learn to silently affirm with facial expressions and head-nods, and throw in the vocalization only occasionally.\n\nFIGURE 2.7 The interviewer’s affirmations can be louder than the participant’s comments.\n\n26 Chapter 2\n---\n# Summary\n\nExperts have a set of best practices—tactics, really—that they follow. But what really makes them expert is that they have a set of operating principles. This looks more like a framework for how to be, rather than a list of what to do. You will have your own framework, but mine consists of the following:\n\n- Check your worldview at the door. When you begin fieldwork, don’t fixate on what you expect to learn, but rather cultivate your own general, non-specific curiosity.\n- Embrace how other people see the world. Do your fieldwork in their environments—not in yours. Before you head out to the field, get the team together and do a cleansing brain dump of all the things you might possibly expect to see and hear, leaving you open to what is really waiting for you out there.\n- One of the factors that makes for great interviews is the rapport that you establish between you and your participant. Don’t forget that it’s up to you to build that rapport. Focus on them and be very selective about talking about yourself.\n- Your job is to listen beyond “Keep your mouth shut and your ears open.” Your choice of questions and how you ask them demonstrate that you are listening. Pay attention to how your body language cues your participant—and you—as to how well you are paying attention.\n\n# A Framework for Interviewing\n\n27\n---\nNO_CONTENT_HERE\n---\n# CHAPTER 3\n\n# Getting Ready to Conduct Your Interviews\n\n- Establishing Your Objectives 30\n- Finding Participants (aka Recruiting) 31\n- Creating the Field Guide 39\n- Scheduling Interviews 44\n- Participant Releases and Non-Disclosure Agreements 45\n- Incentives 46\n- Summary 49\n---\nAnyone who has ever painted a room knows all too well the amount you have to tape off windows and trim, move the furniture, spread out the drop cloths, and so on. Sometimes I find this preparation tedious and unrewarding (I wanna see paint on the wall!), but I also know from experience that all the prep work has a dramatic impact on the quality and efficiency of the painting process itself. I know you see this coming, but here it is: Interviewing users requires the same level of prep work. There’s a significant amount of preparation involved before you begin asking the users anything. This may make some teams anxious if they’ve assumed the launch of a research project means fieldwork tomorrow. But these projects are by nature vaguely defined. You probably don’t know what you don’t know, which is why you are using interviews as your research method. The time spent creating alignment and developing a plan pays off tremendously. In this chapter, I’ll review the key issues to address when putting together a study, including who to interview (and where to find them), uncovering specific goals and defining the technique that will help address those goals, and refining the basic logistics that will make your time in the field go smoothly.\n\n# Establishing Your Objectives\n\nClarifying the objectives—what you hope to get out of the research—is an extremely challenging aspect of many engagements. Even though I begin capturing objectives in the initial conversations with the client, when it’s only a potential project, the objectives are further clarified while we are planning the research, executing the study, and even up until the delivery of results. Sometimes the objectives are not a fit for the approach. Researchers are often asked to find out how much participants would pay for a product, often when that product doesn’t yet exist. Responses to that question will not be valid, and it’s good to clarify for stakeholders as early as possible the limitations of contextual research (or any research method, for that matter). At the outset of a project, make the objectives your initial priority. The first interviews you conduct should be with the stakeholders—these are often consumers of the research findings who are less likely to be involved in the day-to-day study. I typically aim for 6–8 stakeholders, although some clients ask for twice that amount. These are one-on-one conversations either on-site or on the phone. They run between 30 and 60 minutes and are used to dig.\n\n30 Chapter 3\n---\nDeeper into objectives and establish collaboration. You should ask the stakeholders about:\n\n- History with the organization and the research topic\n- Current beliefs about the customer, the user, and the proposed solution\n- Organizational or other barriers to be mindful of\n- Business objectives for the project and specific questions the research should answer\n- Concerns or uncertainty around the methodology\n\nYou should also review other material, such as previous research reports, existing products, and in-development prototypes.\n\nEven though what you’re learning will undoubtedly inform all of the activities throughout the project, the immediate output is the research goals—articulating what you want to learn from the interviews.\n\nOn a project that dealt with reviewing products and services online, the team arrived at five research goals. Here’s one of them:\n\n# 1. Structure of Social Network\n\nHow is decision-making driven by the structure of people’s social network (on and offline)? More specifically:\n\n- What do people’s social networks look like? What tools do they use and how are their networks structured?\n- How do people leverage social networks for shopping and other kinds of decision-making? Who has influence with them currently?\n- Who among their social network (and beyond) are trusted sources of information for various decisions and purchases (particularly within the client’s area of business)?\n\nMy team created a document that summarized the project as we understood it at the time, including the agreed-upon methodology and the complete set of five research goals. I shared this document with our client to ensure that we were aligned. In most cases, the goals come easily and are not controversial. In rare cases, the goals may be wide-ranging and exceed the planned scope of investigation. In some cases, the goals are not a good fit for the approach you are planning. Use this checkpoint to realign, reprioritize, or expand the work.\n\n# Getting Ready to Conduct Your Interviews\n---\n# When the Seat of Your Pants Is Enough\n\nby Nate Bolt and Cyd Harrel\n\nNate Bolt is a design research manager at Facebook. Previously, he was CEO of Bolt | Peters and an adjunct professor at SVA iXD.\n\nCyd Harrell is an advisor to Code for America and other civic projects. She was previously VP of UX Research at Bolt | Peters.\n\nThere are two ways to approach a road trip. At one extreme, you can just go. At another, you can spend months planning the whole thing. Which approach will lead to a deeper exposure to the region you’re traveling in? It’s certainly open to debate, and the same can be true of planning user research.\n\nFrom our time at Bolt | Peters, we’re fans of minimal preparation for research because it allows for maximum serendipitous revelations and maximum speed. We frequently do successful interview studies with a single day of preparation, and that includes plenty of time for lunch. For start-up clients, we can then complete the research and generate useful recommendations in one more day. Some researchers would call this reckless and irresponsible, but we don’t think so. For us, it’s efficient, realistic, and fun.\n\n# An Example: Blurb.com\n\nWhen our clients at the self-publishing site Blurb.com first approached us a few years ago, they didn’t have the time or budget for a large UX research project. Yet they needed to understand why some of their customers were abandoning half-created books and what they could do to improve the publishing process. We proposed a single day of remote interviews followed by a directed workshop to generate recommendations, on one condition: their entire core team had to attend the interviews. This meant we were all in the same conference room at Blurb’s office with their stakeholders present, but the participant was remote, sharing their screen and audio using GoToMeeting. Prior to that day, we had a couple of one-hour calls with our key contacts, and we presented two short documents for their review.\n\nWe did not write a facilitator guide in advance, but instead honed it the day of the interviews, and since we were intercepting people from Blurb.com for the research, half the script was simply just asking them to continue doing what they set out to do on their own. So our live recruiting strategy took care of half the planning process.\n---\n# The study resulted in several actionable recommendations about both the book-creation tool and how to present it to users, as well as some striking insights into users’ mindsets/mental models.\n\n# Several key factors made this study work:\n\n- The entire client team attended. We weren’t doing our interviews in isolation away from the people with the biggest stake in the project, so we had the right group available to approve changes if needed. This meant that we could adjust the interview flow on the fly, even during a session.\n- We didn’t write a script, but we did spend our call time getting a solid understanding of the main questions to be answered. With two experienced interviewers on the project, we had confidence that we could guide an unscripted conversation in such a way that it answered those questions. (And if those had turned out to be the wrong questions based on users’ reality, we could have made the shift right away—see previous bullet.)\n- We live-recruited study participants using a Web intercept. We were confident that participants who answered “What did you come to Blurb.com to do today?” with one of the tasks we were interested in were actually engaged in the task at that moment. Without much direction from us, we’d be able to observe interactions that were important to the study simply by asking them to continue what they had been doing and think aloud.\n- We used an observation and recording method that we had a lot of experience with. While we ran a solid pre-flight check, we didn’t need to do a more extensive proof of concept. We simply used the online meeting tool GoToMeeting to observe users’ screens, and Mac screen recording software iShowYouHD to record their screens and phone audio.\n- We managed client expectations. We made sure our clients knew that findings would emerge from individual (and possibly very differently triggered) behavioral moments that would build into consistent themes. We made everyone promise to ignore the self-reported quotes and focus on behavior. We also didn’t provide percentages, severity scales, or other pseudo-quantitative outcomes. With the major players in the room all day, we knew that consensus on observations would be easy.\n\n# But why do it this way instead of pushing stakeholders for more time and more preparation?\n\nThe easy answer is that many organizations truly don’t have the time or budget required for full-blown research. We often simply have to work lighter and faster. But there’s also a way that a script, in itself, can limit your observations, and so can a strict user profile. When we’re working without a script, we’re not wedded to a strong presumption of how we’ll elicit the answers we need, and when we don’t have participants scheduled in advance, we’re not wedded to our original idea of the right participant profile. If, after six enlightening interviews, the team feels certain findings are solid and decides to recruit someone from an outlying demographic for extra perspective, that option remains open. Many times, that outside-the-box question or that slightly off user generates the most important finding in a study. One of the reasons we do this is that we hate to miss those times.\n\n# Getting Ready to Conduct Your Interviews\n\n33\n---\n# Group Therapy\n\nby Julie Norvaisas\n\nJulie Norvaisas is a senior researcher at LinkedIn. She was previously a researcher at Portigal Consulting.\n\nThe project started innocently enough. At kick-off, our client presented us with a series of hypothesized and storyboard-illustrated consumer needs, along with several early but well thought-out concepts being built to address those needs. Our job was to explore the needs and test the concepts. This seemed straightforward enough, but internal tensions were revealing themselves, even at this meeting.\n\nSome folks on the team were focused on gaining a deeper contextual understanding of the consumer’s experience in order to validate and deepen their understanding of their hypothesized consumer needs. This faction had legitimate questions about their hypotheses (which were not based in formal research) and were hungry for insights that could create more texture in their understanding, and inspire further conceptual design. This group was more comfortable with ambiguity in the research and was open to exploratory techniques.\n\nAnother group of strong voices was determined to simply gather reactions to the early concepts and prototypes they’d developed. This group had a very high degree of confidence that with their years of experience, they understood the market very well and had already nailed the consumer needs. These people were committed to the concepts and interested in specific feedback to prototypes, down to the level of form factor, mechanical design, materials, interaction, and GUI.\n\nPredictably, the former group was user-experience designers and marketing executives, and the latter was software and hardware engineers and technologists.\n\nPrior to departing for fieldwork in Minnesota, the team needed to ensure that our interview guide met the competing objectives of the stakeholders. We also had to be economical, with only 90 minutes allotted for each interview.\n---\nTo build consensus, the team met in the only room that happened to be available, a vacant office. We gathered our chairs in a circle in the otherwise empty room. It felt much more like a group therapy session than a meeting!\n\nRather than painstakingly reviewing the interview guide, we asked everyone to speak about how they felt about it. What were they most excited about? Nervous about? What questions did they still have? What aspects of the interview guide made them feel uncertain? What would make them feel better? We went around in a circle, and we shared. We listened. We acknowledged concerns and addressed them. We mirrored. We prodded.\n\nThe be-sure-to-get-us-context folks needed to know that we were going to gain some meaningful understanding of users while asking such specific, granular questions about the concepts. They would not be happy unless we were delving into behavior and motivations, even while talking about the size of a screen. The test-our-concepts faction required assurances that the early getting-to-know-you portion of the interview would not serve as a distraction from critical time spent on the concepts. They stated strongly that we were absolutely not to waste time asking questions regarding needs and usage that they already knew the answers to.\n\nThe therapeutic approach worked wonders to surface and resolve what seemed like a real impasse. In the end, everyone felt heard, and together we calibrated the priorities for the interviews. Inclusive conversation established a level of comfort on the team and a shared understanding of our objectives.\n\nOf course, as is so often delightfully the case, our careful intentions were blown up in the first interview. Our first participant told stories that touched the team deeply and immediately had us rethinking the needs and the concept, in the context of her reality. This effect built through subsequent interviews, ultimately changing the thinking of all of the members of the team. The prototypes served more as props to foster discussion about visions of the future than actual artifacts to be evaluated.\n\nIn the end, the concept-oriented members led the team to broaden their perception of needs and possible solutions. Original concepts were abandoned. The more reluctant group became the most vocal advocates for a new direction. The fact that all parties were heard and acknowledged prior to the fieldwork created trust despite concerns, and allowed us to be open to what was revealed in the field.\n\n\n\n# Creating the Field Guide\n\nThe field guide (sometimes called an interview guide or more formally, a protocol) is a document that details what will happen in the interview (see Figure 3.5). Creating this detailed plan is an essential preparatory step. The interviews themselves never happen as you imagine, but having a detailed plan prepares you to be flexible. It also creates alignment among the team (as do other planning tools). In situations where you have multiple teams of people out in the field, this alignment is essential.\n\nTo prepare your field guide, start with your research goals and the other inputs. This is the step where you translate “questions we want answers to” to “questions we will ask.” Of course, the guide also covers activities, tasks, logistics, and more.\n\nThe general flow of most interview guides is:\n\n- Introduction and participant background\n- The main body\n- Projection/dream questions\n- Wrap up\n\n# Getting Ready to Conduct Your Interviews\n\n39\n---\n# Reading Ahead Interview Guide\n\n# Introduction\n\nWe'd like to talk with you today about reading. We have lots of questions to ask you; and we’re interested in hearing your stories and experiences.\n\n# Overview\n\nCan you tell us a little about yourself, what you do, hobbies, etc.?\n\nCan you tell me about a recent book you've read? Your favorite all-time book?\n\nWhy do you read?\n\nWhat is your current reading like?\n\n[Probe for different types of reading; locations, motivations, etc.]\n\nIs your current reading typical for you? How is it different?\n\nDo you call yourself a \"reader?\" What does that mean to you?\n\n[Look for their categories; could be frequency, importance, etc.]\n\nIf you were telling a new acquaintance about yourself, would you talk about reading? What else would you say about yourself?\n\n# Exploring Specifics (locations, subject matter, motivations, etc.)\n\nYou mentioned (follow up on specifics from the interview). Is this always the same?\n\nHave there been any special circumstances where you've done it differently? Why? How was that?\n\nHas anything about the way you do this changed over time? How? Why?\n\n# Environment\n\nWhat makes a good reading environment for you? What are the elements? What makes an environment not good?\n\nFIGURE 3.5 One page from a field guide.\n\nA complete example is at http://rfld.me/QBeotb.\n\nChapter 3\n---\nBe sure to assign durations to the different sections and subsections. Again, you aren’t necessarily going to stick to the exact duration in the actual interview, but it helps you see if you’ve got enough time to cover everything you are expecting to cover. I prefer to write most questions as I might ask them (“Is there a single word that captures the thing you most like about wine?”), rather than as abstracted topics (“A single word that represents what they like about wine?”). As I’m writing the field guide, I’m leading a mock interview in my head. Using more detailed, thought-out questions helps me put together a more realistic plan.\n\n# Introduction and Participant Background\n\nIn the introduction, you’ll spend just a few minutes getting the interview under way, handling some logistics, and setting expectations. This section of the interview guide might contain the following (italicized text indicates instructions to the interviewer):\n\n- Give out release form and get signature\n- Turn on video camera\n- Confirm timing: 90 minutes\n- Explain who we are and why we are doing this\n- There are no wrong answers; this is information that helps us direct our work\n- Tell us about your family. Who lives in this house? How long have you lived here?\n\nThe discussion of participant background serves as an icebreaker and also provides some context for later in the interview.\n\n# The Main Body\n\nAs the name suggests, this is the bulk of the interview guide (and the interview). You should create subsections for each of the areas you want to explore (such as configuration, learning about features, downloading new playlists). The main body should also include the exercises and activities that you plan to use (such as mapping, card sorting, demonstrations, and reactions to prototypes or other stimuli).\n\nFor a study seeking feedback about a prototype home entertainment device, our main body topics were:\n\n- Revisit concepts\n- Context of use\n- Map your technology\n- Concept discussion\n\nGetting Ready to Conduct Your Interviews\n---\nBe deliberate in how you sequence these sections. You can start with the general and then dive into specifics; you can start with present day and move backward; you can start with a previous time and move toward the current state. There’s no universal rule here, so much depends on your topic and how you are mentally picturing the inquiry. Remember the participant may take things in a different direction, so don’t sweat too much over this. It’s easy to revise the overall flow once you’ve completed a couple of the interviews.\n\n# Projection/Dream Questions\n\nNear the end of the interview is a great opportunity to ask more audacious questions. Because you’ve spent all this time with your participants, talking through a topic in detail, they’ve become engaged with you. You’ve earned their permission to ask them to go even farther beyond the familiar. Two questions that work really well here are:\n\n- If we came back in five years to have this conversation again, what would be different?\n- If you could build your ideal experience, what would it be like?\n\n# Wrap Up\n\nA typical interview guide concludes with some basic questions and instructions:\n\n- Did we miss anything? Is there anything you want to tell us?\n- Is there anything you want to ask us?\n- Thank then and give the incentive.\n\n# Shot List\n\nAs an appendix to the field guide, list the photos you want to capture (see Figure 3.6), such as the following:\n\n- Head shot of participant\n- Participant and key piece of equipment\n- Close-up of key piece of equipment\n- Establishing shots, interior (cubicle or living room) and exterior\n- Two-shot of interviewer and participant\n\n42 Chapter 3\n---\n# LinkedIn Field Guide\n\n# Interesting Anecdotes\n\nAs with the other preparation tools, share the field guide with your team. The typical audience for the field guide tends to be broader than for the more tactical tools like a screener. I also try to help the people reviewing it understand what the field guide is (and what it isn’t) so that they can effectively help it evolve. I’ve used the following in an explanatory email:\n\nRemember, this is not a script. It reads very linearly, but it’s really just a tool to prepare to be flexible. Questions don’t get asked in the order they’re written here, or using this exact language (so it doesn’t need to be proofread). If you could look at it with an eye toward calling out anything that we haven’t covered—e.g., “We need to ask about how they deal with time zones”—or any larger topic areas that are missing, or anything that seems wildly off base, that would be the most helpful.\n\n# Getting Ready to Conduct Your Interviews\n\n\n---\n# Summary\n\nIt takes a lot of preparation—perhaps a surprising amount—to set up successful field research. I don’t recommend leaping into the fieldwork without setting yourself up to be successful. The effort in creating alignment, developing a plan, and determining the logistics pays off tremendously in the quality of the experience for you, stakeholders, and participants and in the value of the insights gathered.\n\n- Agreeing to the objectives for field research is crucial, but is often challenging. You may all agree that you are going to interview 12 typical users before you are able to agree on what you expect to learn and how that will inform your business.\n- Use the documents you create in planning (research goals, screener, and interview guide) to align with your team.\n- Consider broadly and choose specifically what types of participants you want. But treat this as a hypothesis and adjust your approach if necessary.\n- Leave time in your project plan to find research participants.\n- The field guide is the detailed plan of what you think might happen in the interview, typically flowing from the details to their meaning. Having that detailed plan empowers you to be flexible when you actually go into the field.\n- When scheduling interviews, leave adequate time between them for reflection, eating, travel, and the bathroom. Don’t overload your day—and your poor brain—with too many interviews.\n- Use a release that documents the rights and obligations of both the organization that sponsors the research and the participant.\n- Give participants an incentive that conveys your sincere appreciation of their time.\n\n# Getting Ready to Conduct Your Interviews\n\n49\n---\nAB  N\n---\n# CHAPTER 4\n\n# More Than Just Asking Questions\n\n- Showing and Telling 52\n- Bring the Tools 55\n- Summary 65\n---\nAlthough the title of this book emphasizes interviewing, when you get down to it, interviewing involves more than just interviewing. Did I just blow your mind? I bet that I did. But dust yourself off, acknowledge the glory of recursion, and let’s move on! Interviewing is absolutely the core of the interaction with your participant, but there are other techniques (or if you prefer, methods; or if you really prefer, methodologies). You should consider the interview itself as a platform and try to organically integrate a larger set of techniques.\n\n# Showing and Telling\n\nEven when your only technique is asking questions, there are many ways to get to the information you are seeking. I’ll go further into the types of questions in Chapter 6, “How to Ask Questions.” The phrasing of the question itself leads to a variety of techniques. If one of your research objectives is to understand how people are managing their digital music, you might ask your participants specifically, “What is your process for updating your playlists?” With that question, the participant is being asked to verbally summarize a (potentially detailed) behavior, from memory. This isn’t necessarily a bad approach; it may be interesting to hear which steps in the process are memorable and which ones aren’t. It’s also a chance to get some emotional color. (“Oh, it’s easy, all I do is….”) But it’s not going to be the most accurate information. By asking, “What is your process for updating your playlists?” we are actually learning the answers to the (unasked) “How do you feel about the process for updating playlists?” and “What are the key steps you can recall in the process for updating playlists?” That information is very important, but it may not be sufficient to really understand the user’s situation.\n\nNow, a slightly different expression of the question is “Can you show me how you update your playlists?” Now you’ve staged an activity. In this activity, you and your participant will move to where the relevant devices are, and you will be able to observe the specific steps in completing this task. Of course, you’re also going to gather the emotional context of the process. I sat with a financial advisor who struggled to navigate his intranet in order to find some critical data. His lack of success in locating this data was so frustrating that he began to laugh. Of course, it wasn’t comical per se, but he felt that the failures of the system were absolutely ludicrous, and the laughter clearly revealed his perspective.\n\nAlthough a topic such as playlist updating may be specific to that participant’s personal devices and data, in situations where the process is more general, you may try a slight variation, shifting to a participant-observation dialogue, such as, “Can you show me how I should prepare coffee?” Instead of the subject going through her own process, narrating the different steps\n---\nas she would perform them, your question directs her to explain specifically each step so that you can perform it, such as, “Now, before you put the filter in, make sure the water is boiling.” Asking that person to play the teacher role not only reinforces the idea that she is the expert here, but it also can make it easier for her to articulate the details you are seeking.\n\n# NOTE\n\n# PARTICIPANT OBSERVATION\n\nParticipant observation doesn’t mean observation of the participant; it means that you observe by participating. I’m typically using the term participant to refer to the research subject, but in this approach, you are the participant because you are participating in the activities you are seeking to understand.\n\nDepending on the activity, you may arrange to be present when it occurs. I once sat in a family’s kitchen at 7:00 a.m. and watched as they went through their morning food prep rituals. (Yes, that was very early. The only thing worse than the feeling of getting up so early to do fieldwork was the look on our participants’ faces when they opened the door to let me in. Sure, they agreed to it ahead of time, but I was certainly not their favorite person at that particular moment.) I didn’t need to ask them to show me how coffee was prepared because I knew ahead of time that this was when coffee was going to be prepared. In addition to seeing the operation of the coffee machine, I saw a great deal of context—what other devices were being used, who else was around, what happened before, and what happened after.\n\nYou can also work with your participant to stage the activity you want to understand. Although you can expect that breakfast will be eaten most days, you can’t be sure that the IT department will be installing a new router every day. However, if you bring them a router when you come for your interview, you’ve created the occasion.\n\nAnother approach more suited for unpacking interactions between people is role-playing how this interaction does (or should) take place. In a project where we looked at customer service experiences, a man complained emphatically but without specificity about the phone service at his local department store. I asked him what he objected to, or how it could be different, but he struggled to find anything to tell me beyond his general dissatisfaction with the way things were. Instead, I suggested that he act as the person answering the phone, and I would act as him, and he could show me how it should work. After describing the exercise, I held an imaginary phone to my head and said “Ring, ring!” (see Figure 4.1). He answered his imaginary phone, and we proceeded to model the ideal conversation. Afterward, we talked about how our version differed from his typical experience.\n\nMore Than Just Asking Questions  53\n---\n# ION (2.0)\n\n# FIGURE 4.1\n\nShifting the discussion from the conceptual to the tangible (even when being tangible means being fantastical) is one way to get at hard-to-uncover information.\n\nParticipatory design, a term that sometimes refers to an overall approach to design, is essentially giving people the tools to show us how they envision a new design or solution. This can take many forms: I’ve created blank versions of a mobile device screen and had participants draw the UI, and I’ve seized the moment when participants starting envisioning a new solution and helped them to grab whatever was nearby. (One participant grabbed a hard cover book as a proxy for size and form factor, but then proceeded to gesture with the book as if it really were this future device.) Designers sometimes get nervous with participatory design because it implies that users will tell them what to design, and they’ll be expected to go off and implement it. Of course, that’s not true at all. Participants may decide their ideal product needs a handle. But we know that really means that they need an easy way to move it from place to place, and we know that there are dozens of ways to satisfy that need. My aim with participatory design is to give people a different way to talk about needs, where the solutions stand as proxies for those needs.\n\n54 Chapter 4\n---\nNo one of these interrelated techniques is inherently better than the others. Any of them may be appropriate, depending on what you want to know, what you’ve already asked, and what is working well between you and your participant. You may also want to combine these approaches to look for points of divergence. For example, if you observe a certain coffee preparation step that is excluded from the process your participant teaches you, that’s something you can ask about: “I noticed that when you were making coffee earlier you waited until the water boiled before you put the filter in. That wasn’t something you told me to do. Is it an important part of the process?” As with so many aspects of the work you’re doing, you want to have a broad palette of approaches that you can bring to bear as circumstances warrant.\n\n# Bring the Tools\n\nThis section explains a set of techniques that involves using prepared physical materials to facilitate the interview, including maps, various forms of representing concepts, organizing and sorting artifacts, and “provocative” images.\n\n# Mapping\n\nA map is a tangible representation that shifts the abstract (such as a process, a set of relationships, or the details of a large physical space) into a concrete artifact. This artifact provides a focal point for more detailed discussions and is documentation that can be taken with you at the end of the interview. In one example, architects and designers mapped out their fairly complex workflow (indicating software packages, file formats, processes, contributors, output, and so on) using sticky notes (where each color represented a certain class of element) on a large piece of butcher paper. In a project for Nokia Research Center that involved exploring the notion of convergence, tech-savvy consumers drew a map of their homes and indicated where their technology was located and how it was connected together (see Figure 4.2). The interviewer facilitated the process of drawing the map by probing and prompting. As the map was built, both the participant and the interviewer developed a shared understanding. As the interview proceeded, the interviewer could continually refer to the information on the map—for example, by pointing to an element and clarifying “So that would be when you’re over here, then?” The map became a crucial element in the analysis and synthesis work after the fieldwork was over, as the interviewer used it to relate pertinent details to his colleagues.\n\nMore Than Just Asking Questions  55\n---\nFIGURE 4.2\n\n# Reactions to Concepts\n\nI don’t like to call this “concept testing” because that implies the key to the approach is to present a solution and have participants evaluate it. What you present need not represent an actual solution. For example, you often show concepts that are not viable or otherwise unlikely in order to explore the edges of factors that influence desirability, usefulness, and so on (see Figure 4.3). What you’re learning is not an evaluation of the concept, but instead a deeper understanding of the design criteria for a future solution. Although concepts are the stimuli, you deliberately choose stimuli that contain some aspect of your hypotheses, ideas, or questions in a tangible form.\n\nFIGURE 4.3\n\nIt would be much harder to have a discussion about button size, screen size, ear-canal risk, and so on, if you only had a set of “best” solutions on hand.\n\n56 Chapter 4\n---\n# NOTE\n\n# GO INDIRECTLY\n\nAs with participatory design, solutions that you show can stand as proxies for something else. You aren’t asking questions about their needs (say, their expectations for a device’s size), but rather you are asking questions about a concept in order to elicit, among other feedback, their expectations for the device’s size. This can be quite indirect; the stimuli don’t actually reveal to the participant what it is that you want to know, what is feasible, what is planned, or what your hypotheses are. There’s a difference between what you want to know and what you ask. Let yourself be creative when developing these provocative stimuli.\n\nI’ll go to the interview with a set of specific topics I’m looking for feedback about, but it’s important to let the participants structure most of the response themselves. I’ll put the concept in front of them, with whatever explanation or demonstration I’ve planned, and then ask them an open-ended question such as “What do you think?” The topics they choose themselves are the strongest natural reactions. If they start off raving about the keyboard but don’t mention the screen until I ask about it, that’s an important takeaway. It’s my job to make sure I hear about the keyboard, the screen, and all the other topics of interest, but the concerns and delights that they express unprompted are critical.\n\nOne caution here: depending on your individual role, you may feel a certain amount of ownership of the concept. But as I urged you in Chapter 2, “A Framework for Interviewing,” you should have checked your worldview at the door and be ready to embrace how someone else sees the world. You should present your concepts neutrally in order to give the participants as much freedom in their responses as possible. Even if you begin your interview with “We’re here to get your feedback, so don’t worry about hurting our feelings,” if you bring out a concept by saying, “Here’s something I’ve been working on…” you’re activating a natural social instinct that will diminish their comfort in being critical. The disclaimer at the beginning works at a different (and less effective) level than the cues you give off in the way you present concepts. Before you go into the field, practice “the reveal” aloud until you hear yourself sounding neutral (try “Here’s a whole bunch of early ideas that I was asked to show you” or “I’ll be curious to hear what you think of this one” or “Our clients are exploring some possible ideas”). I’ve often found the concepts themselves are sufficiently complex (because of the technology that’s being used or the domain of work that is being supported) that I’m not able to present them effectively. In that case, my client will handle that part of the interview: I’ll introduce the exercise (with the neutral language), my client will give a neutral demonstration of the concept, and I will ask the first open-ended question.\n\nMore Than Just Asking Questions 57\n---\nOne more caution here: If participants perceive you as having ownership over the concept, they may turn the interview back on you: “Will this be backward-compatible?” “How much will it cost?” “Does it have high fructose corn syrup in the sauce?” Do not answer those questions. This is a terrible struggle for my clients who always have the answers and would feel so much more comfortable in the familiar scenario where they are the experts about this topic. Once again, do not answer those questions. Do the Interviewer Sidestep and turn the question back to them: “Is that important to you?” “What would you expect it to be?”\n\n# Concept Formats\n\nThere is no limit to the manner of concepts you can develop for researching with users. But it’s important to realize that you are creating these concepts for that very purpose: showing to users. You’ve probably seen shiny prototypes that are intended to get investors, retailers, or managers excited. But I urge clients to represent their ideas in lower, rather than higher, fidelity1. As a rule of thumb, lower-fidelity prototypes are best for getting reactions earlier in the process (when you are trying to understand the appeal of the idea), and higher-fidelity prototypes are better for later in the process (when you want to verify some specific aspect of the implementation). There are always exceptions. If you are presenting a futuristic concept, you may want to be very high fidelity in your representation in order to get participants past the inevitable “Well, what would that actually be like?” questions and into the area you want to explore.\n\nHigh fidelity is not an all-encompassing term. There are different dimensions of fidelity—for example, “looks like” versus “works like.” A prototype that simulates an experience may be high fidelity along one dimension but not another. Align your concept representation with your research question. Here are a few formats for presenting concepts:\n\n- Storyboard: An illustration, typically across multiple panels, depicting a scenario. I used storyboards (see Figure 4.4) when working with MediaMaster, a digital music start-up that was trying to choose among a number of different directions in their product development.\n- Physical mock-up: A representation of a physical product that can be touched, opened, and so on. The team at Nokia Research Center mocked up a number of size variations on a mobile device using foam core and a printout of a screen design (see Figure 4.5, left). Tursiogear, a start-up company, provided an early manufacturing prototype of an iPod video case that I showed to consumers in order to help understand the features they were expecting (see Figure 4.5, right).\n\n1 For an engaging and helpful read, see Houde/Hill’s classic “What Do Prototypes Prototype?” http://rfld.me/Wnig5s\n---\n# Step 2\n\nAt Checkout Associate scans barcode on Front Of envelope:\n\n# Step 3\n\nWhen Megan gets home, she follows directions on the envelope and takes the CD booklets out of her CD Cases: She counts the booklets; puts them in the envelope.\n\n# Step\n\nUpon purchase, envelope is \"activated\".\n\nMegan bases online to complete the purchase, selects file formats, and signs up for a free account. She then drops the envelope in the mail;\n\n# FIGURE 4.4\n\nDetail of one of several storyboards showing the different scenarios that MediaMaster was considering developing.\n\n# FIGURE 4.5\n\nPhysical mock-ups from Nokia (left) and Tursiogear (right) help make the conversation about a future product tangible.\n\n# More Than Just Asking Questions\n\n59\n---\nI’ve even used this physical mock-up approach for non-technology projects. When studying how people reacted to different messages in a gas company’s credit card newsletter, I used fairly realistic examples of this newsletter, complete with a sample credit card statement and their official envelope. Although most of the newsletter was actual English, the back page had a number of articles with “Greeked” text (lorem ipsum, and so on). One participant noticed this text and (thinking that it was Spanish) commented that the inclusion of a second language was a great idea! It was a good reminder that our assumptions about elements in a concept are often shattered in the field. In a slightly more challenging situation, I arrived at the research session to find that my client, who was not Apple, had echoed (to put it charitably) the iPhone form factor in a solid model mock-up for a hand-held device. (Their logic was that they were going to try to mock it up later using an iPhone, so….) Every participant therefore assumed that the product would be made by Apple (it wasn’t), and that it would be usable not only around the home but also could be taken out and used away from the home (it wouldn’t). I had to adjust for those influencing factors in interpreting the results of the sessions.\n\n# Wireframe\n\nA simplified version of an on-screen interface. This could be printed, sketched on paper, or a combination. It could be presented on a screen (say, a laptop or tablet). It could be a series of screens that depict a flow with real or simulated interactivity. We showed currency traders a data-free mock-up of their trading platform to uncover which elements had to be carried forward into a redesign and which elements they were receptive to seeing changed. In the previously mentioned Nokia Research Center project, their team produced an iPad-based simulation of a mobile device UI (see Figure 4.6) that we used in combination with a physical mock-up (see Figure 4.5, left).\n\nFIGURE 4.6: Nokia used an iPad to demonstrate the on-screen interaction for a future product concept.\n\n60 Chapter 4\n---\n# NOTE\n\n# IMPROVISING WITH A WOUNDED PROTOTYPE\n\nWorking with Hewlett-Packard on research for their DVD/digital projector, I met up with my client at the Denver airport a few hours before we were to head out for our first interview. He was traveling with an engineering breadboard, which is a working model cobbled together from parts and controls and stuffed into an electronics case. (This is a “works like” but not a “looks like.”) Too big to carry on, it came as checked baggage. Oops. While it was physically intact, my client quickly realized that the audio no longer worked. In our scant time, we scrambled to borrow multi-tools and other weapons of engineering destruction. The back seat of our rental car became a mobile bench as he struggled in vain to repair it before fieldwork commenced. In the end, it was fine, even without sound. We showed participants how the device played a DVD and projected the image on their walls. And then we asked them to describe the qualities of the audio they would expect in order to match the video experience the prototype delivered. For more about this project, see this link.\n\n# Reactions to Other Stuff\n\nOther stimuli can be helpful in probing people’s underlying belief structures, expectations, or motivations. As with the mapping tools, these stimuli are an interactive and tangible way to help people express themselves. And as before, there are endless ways to provoke participants. Here are just a couple:\n\n- Casual card sort: In contrast to the more rigorous card-sorting process that is used in software design2, this is a way to prompt a discussion about a large set of items. For one project, I used cards that depicted a large set of online services (see Figure 4.7). For another project, the cards illustrated many items that people purchased on a regular basis. As the cards were spread out, people began to talk about those that were relevant to them, prompting stories or highlighting areas for follow-up questions. Some groupings may emerge with this process, and the cards can be used as a tool for confirming your understanding of the participant’s mental model, as in “So it sounds like these two cards would go together because you see these as examples of something you do for work, but not for your personal use?” Of course, you can create new cards based on what you hear (bring blank ones!), or you can annotate the cards to reflect what the participant has told you.\n\n2 You can find a great primer on traditional card sorting at this link.\n\nMore Than Just Asking Questions\n\n61\n---\n# FIGURE 4.7\n\nThe primary online services that our research participant mentioned, selected from a larger set.\n\n# Images that resonate:\n\nThese images can also be cards, or a printed sheet, or stickers (see Figure 4.8). Whatever the medium, they depict a large number of images that are meant to evoke an emotional reaction. Consider stock photos, glamour shots of products, celebrities, historical images, nature and landscape images, textures, colors, and so on. (A variation might be to include words in the set as well.) With this large set of diverse stimuli, you can ask people to pick a few images that address something you’re interested in. In past projects, I’ve asked people to select images that evoked their ideal online experience with our client’s brand, or that represented the way they hoped a new printer could change their lives. The most insightful part happens when you ask participants why they picked those images. They’ll tell you—in surprising ways—what it is about those images that speaks to them and how those characteristics represent their hopes, aspirations, or ideal solution.\n\n62 Chapter 4\n---\n# 855\n\n# FIGURE 4.8\n\nLaminated image cards are used to provoke individual reactions and uncover hidden associations.\n\n# Homework\n\nOften the thing we are most interested in happens in a series of smaller interactions over a course of days and weeks. In that case, give your participant a homework assignment. When I wanted to understand how people would react to a credit card newsletter, I asked participants to save their postal mail for a few days, without opening it. During our interview, they narrated their mail sorting process, explaining what they would keep and what they would trash. When I then showed our prototype newsletter in its envelope, we had a solid context for investigating the meaning of the newsletter. Similarly, when Beringer was redesigning its Stone Cellars wine packaging, we asked our participants to save a week’s worth of empty bottles. Between their unopened wine, the empty bottles, and the sample bottles we brought with us, we had a wide range of example packages to look at together.\n\nMore Than Just Asking Questions 63\n---\nI also use homework as a way to prime participants about a topic I’m interested in. In other words, it helps people reach a state where they are more introspective about something they may not pay attention to otherwise. I’ve asked people to log when they use their mobile phone, take screen shots of every intranet search, or document all their banking activities. This certainly produces all sorts of curious instances, provocative examples, and weak signals about possible behavior patterns, but this self-documentation (sometimes called journaling or a diary study) really pays off during a follow-up interview. Not only do you have an extensive set of examples to discuss, but you also have a participant who has been thinking about a topic a lot more than she normally does. (You can see this happen during interviews as well; I’ll discuss this more in Chapter 5, “Key Stages of the Interview.”) That reflection will lead to a better conversation. Of course, a primed user is not in her natural state, so don’t prime if your goal is to understand what’s already top of mind.\n\nA specific type of priming is used to accelerate the usage of a product. I took a streaming music server to digital music enthusiasts and asked them to install it while I watched. At the end of the interview, I left them with a workbook that contained about two weeks’ worth of assignments, asking them to explore a different feature or use case. Given that people would be unlikely to explore a product that thoroughly in two weeks (if ever, especially given the complexity of this particular product), it was crucial to give people a structure—and a motivation—to drive their usage. After two weeks, we collected their workbooks and then returned for a follow-up interview.\n---\n# Summary\n\nBe creative in developing a range of methods for any one project. While interviewing is at the core, it’s really a platform that can organically include a larger set of techniques that goes beyond merely asking questions. For example, you can vary the activities in the session itself, ask participants to prepare for the interview, or take materials specifically to facilitate the discussion. You can also do the following:\n\n- Ask for a demonstration of an activity that might not otherwise take place.\n- Observe a behavior or a task as it happens to occur naturally.\n- Use a mapping exercise to create a tangible representation of something abstract that you can refer to repeatedly throughout the interview (and then take away with you at the end).\n- Show provocative concepts at varying levels of fidelity and create concepts that will generate discussion around the issues at hand (rather than testing your best guess at the best solution).\n- Use images as stimuli to prompt a deeper discussion. When mounted on cards, they can be sorted, grouped, annotated, referred to later, and so on.\n- Assign homework (for example, take a few pictures, save some artifacts, complete a questionnaire, and document a set of activities) to give you some data before the interview and to prime the participant about the interview topics.\n\nMore Than Just Asking Questions 65\n---\nNO_CONTENT_HERE\n---\n# CHAPTER 5\n\n# Key Stages of the Interview\n\nBut Wait! Before You Head Out:\n\n|Roles for the Field Team|69|\n|---|---|\n|Once You Get On-Site|72|\n|Summary|81|\n---\nMost people are at least conversationally familiar with the Kübler-Ross model of the five stages of grief: denial, anger, bargain, depression, and acceptance. This model describes a consistent set of elements in a very human experience. At the same time, Kübler-Ross pointed out that people don’t necessarily experience all those stages or experience them in that order.\n\nA contrasting model is the beat sheet (see Figure 5.1), a tool for screenwriters that lays out the necessary sections of a typical three-act screenplay, a ubiquitous structure for Hollywood films. There are even beat-sheet calculators that will take the number of pages of a screenplay as input and identify on what specific pages the different story elements should appear. While Kübler-Ross is descriptive, beat sheets are predictive. While being predictive might seem a limitation when making movies, this consistent structure and the reliance on other tropes is part of what makes movies work: viewers are being taught the code with every experience.\n\n# THE BLAKE SNYDER BEAT SHEET\n\n|PROJECT TITLE :| |\n|---|---|\n|GENRE| |\n|DATE :| |\n\n|Opening Image (1)| |\n|---|---|\n|Theme Stated (5)| |\n|Set-Up (1-10)| |\n|Catalyst (12)| |\n|Debate (12-25)| |\n|Break into Two (25)| |\n|Fun and Games (30-55)| |\n|Midpoint (55)| |\n|Bad Guys Close In (55-75)| |\n|All Is Lost (75)| |\n|Dark Night of the Soul (75-85)| |\n|Break into Three (85)| |\n|Finale (85-110)| |\n|Final Image (110)| |\n\nFIGURE 5.1 The beat sheet outlines a standardized structure for storytelling via a screenplay.\n\n68 Chapter 5\n---\nI’ve identified the stages that most interviews go through, and my model is somewhere between descriptive and predictive. You may notice some or all of these stages in your interviews, but you can’t anticipate, for example, that one will (or should!) happen precisely at the 40-minute mark. But each stage requires specific tactical preparation or responses from you, the interviewer. Get familiar with the details of the stages, and if you don’t recognize them while reading, you probably will the next time you are out in the field. As you gain experience, moving through these stages will become secondhand.\n\n# But Wait! Before You Head Out:\n\n# Roles for the Field Team\n\nGenerally speaking, I find the ideal size for the field team to be two people: one to lead the interview, and one to back up the other person. In some cases, it’s important to expose as many people as possible directly to users, so more people join the sessions. From social psychology, we know that even the presence of others will influence behavior, so be cautious. Even three interviewers will shift the power dynamic and make some participants awkward and less open. This is especially true in a home environment and can be exacerbated depending on the age and gender of the people involved. If I’m asked to field a team of three, I make sure that everyone is aware of the trade-off we’re making between more team exposure and less open interviews. I’m extremely resistant to anything larger.\n\n# A Guide to Participating in Fieldwork\n\nIt’s crucial that everyone going into the field understands their roles and that the two or three people who are meeting participants will act in concert, performing like a team. Typically, I convene a brief in-person or telephone meeting where all the potential fieldwork attendees come together to review some basic rules. I’m not trying to make instant expert interviewers out of these folks; I’m looking to pass along the minimum information to ensure these interviews are successful. By handing out the following guide and talking through it, I am starting a conversation about expectations and roles.\n\nHere is an example of how I might introduce the guide when I’m talking to my fellow participants:\n---\n# A Guide to Participating in Fieldwork\n\nThanks for joining our research team in the field. Your participation in this part of the process will benefit the overall results of our collaboration.\n\nAlthough fieldwork may appear on the surface to be a straightforward conversation, you will soon see that a lot more is going on. We don’t expect you to be an expert interviewer, although you’ll find that you get better with practice. Here are a few tips to help you get the most out of your experience and help us work better together:\n\n- One of us (Portigal Consulting) will be the lead interviewer. You will be the second interviewer. (Kind of like “second chair” on Law and Order, where this lawyer sits next to the “first chair,” actively observing and strategizing without conducting any of the questioning.) The lead interviewer runs the interview. They also coordinate the participation of the second interviewer.\n- Stay engaged! Even if you are not asking questions, listen actively. That means thinking about what you are hearing, making eye contact, nodding affirmatively, and taking notes. You aren’t just a “fly on the wall”; you are participating.\n- Interviews are different from conversation. We’ll use a relaxed tone, but we are purposefully guiding the interaction, often thinking several questions ahead. Although you may not see the path the lead interviewer is on, as the second interviewer, it’s important not to interject in a way that can interrupt the flow.\n- Write down and hold your questions for the appropriate time. Interviews unfold like the chapters of a book. Your questions need to stay within those chapters. It’s the job of the lead interviewer to move the interview from one chapter to the next. The lead interviewer will create opportunities—usually at the ends of these chapters—for you to ask questions.\n- We aren’t the experts. The people we are interviewing are the experts. We want to gather their stories and opinions, and to hear what they have to say without influencing them. Use their language and terminology. If they refer to a product, brand, or feature inaccurately, don’t correct them explicitly or implicitly.\n- Use open-ended questions. Don’t presume what you think the answer should be.\n\nLess good: “What are three things you liked about using the bus?”\n\nGood: “Can you tell me about your experience using the bus?”\n\nWe don’t know that they liked anything about their experience on the bus!\n\nAlso available as a PDF at http://rfld.me/PFG8dP.\n---\n# Everyone Stays Engaged\n\nAnother approach I’ve seen teams take is to assign explicit roles (such as note taker, photographer, videographer, and so on). I am suspicious this is partly busy-work, akin to giving a toddler a complex toy to play with so they don’t get distracted during a long car ride; it is beneficial to distribute those tasks, but it’s also more well-defined to serve as the photographer than the second interviewer. My preference is to set someone up as an interviewer and then, when we meet individually before the interview (say, 30 minutes before, at a nearby café), explore that person’s comfort and interest with any of the various roles.\n\nOne executive asked me hesitantly about joining in the fieldwork, promising that he’d just be there to observe and wouldn’t be involved. But this isn’t surgery; it’s an engagement with another person. I told him that his participation was at least welcome, and at best necessary, but his role would be an active one, even if it was mostly active listening.\n\nThere are a number of techniques for managing the second interviewer and his understandably naive impulse to ask whatever question he thinks of at the moment he thinks of it. You can provide him with sticky notes to write his questions on as he thinks of them (so even if the asking is deferred, at least capturing the question provides some—albeit muted—immediate gratification). You can set aside a period of time at the end of the entire interview for his questions (although this may be asking him to “hold it” for a long period of time, and you may observe some squirming; further, the questions are perhaps decreasingly relevant as the interview proceeds). You can set aside a time for him to ask questions within each topic area before you move along, asking him “Is there anything that we’ve talked about so far that you’d like to know more about?” I tell my fieldwork attendees that we can have a brief conversation in front of the participant about any questions they have; they may want to suggest a topic to me rather than constructing the question directly themselves, which enables me to pick that question up or defer it as I choose. (For example, “Steve, I’d love to learn about how Jacob sends the documents to accounting.”)\n\nMuch of this presumes that the fieldwork team is assembled from two types of people: those who are likely to be reading this book, and those who wouldn’t even have imagined a book like this existed. Alternatively, if you are out in the field with a peer, and you’ve had a fair amount of experience, not only individually but also as a team, you will find a lovely fluidity between the two of you. Your brain will tell you, based on body language and breath, when your colleague wants to ask a question. If you are chasing down a bit of information, don’t turn it over immediately; just make eye contact to let your partner know you’re getting there, finish the thread you are exploring, and then give him the “nod” to step in. This can be a wonderful moment, where instead of feeling like you are managing precocious toddlers, you are instead gigging with a very tight jam band.\n\n# Key Stages of the Interview\n---\nBe clear with yourself whether you are interviewing with a peer or managing a less-experienced fieldwork attendee. With a peer, your goal is to harness her keen brain and make the interview better. Talk to your peer before the interview and explore tactically how loose you both want to be. With a fieldwork attendee, you don’t share a mental model about how the interview might proceed, and so he might be as baffled by your next question as you would be by his random question. Given that, your goal is to maintain control over the flow of the interview while facilitating the attendee to have a successful experience. Engaging him and uncovering his perspective (as revealed by his questions) is important as well, but I see that placing third.\n\n# Once You Get On-Site\n\nOnce you get on-site, you’ll find these different stages:\n\n1. Crossing the threshold\n2. Restating objectives\n3. Kick-off question\n4. Accept the awkwardness\n5. The tipping point\n6. Reflection and projection\n7. The soft close\n\nIn Chapter 3, “Getting Ready to Conduct Your Interviews,” I described the general flow of most interview guides. The flow of the guide corresponds roughly to the stages of the interview.\n\n# Crossing the Threshold\n\nThe very first few moments of an on-site interview are often characterized by mild confusion, especially if you are going to someone’s home; less so if you are arriving at a professional office with a reception area. In general, your participants aren’t 100 percent clear on what’s expected of them. They may not have been told, or remember, your name or the organization you represent, and only know the details of who recruited them to participate. Before you arrive, figure out what you are going to say. It may be as simple as “Hi, I’m Steve. I’m here for the interview.” Or “Hi, I’m Steve from _____. I’m here for the interview.” (These work especially well if your name happens to be Steve.) Think carefully about what organization name you use. They may know the recruiting firm’s name (or even the name of the individual recruiter), but not the name of your company. They may be more familiar with your product’s name (such as BlackBerry) than your organization’s.\n---\nname (such as Research In Motion).2 Identify yourself in a way that they’ll recognize. Of course, if you’ve personally reached out to the participants by email or telephone before the interview, this is much simpler.\n\nWhether you are in a home, a workplace, or any other environment, once you are “in,” social graces matter. Introduce the rest of your fieldwork team and offer to take off your shoes if you are in someone’s home (but be sure you don’t have holes in your socks!). As you come in, figure out where you want to start the session. In an office, it may be a conference room. In a home, it may be the living room or dining table. Even if the bulk of the interview is going to take place at a specific location (say, at a computer or in the mail room), you may want to start off in a more open and front-stage part of the environment. Your participant won’t know what you need, so be prepared to ask her.\n\nArrange seating so that you and your fellow interviewer (or interviewers) are near each other. In order to maximize the engagement among all parties, you want the fieldwork team to be able to maintain eye contact with the participant, and you want the participant to be able to respond to questions from either of you without having to turn her head too far (see Figure 5.2).\n\nIf need be, ask the participant to sit in a particular spot. The participant doesn’t know what’s supposed to happen, so by gently taking charge, you can reassure her and set the tone for the whole interview.\n\nIf you’re shooting video, make sure the lighting is appropriate. If your participant is sitting in front of a bright light (such as a window), then ask her to move or close a blind. If the room is too dark, ask about opening window coverings or turning on lights. If there’s a radio or television on, ask her to turn it off (as sometimes those can appear more prominently on audio recordings than you would expect). This isn’t a social visit (as a guest, you probably wouldn’t ask your friend to move to a different seat), but rather it’s\n\nFIGURE 5.2\nEnsure that all interviewers can maintain eye contact with the participant (L), rather than forcing her to swivel her head to keep you both in view (R).\n\nIn January 2013, Research in Motion finally acknowledged how people think of them and changed their organization’s name to BlackBerry.\n\n# Key Stages of the Interview\n\n73\n---\na purposeful, arranged session. If you are offered a drink, feel free to accept it, as this is the participant’s way of anchoring the session to a familiar scenario. The participant isn’t trained as a professional interviewee so she will, of course, rely on familiar styles of social interactions. Although it’s fine for you to accept her social gestures (in some cases, it can be essential, as a failure to do so can be read as rude; err on the side of taking the offered glass of water), as the interviewer, you will offer fewer of those gestures yourself.\n\nAs you are settling into place and getting your gear unpacked and set up, ask the participant to sign any non-disclosure and consent agreements. I’ll often bring it out as quickly as possible and tell the participant “Before we get started, we’ve just got some paperwork for you.” The key words here are “Before we get started.” Specifics will vary depending on the study, but in general, ethically and legally, the interview shouldn’t start until your participant has signed whatever forms you’ve planned for. Let the forms do their work: don’t project your own discomfort onto the participant by over-explaining the contents of the form. I prefer to hand over a pen and the forms and then sit quietly (or prepare my surroundings) while she reads it over. Defensive nattering (“Ha, ha, this won’t end up on YouTube”) undercuts the document’s clarity and raises concerns that the participant might not even have. Start setting up the video camera or getting your field materials ready rather than watching her.\n\nSometimes the people who join me in the field will try to fill these initial moments with small talk that can inadvertently transition into some of the interview content itself. The participant—without a clear sense of the process—may start offering up opinions and details. Agree ahead of time with your colleagues not to let the small talk turn into questioning before you have the signed consent, and before you have your video camera (or other recording media) turned on. Otherwise, you’re going to have to ask those questions again. Small talk is a lovely lubricant, but keep it at small talk—discuss the weather, or how your day is going, but don’t start asking questions about artifacts in the environment or how long she has been doing her job.\n\n# Restating Objectives\n\nThis is the point at which the interview itself really begins. Thank the participant for taking the time to speak with you, and at a high level, tell her what this is about. This is an early and important chance for you to speak using her terminology, not yours. Depending on how her participation was secured, someone may have told her something about why you are doing this and what is being asked of her. If that someone wasn’t you, you don’t really know what was said. Even if it was you who spoke with the participant, you don’t really know what she took away from the conversation.\n\nIt’s okay to describe your work as “market research” if that’s the most understandable way for her to know what you are doing. The differences between user research and design research and market research do not matter to her!\n\n74 Chapter 5\n---\nI refer to our process and objectives at a high level: “We’re working for a technology company, and we’re out talking to a bunch of different people about how they are using their laptops.”\n\nI sometimes acknowledge the recruiting process explicitly. Depending on the topic, it may have been very clear to the participant by the end of the screening interview what it was we were interested in, saying, “You probably know from the questions that we were asking when you talked with…that we’re interested in…” or “I don’t know how much you know about what we’re doing. I know you answered a lot of questions about…”\n\nLet the participant know what to expect by giving a thumbnail outline of the process: “We’ll take about 90 minutes with you. We’ve got a bunch of questions to ask to start off, and then later it’d be great if you can show us the warehouse,” or “Let’s start here with some discussion and then we’ve got something we’d like to show you and get your feedback.” If they have any concerns (“I have to stop at 2:15 to go pick up my daughter”), then these should come up right away, and you can adjust your process, timing, or clarify your expectations. This has the additional benefit of reminding your client (who maybe isn’t as prepared as you’d like) what is going to happen.\n\nEngage your participant: “Do you have any questions for us right now?” If she doesn’t have questions, keep moving, because even though you’ve told her that you have specific questions for her, a participant may feel that it’s up to her to somehow start telling what she thinks might address your objectives. You may even want to shut down too many detailed questions (“How many people are you meeting?” “What company do you work for?”) by defering those until the end of the interview. In a gentle way, you can use this to further set the tone for you as the leader of the interview.\n\n# NOTE   ADAPTING AT THE OUTSET\n\nOnce, in interviews with high-powered fast-talking finance professionals, I found myself getting through about half of these first few sentences before they verbally brushed past me and launched into their complaints about our client’s product (something we were all well aware of and not at all focused on for these interviews). Because of the difficulty of access to these customers (who were basically doing the interview as a favor), they didn’t seem to have well-managed expectations about our goals. Eventually, I just turned this part of the interview over to them, kicking off by asking, “Well, before we start, why do you think we’re here?” Inevitably, they politely raged about their current frustrations until I could interrupt with “Actually, we know that’s important, but that’s not what we’re hoping to talk about today.” It was not an orthodox way of starting the conversation, but given the type of people I was meeting and the context of their frustration, it was an effective adaptation.\n\n# Key Stages of the Interview\n\n75\n---\n# Unstructured Fieldwork\n\nby Julie Peggar\n\nJulie Peggar is an ethnographer, chief storyteller, and president, Gaze Ethnographic Consulting, Inc.\n\nI don’t conduct interviews.\n\nIn my design-oriented working world, interviews form the basis of most research. For me, this hasn’t always been the case. I come from a more traditional ethnographic background, one in which interviewing is merely a by-product of being in a situation, rather than the primary reason for the visit. When I design a study, I try to avoid formal, stand-alone interviews as a part of the process. Instead, I ask what phenomenon we’re trying to understand, where I would have to be to see it in action, and who the people might be who can get me there. I privilege observing and participating over asking and telling. A successful field visit is one in which, at the end, the participant feels like they’ve made a new friend rather than like they’ve just been interviewed.\n\nWhen I first meet participants, they are often curious about what I do, who I am as a person, and why I’m so interested in the mundane details of hanging out with them while they do the dishes or pick up their kids. In the field, I don’t put on a “working personality.” I’m just me, getting to know them and letting them get to know me back. This give and take helps me blend into the environment more naturally, learning how they would introduce someone new into the family, business, or activity. The process of getting to know one another gives me critical information about the culture and context within which my topic exists. I know I’ve done my job building rapport when we’ve been talking for half an hour and someone says, “I should shut up and stop asking you questions so you can start.”\n---\nalready started. Their interest in my world tells me about theirs. Everything is data to me, not just specific questions about specific objects or actions.\n\nAlthough I have general areas of inquiry that I know I’d like to cover, I don’t put limits on my time with the participant or on what we do in the time that I’m there. I’ve never spent less than an hour and a half on a visit, and my longest single visit (so far!) was 16 hours, although I’ve been based in field sites for months at a time. I allow what we cover to emerge from the day’s activities, and my questions are firmly based in what I see them do or hear them say in context rather than on pre-existing ideas about what might arise. In practice, this works much better than it sounds! If a participant gets a phone call in the middle of a formal two-hour interview about GPS units, asking him to leave immediately and drive from San Francisco to Los Angeles that night, would he ask the interviewer to come with him? As an interviewer, would you go? What if instead of an interviewer, there was someone just hanging out and spending the day with you, who has as much time as it takes for you to teach them about your GPS unit? Would you ask then?\n\nMy research assistant and I were hanging out in San Francisco with a comic, learning how he uses his GPS to get to new venues. At some point during the evening, he got a call about a booking in Los Angeles for the next afternoon that he really wanted to do, even though he had to be back in San Francisco that same night. He asked if we wanted to come along...so we stayed with him. We drove down to Los Angeles with him that night in the pouring rain, in his beat-up car with no heater, and windshield wipers that didn’t work, and his bright, shiny, new, expensive GPS on the dash! Then we went to his show the next afternoon and drove back home with him that evening. We certainly got a great idea of what his life is like, about his purchasing decisions and priorities, about the pros and cons involved in using the GPS on a long road trip that included both known and unknown roads, and about how the GPS fit into the overall picture. This was a lot of data that we would have missed out on with a more formal design.\n\n# Key Stages of the Interview\n\n77\n---\n# Kick-Off Question\n\nThis is another transitional moment as you move into the body of the interview and begin to actively inhabit the role of the question-asker. Your intro words—“So, to start”—help move things forward, past small talk and logistics. The first question is usually a simple broad one to set some context. “Maybe introduce yourself and tell us about what your job is here?” It doesn’t matter too much what it is, as you are going to follow up with many more specific questions. The key here is not to start too specifically (“Ahem. Question 1. What are the top features you desire in your mobile device?”), but to be mindful of shifting into the mode of asking questions.\n\n# Accept the Awkwardness\n\nAs you proceed through your questions, you may encounter some resistance. Although many people (especially those likely to agree to participate) will be extroverted and comfortable, some people will be uncomfortable. There’s no formula for how long it takes people to get past discomfort. Some people will get there with you in a few minutes, whereas others may take an hour. Sometimes (rarely, in my experience), they’ll never reach that point. This discomfort presents itself in subtle ways; rather than frowns and squirming, you may observe stiff posture and clipped deliberate responses. They may fend off your questions (while seemingly answering them) by implying that those are not normal things to be asking about, or providing little or no detail about themselves, describing their behavior as “you know, just regular.”\n\nYou may have to identify your own feelings of discomfort to know when you’re in this stage. If you feel like you don’t have permission to keep going, or that this person doesn’t really want you there, you are in this stage. First, you have to accept this as awkward. It’s not the worst thing in the world to be conversing with someone and feeling ill at ease. You aren’t in physical peril; it’s just an inner feeling. Let it happen, but don’t let it define you. Listen to the feeling and set it aside. Now give your participant plenty of ways to succeed. Ask her easy questions, keeping the inquiry factual, straightforward, and simple. This isn’t the time to ask challenging questions or to bring out props or stimuli. Be patient and keep asking questions and keep accepting, acknowledging, and appreciating her responses. Your own comfort (or discomfort) will come through and contribute to the tone. If you’re following your field guide linearly, you may get a good portion of the way through in a short time and begin to feel some panic about the amount of questions you’ve come with. Just stick with it; the remaining questions will take longer to get through (and will generate more follow-up questions, too).\n\n# Chapter 5\n---\n# The Tipping Point\n\nAlthough I can’t predict when it will happen, there’s often a point when the participant shifts from giving short answers to telling stories (see Figure 5.4). Whether or not it’s an actual moment where the answers get longer, there is a point where you realize that you’ve arrived at a high level of rapport and the tenor of the exchange is different. In all likelihood, by the time you have that realization, you’ve probably been crossing back and forth between short answers and stories. Even if you do notice more short answers, you are on your way, so just stick with what you’ve been doing.\n\n# FIGURE 5.4\n\nYou can see where this hypothetical interview tips from questions and answers into stories.\n\n# Key Stages of the Interview\n\n79\n---\n# Reflection and Projection\n\nThe deepest rapport comes when the participant has spent enough time immersed in the topic in a supportive and exploratory fashion. By this time, you’ve presumably captured many of the details around process, behaviors, usage, and so on, and are ready to move into the higher-level part of the inquiry. Now your participant is thinking about the big picture. Her responses drift into sweeping statements about herself, her goals, her dreams, her past, the future, our society, and so on. This is the type of thing that varies across cultures. Anecdotally, I suspect this may be a more American characteristic than, say, British. This can be the most fun part of the interview; it’s certainly the most inspiring. You are now fully drawn into her world, and she is painting a detailed picture of what lies beneath or what lies beyond.\n\nJust because people are speaking about a future (say, how mobile phones will change their relationships) doesn’t mean it’s an accurate prediction. That’s not the point of the question; it’s what these predictions and reflections reveal. These parts of the interview often produce phrases or ideas that the field team will continue to repeat and go back to as they distill complex issues into visionary notions.\n\n# The Soft Close\n\nAssuming that your participant isn’t running off to another appointment, the winding-down of the interview can be a soft process. Your hard cues (thanking her, handing her the incentive, packing up your stuff, standing up) may not mean she is going to stop talking. Physicians and therapists are familiar with the “doorknob phenomenon,” where crucial information is revealed just as the patient is about to depart. So consider keeping your recording device on, even if it’s packed up. Even as you are heading to the door, the interview may resume, at the participant’s initiation. Or you may see something in the environment to ask about. Keep your eyes and brain in interview mode until you are fully departed. Even if you are tired and ready to leave, stifle the inner “Oh, there’s nothing here” voice that wants you to pull the plug. Stick with it a couple of minutes more. Those may be the bits of recorded data that pull the whole project together for you in the analysis phase. You don’t know at this point!\n---\n# Summary\n\nAlthough interviews are all wonderfully unique, they tend to follow a consistent pattern. Each stage requires specific tactical preparation or responses from you, the interviewer. With experience, moving through the different stages will become second nature.\n\n- When you first come in, set up your seating so the participant can easily maintain eye contact with all interviewers. Use just enough small talk but don’t get bogged down in chat. If you are offered a drink, feel free to accept it.\n- If you are joined by colleagues or clients who aren’t skilled at interviewing, manage their participation by giving them tasks (for example, photographing the interview) or by briefing them on when to ask questions and what kind of questions they should be asking.\n- Start with a general, easy question (such as asking the participant to introduce herself). Ideally, the rest of the interview just flows from there as follow-up questions.\n- If your participant exhibits discomfort, you can choose whether or not you feel discomfort yourself in response. If you feel uncomfortable, you should find a way to accept that feeling as just a feeling and move forward.\n- People will respond with short answers at first and will eventually reach a point where they are telling stories. You can’t predict how long it will take to reach that point, but that is the goal.\n- Remember the “doorknob phenomenon,” where people suddenly open up as the session ends. Try to keep recording until you’re out the door.\n\n# Key Stages of the Interview\n\n81\n---\nNO_CONTENT_HERE\n---\n# CHAPTER 6\n\n# How to Ask Questions\n\n- Silence Defeats Awkwardness &nbsp;&nbsp;&nbsp;&nbsp; 84\n- Managing the Flow &nbsp;&nbsp;&nbsp;&nbsp; 86\n- Getting to Even More of the Answer &nbsp;&nbsp;&nbsp;&nbsp; 87\n- Managing the Ebb and Flow of the Interview &nbsp;&nbsp;&nbsp;&nbsp; 94\n- Embracing Your Participant’s Worldview &nbsp;&nbsp;&nbsp;&nbsp; 96\n- Summary &nbsp;&nbsp;&nbsp;&nbsp; 103\n---\nSo there you are in “the field,” that coolest of phrases that means that tenance shed, copy center, or other unlikely environment. As you get down to business, your printed copy of the field guide is gripped tightly in your sweaty paw. All your objective-setting, question-wordsmithing, and other planning is captured in 11-point type on these precious four sheets of paper.\n\nNow, set it aside.\n\nLeading the interview successfully comes down to you. Go ahead and refer to the field guide as you need to, but don’t let it run the interview. It’s not a script; it’s only for reference purposes. If you get stuck about where to go next, that’s when you pull it out and scan through the pages. Despite your planning, the interview probably won’t unfold the way you anticipated. If it does, perhaps you aren’t leveraging the opportunities that arise. If you’re a novice interviewer, you’ll probably lean more toward the guide than improvisation. Similarly, if you’re at the very beginning of a study, you should rely more on the guide than you will once you’ve learned from a couple of interviews.\n\n# TIP\n\nHOLD ONTO YOUR LOOSE-LEAF\n\nKeep your field guide in a portfolio, a folder, a sheaf of papers, a notebook, or something else. You’ll be better off if the guide appears to be put away when you aren’t using it. Early on I did an interview with the field guide held out in front of me as my only bit of “business.” At one point, my participant snatched it from my hands and said, “Okay, what else do you wanna know?” Although this is unlikely to happen often, it served as a good lesson for me to tote my paraphernalia in a more professional (and protected) manner.\n\ntoday your assignment is to talk with a stranger in her kitchen, main-\n\n# Silence Defeats Awkwardness\n\nAfter you ask a question, be silent. This is tricky; you are speaking with someone you’ve never spoken to before. You are learning about her conversational rhythm, how receptive she is to your questions, and what cues she gives when thinking about an answer. These tiny moments—from part of a second to several seconds—are nerve-wracking. One way a novice interviewer tries to counteract nervousness is by preemptively filling the silence. So the interviewer asks long questions. What he wants to know is, “What did you have for breakfast yesterday?” but the novice stretches the question out so as to delay that moment where the question is done, and he is forced to await the answer (or some awful unnamed fate). The question then becomes “What did you have for breakfast yesterday…was it toast or juice?” The novice interviewer is suggesting possible responses, and his interviewee is just\n\n84 Chapter 6\n---\nthat much more likely to work within the interviewer’s suggestions rather than offer up her own answers. In fact, what the novice interviewer probably asked was, “What did you have for breakfast yesterday? Was it toast, or juice, or…?” You can hear the novice interviewer actually articulate the ellipsis, as a descending, slowly fading “Rrrrrrrr?” That trailing sound is the last gasp at holding onto the question.\n\nDon’t do this. Ask your question and let it stand. Be deliberate about this. To deal with your (potentially agonizing!) discomfort during the silence, give yourself something to do—slowly repeat “allow silence” as many times as it takes. Use this as a mantra to calm and clear your mind (at least for the moment). If the person can’t answer the question, she will let you know.\n\nAfter she has given you an answer, continue to be silent. People speak in paragraphs, and they want your permission to go on to the next paragraph. You ask “What did you have for breakfast yesterday?” There’s a second of silence, and the person tells you, “I had toast and a bit of yogurt, and then about 20 minutes later, I had steak and eggs.” Our novice interviewer figures it’s time to move on to the next question, asking “Oh, okay. Where did you buy those groceries?” But the best play is to just rest for another beat. Usually, the person will continue. “Well, in fact, yesterday was quite unusual because what I typically do is just have a granola bar, but my sister was coming to visit, and I had to prepare for all of us before she got here.” By simply not asking your next question, you can give your interviewee time to flesh out the answer they’ve already given you. Try to sense when the thread is played out, and it’s time for your next question.\n\n# TIP\n\nPARAGRAPH SPEAK\n\nPeople do speak in paragraphs. You can see evidence of this by looking at an interview transcription. The pauses between blocks of content are interpreted by the transcriptionist as paragraphs.\n\nWerner Herzog’s documentary Grizzly Man tells the story of Timothy Treadwell, a self-professed naturalist who lived in the wilderness to be close to his beloved grizzly bears, only to be mauled to death. There’s a scene in which Franc Fallico, Alaska’s state medical examiner, presents a watch, still in an evidence bag, to Treadwell’s ex-girlfriend, Jewel Palovak. Herzog, holding the camera, cuts between passively observing the dialogue between the two of them and inserting his own questions about her memory of Treadwell (and his girlfriend who died with him). Finally, Fallico has Jewel sign some official papers, and the process is complete. Herzog doesn’t cut and continues to film the two. But nothing is happening! They have uttered their concluding words and smile awkwardly and stare at nothing. Moments tick by and still no cutting. Jewel gives a sharp intake of breath, and Herzog, holding the camera, steps forward. Another moment goes by, and she sobs, breaking down for the first time in this entire sequence. “It’s the last thing\n---\nthat’s left.” Herzog is directing the scene while observing and interviewing. He lets a delicate moment hang uncomfortably, and a devastating emotion emerges. That’s the power of silence.\n\nEven if you don’t feel nervous, you can’t really know what’s going to hap- pen as you ask a question.1 Perhaps your participant will start to answer the question while you are asking it (indeed, you can see this sometimes when the participant’s whole affect changes as he begins to understand the question and his face shifts dramatically as he brings his answer out to the launch pad). Perhaps he’ll be supremely fast-talking2 and whip out an answer the very moment you’ve finished asking it. Perhaps he will wait for you to finish your question and take some amount of time to start speaking, and during that gulf between question and answer he may give you really great “I’m thinking” cues (hand rubs chin, eyes gaze away, lips pursed, and so on). Perhaps he’ll give you a juicy verbal cue, like “That’s a great ques- tion…ummmm….” Or he may simply stare at you, giving no quarter, until he answers. Be prepared for any of these!\n\nWith some participants, it takes me most of the interview to align my pac- ing with theirs. I’m particularly vulnerable to what one might call the Skype effect. When technology (VOIP, Skype, transatlantic cables, satellite transmission, and so on) introduces a small delay in conversation, we get messed up pretty quickly; the pauses we listen for at the end of someone’s speech are not quite in real time and so we start to speak at the same time as the person on the other end of the call. We hear each other start and so we abruptly stop and defer to them. It’s challenging to correct this out-of-phase state. Of course, this happens in person as well, without any technologically introduced delay. Some people just have different natural rhythms. There’s no magic fix, any more than there’s an easy way to successfully talk on the phone when you hear an echo of your own voice. This is stuff happening way below conscious thought, down at the autonomic level. At the very least, be mindful of the out-of-sync phenomenon and try to slow…yourself…down.\n\n# Managing the Flow\n\nAt a high level, most of the interview can unfold naturally from the kickoff question (see Chapter 5, “Key Stages of the Interview”). Strive to weave the questions from your field guide into follow-up questions. Although it won’t cover the entirety of the interview, pursuing this ideal will help develop\n\n1 Detailed analysis of “turn taking” is part of conversation analysis, a subdiscipline of linguistics. Experts explore how intonation, pausing, and body language inform the interaction between speakers. Unlike your work as an interviewer, conversation analysts don’t do their work in real time.\n\n2 A wonderful example is the rapid-fire dialogue between Hildy and Burns in the 1940 Howard Hawks film His Girl Friday.\n---\nrapport, demonstrate listening, and create an interaction that feels more conversational than interrogatory.\n\nNot everything can be a follow-up. Some threads run out of steam, or sometimes you need to deliberately change the discussion in order to dig into a specific area of interest. The guiding principle here is to signal your lane changes. Compare these two snippets of a hypothetical interview:\n\n# Version 1\n\nQ: And what happened when you downloaded the updated version of the iPhone app?\n\nA: (laughs) It installed instantly!\n\nQ: Where do you keep your used oil drums?\n\n# Version 2\n\nQ: And what happened when you downloaded the updated version of the iPhone app?\n\nA: (laughs) It installed instantly!\n\nQ: Okay, this is great. I’m just going to shift direction here. Maybe you can tell us, where do you keep your used oil drums?\n\nIn the second snippet, the deliberate, explicit turn signal acknowledges the most recent answer and points the way toward the next, otherwise discontinuous, topic for discussion. As a rule, if your question isn’t fairly obviously a follow-up question, you should preface it with some transitional words.\n\n# Getting to Even More of the Answer\n\nHere’s some bad news: you won’t get the answer to your questions just by asking. If only you could simply utter the question and wait while the person gives you all the information you need, and then move on to the next question on your list. That’s just not how real interviews go. For most threads in most interviews, you need to use a series of questions to get to the information you want. It’s not that people are being difficult; they just don’t know what it is that you want to know. They interpret your question in a certain way and do their best to answer it. But it’s up to you to help them to tell you what you need to learn about.\n\nWhen you listen to your participant answering your question, be vigilant. Do they appear to have understood what you intended by the question, or have they gone somewhere else with it? Their interpretation may be more revealing than what you intended, so you may just let the conversation go down that path, or you might want to wait for an appropriate time to redirect back to the topic you were initially interested in.\n\n# How to Ask Questions\n---\n# Silence Abroad\n\nby Lynn Shade\n\nLynn Shade is a freelance UX designer and researcher who previously worked at Claris, Apple, and Adobe. She grew up in Japan and is bilingual.\n\nOver the course of my career, most of the user research I’ve done has been in Asia, in large part in Japan, where I happened to grow up and where software companies used to invest in efforts to understand market needs. Years ago when working for Apple, I accompanied a Dutch colleague, Anke de Jong, to New York for field research for new laptop models. Trained as an industrial designer, Anke designed at the intersection of hardware and software. This made her research interesting in and of itself, but what I remember most vividly from that trip was being occasionally astonished at her use of silence to impel further comment.\n\nThis technique wasn’t for the most part necessary since as compared to Asian participants, these participants talked a lot. Admittedly, we were interviewing New Yorkers, but the willingness and eagerness of American study participants to express themselves verbally was the source of considerable discussion and hidden envy among myself and my Japanese colleagues. In Silicon Valley at the time, the solo-participant-in-a-lab Talk Aloud methodology was enjoying great popularity as the de-facto usability testing methodology. Upper management expected this quick lab technique would be used to inexpensively confirm U.S. results in other countries. Doing research in Japan wasn’t so easy. Beleaguered by the all-too-common silent-ish Japanese participant, Japanese colleagues and I would discuss endlessly and even devote entire conference presentations to how to draw our quiet participants out, and what magic combination of factors might encourage them to speak.\n\nHowever, even Americans can go silent after answering a question. If this happened, Anke would deliberately not comment, waiting calmly and putting what seemed to me subtle stress on the interviewee. The first few times I observed this, the Japanese part of me would grow slightly anxious as the silence hung in the air for a half-beat too long. Invariably, the interviewee would break it. The additional information was often valuable; they’d clarify or amend, or start a new topic with a new observation, or make a connection that offered interesting insights. The interviewees, while feeling the need to break the silence, seemed not to mind. They often became very talkative, responding to the silence as the encouragement it was.\n\nUsing silence as a mechanism to elicit participants to talk is a common technique, but it stuck in my head. Over the years as I continued doing research in Asia, I thought quite a bit about that New York experience and silence in general. Silence in user research in Japan is so important. We allowed lots and lots of room for it. There have been entire books written on Japanese silence, but for the purposes of this sidebar I’ll summarize Japanese conversational silence into three broad categories: setting-the-stage silence, effort silence, and failure silence.\n\n88 Chapter 6\n---\nSetting-the-stage silence: Along with body language, setting-the-stage silence is a spot of silence from both sides to indicate readiness for a shared experience. Both parties work to set the mood for a productive conversation, and some of this work is done with silence. This silence takes place here and there during initial greetings, along the way as topics change, and is most obvious when greetings wind down right before initiating the topic at hand. Lest this paint the wrong picture of some prolonged zazen meditation-like situation with a temple bell tolling in the background, let me hasten to add that those setting-the-stage silences can be long or quick, depending on personalities. Fairly typical in lots of situations is saying the equivalent of “um” with a trailing silence and the other party nodding, again followed by a bit of silence. Setting-the-stage silence is created partly because silence is considered a more deeply shared experience than talking—a version of that exists in many cultures—and partly showing mutual respect and mutual humility for the other’s expertise. The interviewer’s task here and during the interview is to match the interviewee’s natural response and thought pace, allowing time for both sides to ponder questions.\n\nEffort silence: During the interview, silence indicates making an effort to help the cause along. The interviewee will be silent to show they’re thinking the topic over carefully and showing a desire to contribute to the interviewer’s goal. The interviewer will be silent to show they’re thinking the subject’s response over carefully and showing respect for the effort the interviewee made in answering. All parties may be silent when faced with a very difficult or complex question to show respect for the difficulty by giving it due diligence and giving the question and the other parties room to think. Essentially, Japanese people are being conversationally encouraging by using lots of silence.\n\nFailure silence: The tones of silence to watch for are silence indicating resistance and silence indicating confusion. If the interviewees don’t feel knowledgeable enough or qualified to answer the question, they’ll fall silent. Likewise, when confused by a question and unsure, interviewees can fall silent. This “falling silent” has its own tiny cues and must be broken by interjections from the interviewer. If the failure silence is overly prolonged, the interviewee will start experiencing the stress of failure. This is why the waiting-without-help technique used so successfully in New York wouldn’t work in Japan, at least not without considerable modification.\n\nThe designer Kenya Hara has a rather lovely section in his book White on the meaning of emptiness in the Shinto shrine architecture. He describes how the space created by tying the tops of four pillars with ropes creates emptiness that has potential as a vessel to receive thoughts and feelings. He later goes on to tie silence to emptiness and suggests that silence has the possibility to enrich mutual comprehension. Building on this, it’s hard to imagine silence in Japanese conversation as being created simply to facilitate a means to a certain end. Rather, successful Japanese silence is a roomy empty space that, created by both parties, helpfully exists to allow communication.\n\nHow to Ask Questions 89\n---\nIs there more that you need to probe further on? People sometimes speak in coded terms: “…this was before the earlier situation that changed my purchasing….” The “earlier situation” may be something they are uncomfortable revealing, at least for now, or it may be that they aren’t sure if they have your permission to share the specifics of the “earlier situation.” Even if you don’t follow up immediately, it may be a topic you want to return to.\n\nAre you asking the question in a way they can answer? In a study about customer service, a participant complained passionately about the poor telephone service he received from a retailer. I asked him how the service might be different, but he could only speak about the current situation. Eventually I shifted my tactics entirely, and we role-played an imagined future version of the telephone interactions. My follow-up questions focused on uncovering the specific details that made his scenario a desirable one.\n\n# A Palette of Question Types\n\nThe field guide is your (highly idealized) hypothesis for how you will ask questions. But really, you’ll spend much of your effort in the interview digging further and giving your participant the best opportunity to share deeply. You need a broad set of question types in order to make this happen. Here are some examples to get you started:\n\n# Questions that gather context and collect details:\n\n- Ask about sequence. “Describe a typical workday. What do you do when you first sit down at your station? What do you do next?”\n- Ask about quantity. “How many files would you delete when that happens?”\n- Ask for specific examples. “What was the last movie you streamed?” Compare that question to “What movies do you stream?” The specific is easier to answer than the general and becomes a platform for follow-up questions.\n- Ask about exceptions. “Can you tell me about a time when a customer had a problem with an order?”\n- Ask for the complete list. “What are all the different apps you have installed on your smartphone?” This will require a series of follow-up questions—for example, “What else?” Very few people can generate an entire list of something without some prompting.\n- Ask about relationships. “How do you work with new vendors?” This general question is especially appropriate when you don’t even know enough to ask a specific question (such as in comparison to the earlier example about streaming movies). Better to start general than to be presumptive with a too-specific question.\n\n90 Chapter 6\n---\n# How to Ask Questions\n\n- Ask about organizational structure. “Who do the people in that department report to?”\n\n# Questions that probe what’s been unsaid:\n\n- Ask for clarification. “When you refer to ‘that,’ you are talking about the newest server, right?”\n- Ask about code words/native language. “Why do you call it the bat cave?”\n- Ask about emotional cues. “Why do you laugh when you mention Best Buy?”\n- Ask why. “I’ve tried to get my boss to adopt this format, but she just won’t do it….” “Why do you think she hasn’t?”\n- Probe delicately. “You mentioned a difficult situation that changed your usage. Can you tell me what that situation was?”\n- Probe without presuming. “Some people have very negative feelings about the current government, while others don’t. What is your take?” Rather than the direct “What do you think about our government?” or “Do you like what the government is doing lately?” This indirect approach offers options associated with the generic “some people” rather than the interviewer or the interviewee.\n- Explain to an outsider. “Let’s say that I’ve just arrived here from another decade, how would you explain to me the difference between smartphones and tablets?”\n- Teach another. “If you had to ask your daughter to operate your system, how would you explain it to her?”\n\n# Questions that create contrasts in order to uncover frameworks and mental models:\n\n- Compare processes. “What’s the difference between sending your response by fax, mail, or email?”\n- Compare to others. “Do the other coaches also do it that way?”\n- Compare across time. “How have your family photo activities changed in the past five years? How do you think they will be different five years from now?” The second question is not intended to capture an accurate prediction. Rather, the question serves to break free from what exists now and envision possibilities that may emerge down the road. Identify an appropriately large time horizon (A year? Five years? Ten years?) that helps people to think beyond incremental change.\n---\n# She Blinded Me with Silence\n\nA while back I was in my first public improv show. We were all amateurs, some with many years of experience, others with a year or less (such as me). In this performance, we started each scene with one idea (often from the audience) and proceeded with some sort of structure. What often happened was a scramble to move the idea forward—everyone speaking at once, with too many ideas “thrown” in the first few moments to ever really solidify into a great scene. Have you ever seen 8-year-olds play soccer? The ball and both teams are a whirling cloud that moves up and down and across the field like the Tasmanian Devil. That was us.\n\nBut then the next night I saw the Kids in the Hall—a comedy troupe that has been performing together for a very long time. After the scripted material had finished, the audience was clamoring for more. In advance of the encore, they all walked on stage and thanked us, and then improvised a few jokes before heading off stage to prepare for the encore. All five of them managed to hold the stage coherently. Not everyone spoke at equal length in those few minutes, but at no point did any of them speak on top of another. It came off as natural and easy, but it was really quite incredible.\n\nWhere they succeeded, and we didn’t succeed as well (for there are no losers in improv) was in allowing for silence. Each Kid in the Hall was silent for most, if not all, of their unscripted segment. What a powerful contribution they made by not speaking. Isn’t that a strange statement to make? A comedy performer contributed by not speaking. How can that be? We tend to expect performance to be the explicit utterances, not the space between them.\n\nThere’s a lot that can happen without verbalization—posture, gestures, breath sounds, eye gaze, facial reactions, and more. The Kids in the Hall were doing all those the entire time—and they were paying attention to each other. When they were silent, they were actively silent; they were sending and receiving information.\n\n# Chapter 6\n---\nThis behavior is crucial when interviewing users. I would estimate we speak as little as 20 percent of the time. Yet the interviews are directed and controlled by the interviewer. Nodding, eye contact, and body language all support the respondent in providing detailed information.\n\nOf course, there is often more than one researcher on hand. If the first ethnographer remains silent, waiting for the respondent to continue, the second interviewer must recognize that, and also listen silently, rather than using the opening as his chance to interview. This collaborative use of silence is something the Kids in the Hall managed, and my improv group did not.\n\nWe experience these same challenges in more familiar work settings: brainstorming, meetings, and so on. We work in a society that judges us primarily by our own contributions, rather than the way we allow others to make theirs. If the collaborative silence is not a shared value in a group, there can be a real challenge for those who default to listening, not speaking. We’ve learned how to give credit to those who utter the pearls, but we don’t know how to acknowledge the value of those who choose their moments wisely, who allow others to shine, and who ultimately enable those pearls.\n\nIn a 2002 episode of The Simpsons (DABF05, “Jaws Wired Shut”), Homer’s jaw is wired shut. He is physically unable to speak. He does become a better listener, but most interesting are the positive qualities the people in his life project upon him. Simpsons’ Executive Producer Al Jean said: “When Homer gets his jaw wired shut, it makes him into a really decent, wonderful human being.” I don’t know if Al Jean is getting post-modern on us, but Homer’s internal change, through his silence, was fairly minor compared to the differences that other people perceived. For even more on this theme, check out the book Being There by Jerzy Kozinsky (or the film with Peter Sellers).\n\nHow to Ask Questions\n---\n# Managing the Ebb and Flow of the Interview\n\nAs a plan for an idealized interview, the field guide is, of course, linear. But the active planning process you go through during the interview is actually more of a tree (see Figure 6.2).\n\nThis is a fairly typical snippet of an interview. It’s what is going on for the interviewer that deserves some special focus here, though. As the participant is explaining in his natural manner, the interviewer is identifying other questions to ask. At the first pause, the interviewer has at least two new questions (beyond what’s already in her interview guide), but the questions encourage the participant to continue by responding with “Okay.” As the participant continues, she might identify another two topics to be explored. Maybe those topics are included in the interview guide, but probably they aren’t.\n\nSadly, most of us are constrained by the linearity of time. We can’t clone ourselves and follow each thread in parallel universes. We have to stick with our own reality.\n\n# FIGURE 6.2\n\nEven in this tiny excerpt of an interview, the interviewer has to track a great deal of information and make choices about where to go next.\n\n94 Chapter 6\n---\nIn addition to watching the clock, maintaining eye contact, building rapport, and so on for most of the interview, your job also includes managing this tree. Here are some coping techniques:\n\n1. Wait patiently until these threads come up again in conversation organically, without you having to ask. Often they do.\n2. Jot quick notes on your field guide about what you want to come back to, so you don’t forget.\n3. Prioritize (or perhaps triage) based on your research objectives. Although something that seems irrelevant does often prove to be insightful, you have to choose. So be opportunistic and choose what you think is going to bear fruit for your area of inquiry.\n4. Triage based on what makes the best follow-up, in order to demonstrate listening and further the rapport. Come back to a topic later if it still seems important; refer back to the participant’s previous statement in order to establish continuity. (“Earlier you mentioned using PayPal. I wanted to ask a bit more about that.”)\n\nTIP GOING WITH THE FLOW\n\nThe complexity embedded within the exploding questions tree might suggest that interviewing really sucks. In fact, dealing with these challenges can take you to someplace very creative. Mihály Csíkszentmihályi has articulated the psychological notion of flow— as “the mental state of operation in which a person in an activity is fully immersed in a feeling of energized focus, full involvement, and success in the process of the activity.” This certainly happens to me in interviews. My brain is firing on all cylinders with all the responsibilities I’m managing, and yet I can feel myself slow right down. It’s a feeling in both my brain and my body, which compares to the familiar special effect, often seen through the view screen when a spaceship enters hyper-space and the stars stretch out from points into lines. In this calmness, I’m not ignoring the complexity; instead, I’m somehow above it. Things become very quiet in my head, and I can feel myself riding on top of the challenges of the interview. It’s not boredom; it’s a very engaged feeling. It’s the opposite of the chicken-sans-head feeling you might imagine the demands of an interview could lead to. This flow state both creates and is fed by the imperative to keep silent, keep myself out of the equation, and let the experience breathe, while still being the most creative and insightful time during fieldwork.\n\n3 http://en.wikipedia.org/wiki/Flow_(psychology)\n\n# How to Ask Questions\n\n95\n---\n# Embracing Your Participant’s Worldview\n\nIn Chapter 2, I introduced the principle of embracing how participants see their world. That principle informs the entire approach of a study, but it becomes vital once you are with that participant and asking questions. In this section, you’ll see how to ensure that your questions make it clear to both you and your participant that you are curious, even hungry, to understand their worldview.\n\n# Use Their Language\n\nYears ago I was working with a client on understanding the opportunities for a new home entertainment technology, targeting everyday consumers. We were in the family’s home to speak with them about their current gear and how they were using it.\n\nIn this house, the father had put a lot of effort into making product choices that would enhance their family’s time together. He was visibly (and appropriately) proud of their setup. As he explained the choices he had made, he explained how he didn’t want a DVR, because of his concerns over privacy. He referred to the leading DVR brand, TiVo, but mispronounced it as “Tye-vo.”\n\n“I took a look at Tye-vo, but didn’t want anyone paying attention to what we watch the way Tye-vo does so I decided that Tye-vo wasn’t for us.” As with many stories, this one has become richer in the retelling, but you can imagine how my client, originally an engineer, quietly winced each time the brand name was misspoken. I could sense his winces without turning my head to look at him.\n\nThe interview continued and when it was appropriate for me to ask follow-up questions about DVRs, I referred to it as the participant did—as Tye-vo. But later, when the client asked some of his own questions, he pronounced TiVo correctly as “tee-vo.” This was a small, yet dramatic moment in the interview. This proud man was revealed to be, well, stupid, in front of his family, in his home. Despite being a self-proclaimed expert in these types of products, he was indirectly corrected and thus lowered in status. You could immediately feel the power dynamic in the room shift; now we were the experts, and he was just some dude. Of course, that’s not the situation I was hoping for!\n\nMy client was a wonderful, sweet, caring person who would never dream of making this participant feel that badly. But it would have never occurred to him to say something the “wrong” way. Yet in this situation, it was right to be wrong. It wasn’t our role to be right.\n\nDesign researcher Todd Hausman talks about his work on an instant messaging product, when research participants would refer to “emochicons.” In reflecting back their pronunciation, he was viscerally reminded of the risk in making assumptions about users.\n---\nLetting go of being right is something to pay attention to in most interviews; it doesn’t have to be as glaring a situation as a participant’s mispronunciation of a technology or a brand name. It could be in the description of a part, a process, or just about anything. Even if there’s not an obvious “right” or “wrong” way to refer to something, you must defer to the participant’s way.\n\n# TIP\n\nWHEN IT’S AWKWARD TO USE THEIR LANGUAGE\n\nIt can be challenging to use someone else’s terminology and feel as if you are being authentic. (After all, you are trying to establish rapport, and being fake would destroy that.) Participants in a study told us about a new technology that was being developed at their organization, called an aggregator. Due to its troubled history, it was referred to colloquially as an “aggravator.” This term was used more frequently in the interview than “aggregator.” But it wasn’t comfortable for our interviewer to ask about the “aggravator.” They didn’t really have permission from the group to use their insider language, and they ran the risk of coming off as flippant or minimizing the seriousness of the development effort. They resolved it by acknowledging the participant’s language and their own reluctance to use the same phrase. Going a little meta (such as “I want to ask about what you like to call the aggravator”) enables the interviewer to point to the language directly, acknowledging the participant’s terminology, as well as referring back to the previous conversation about the terminology itself. When the words being used become a topic in the interview, pointing to the words in this manner is appropriate.\n\nIn one project, a research participant referred to a technology platform their firm uses. Our client, perhaps trying to demonstrate insider status and reassure the participant that this interview was valid, asked about the platform but used an abbreviated form (in essence, a nickname) of the platform name. The participant responded by hesitantly using this nickname and then immediately correcting himself and switching back to the full name that he had originally used. If my client simply had to introduce his alternative name for the technology, he could have asked “Oh, when you say [platform name], I wonder if that’s the same thing I’m used to calling [nickname]?” In this case, there would be no ambiguity, and he would not in any way be trying to clarify, so the better course of action would have been to build rapport by accepting the terms the participant was using rather than trying to demonstrate credibility.\n\n# How to Ask Questions\n\n97\n---\n# Assume Your Participant Makes Sense\n\nYou may hear and see apparent contradictions. People may tell you they value cleanliness and then open a bedroom door to reveal piles of dirty clothes on the floor. Or people may express a preference for a certain type of feature and then reject an example you show them. Although you might find this frustrating, try to see it as an opportunity. Your interpretation of “cleanliness” may be oversimplified. The social performance of valuing cleanliness may be entirely separate than the act of maintaining cleanliness. Your framework for what that feature is doing may not align with the participant’s framework. These seeming disconnects are indications that you need to explore further. This isn’t about calling out hypocrisy; it’s about probing to understand.\n\n# Don’t Make Your Questions Pass/Fail\n\nA client joined me in the field, arriving at our pre-meeting with mere moments to get acquainted and review the approach. This was not an ideal arrangement (and a good learning moment for me) and led to a dysfunctional dynamic. Her abrupt questions for our participant were presented more as tests than as inquiries. She asked our participant if she knew what a USB cable was (see Figure 6.3), phrasing it as a challenge rather than as something she was curious about. Later, she presented her framework for the digital media functionality she was charged with designing and asked the participants if they understood the difference between the various terms used in the framework. As an exercise, imagine asking someone if they know what a USB is. You might even try this out loud. First, ask in a gentle, curious fashion. Next, ask in a judgmental critical tone. In this case, my client was somewhere in between, but far too close to the critical side of the continuum for comfort. The participant became confused and very uncertain about how to talk about her usage since these terms were indeed unfamiliar. It’s good to understand if the language you are using internally aligns with the way people are really talking, but that doesn’t mean you need to thrust your terms at people and test them on whether or not they can explain them.\n---\n# FIGURE 6.3\n\nDo you know what a USB cable is?\n\n# Don’t Presume They Accept Your Worldview\n\nI interviewed a young man who had gone through a significant personal change, first living abroad as a successful professional, and then returning to California to live in his parents’ home to go back to school. At one point in the interview, my client commented to our participant (let’s call him Keith) about the differences in value systems between “Old Keith” and “New Keith.” Even though this is not a framework that Keith had explicitly articulated to us, he said, “Right.”\n\nAfter a few minutes of further dialogue, I decided it was time to intercede, and I asked Keith what he thought about this idea of the old versus new Keith. Given the chance to expound, Keith told us, “I don’t really see it.” At no point had Keith told us that he had old and new versions of himself. Keith was always Keith. My client was synthesizing on-the-fly and had imposed his model on Keith. And what did Keith do? He agreed. Of course he agreed! Why should he argue about something like that? Just because a framework isn’t rejected by the participant doesn’t mean it is accurate!\n\nHow to Ask Questions 99\n---\n# Good and Bad Examples from Marc Maron\n\nIn an episode of Marc Maron’s WTF podcast, he spoke with 85-year-old comedy legend Jonathan Winters. Within this interview are several examples that embody the points I’ve made throughout this chapter—getting to more of the answer, asking clarification questions, managing the ebb and flow of the interview, and not presuming that the participant accepts the interviewer’s worldview.\n\nEarly in the interview, Maron asked a fairly direct question:\n\nYou were in the Marines. Where were you?\n\nWinters answered:\n\nI went in at 17. The Japanese were way down on the list…Pearl Harbor. I didn’t get along with either parent; they were divorced; it didn’t seem to matter; they didn’t like me.\n\nHis truth-in-comedy comment about his parents seemed to be a non-sequitur, and he continued on about his parents and some of his time in the Marines for more than three minutes (finally explaining that he was on an aircraft carrier, which answered Maron’s question), before concluding with:\n\nBut I enjoyed the Marines…I only made corporal, but that’s okay…\n\nMaron picked up on the earlier non-sequitur and asked:\n\nWas it a way to get out of your parents house?\n\nAnd Winters quipped back:\n\nYeah, yeah, they were eager to sign. I never saw two people sign papers so fast!\n\n4 Hear the whole episode at http://rfld.me/QLhHj5.\n\n# Chapter 6\n---\nAlthough the answer to Maron’s question was buried within several layers of stories, Winters only implied his motivation for enlisting. Maron did the right thing and asked his subject explicitly about it. As the interviewer, you want to find out for sure, from the subject’s perspective, rather than leaving things to your own inferences.\n\nLater in the interview, Maron was less successful as an interviewer. Winters described an early job working as a radio DJ. In this job, he eventually got bored and did interviews with himself, playing different characters. Management objected, Winters persisted, and he was fired:\n\nWinters: I did try some more guests and that was the end of that career there.\n\nMaron (laughing, interjected): You had to, though, right?\n\nWinters: I had to.\n\nMaron: Yeah! It felt too good, right?\n\nWinters: It felt good. I did a year there, and then I went to Columbus.\n\nMaron’s interjections reflected his own interpretation: that Winters must have been compelled to continue doing interviews with himself because of how good it felt. Winters never actually said that, but Maron stated it as a fact, where his “right?” was not truly a question but more like a fellow bar patron elbowing you in the ribs while asking you to agree with him. What this transcription failed to capture was the momentum Winters had in telling his story, and even though he agreed with Maron, he was sidetracked from his story and ended up expressing parts of it in Maron’s terms, not his own.\n\n# How to Ask Questions\n---\n# Don’t Enter Lecture Mode\n\nAn alternative title here might be “Sit on your hands!” or “You don’t need to give voice to every thought that comes into your head!” On a project that dealt with online decision support tools, one client, when offered the chance partway through the interview to follow up on the conversation so far, came up with this gem, presented here in sanitized form.\n\nI suppose that seems more like a divergent set of factors informing you versus specific feedback that came from any particular individual source and that served as a guiding factor for decisions for your purchase or not. I’m just thinking that it’s more of a multiple...\n\nAt this point, the participant interrupted the client to tell us more about her decision-making process. Although sharing your forming thoughts can be a method of interrogation, it is a tricky approach, relying heavily on rapport and shared agenda to be effective. That was not what was happening here. The client didn’t really say anything about anything but was just thinking aloud. Although I’m a huge enthusiast for sense making, it would have been fine for the client to have kept this in his head and declined to ask any questions. But, within a minute of the exchange, the emboldened client continued, making declarative summary statements about the utility of a specific type of online tool. His descent into lecture mode was complete; he was not asking questions, but instead was sharing his own beliefs. He had transformed from a listener to a teller.\n\n# NOTE LEARNING FROM MISTAKES\n\nI’m really beating up on “clients” a lot here! But there is no anti-client subtext at all; when you team up expert interviewers (my team) and novices (our clients) you get a glorious supply of illustrative examples. These examples remind me not to do these things; I’m using them to tell you not to do these things, and for both of us to coach our respective clients not to do these things either!\n\n# If You Have to Fix Something, Wait Until the End\n\nIf you are interviewing someone about your product, it will be tempting to help her have the best experience possible. You will invariably watch her struggle to find features, express a desire for something that you know is available, or hear her describe aspects of the product incorrectly. This can be very trying for an interviewer who is also passionate about the product. (Of course you are! After all, you are out in the field meeting customers in order to make the product better!) So how do you deal with this?\n\nDo not jump in and correct or instruct her. This is just like the TiVo example, only more so! You are conducting the interview to learn from this person, so\n---\nthere’s no need to assert your own expertise. In fact, once you do so, you can lose control over the interview entirely, as the participant will simply turn it around and ask you, “Is there a way to do_____? How can I make _______ happen?” Suddenly, your field visit has turned into the world’s most expensive tech support house call.\n\nBy all means, at the end of the interview, as you are handing over the incentive and packing up, take a moment to share anything that you think might help that person. But ask yourself if explaining something is better for you or better for her. Don’t correct her perceptions or terminology if the only outcome is “educating” her. Advocate for her, not for your product.\n\nI led an interview with a fascinating professional who blew our minds with his insights into building up a professional network over decades of his career. As he was showing us how he worked, we saw him complain as he struggled to move the cursor between his two monitors, as the one on the left was set in Windows to be on the right. After we were finished, I offered to fix this, since it was something that came up peripherally in discussion. He was absolutely thrilled and quipped that this bit of support (even more than the incentive, or the tips my clients had given him about how to use their product) made the whole time worthwhile! Hyperbole or not, I was glad to be able to do something nice for him after he had been so wonderful to us.\n\n# Summary\n\nWhen you’re out in the field, actually doing your interview, keep the following in mind:\n\n- Your field guide is a guide. Set it aside until you really need it. Leading the interview successfully comes down to you.\n- Although it’s tricky, ask the shortest question you can, without directing them to possible answers you are looking for. Then be silent.\n- When you move from one topic to another, use transitional phrases such as “Great, I’d like to shift directions now….” or “Let’s go back to something you said before….”\n- Pay attention to whether or not you have received an answer to your question. Be prepared to follow up multiple times using different types of questions.\n- Reflect back the language and terminology that your participant used (even if you think it was “wrong”).\n- If you want to fix something (say, a setting on their software) for your participant, wait until the interview is over.\n---\n\n---\n# CHAPTER 8\n\n# Optimizing the Interview\n\n- Troubleshooting Common Interview Problems  120\n- Interview Variations and Special Cases      125\n- Improving as an Interviewer                129\n- Summary                                     133\n---\nAn interview is an interaction between two humans. Or throw in a colleague and a spouse, and now it’s an interaction between four humans—irrational, emotional, language-using, unpredictable humans. The only one of these four you have any control over is yourself. This is a messy business. There will always be variables and curve balls. This chapter looks at some of the more common challenges that you will face in the field. It also suggests a number of ways to develop your own skills so that you are prepared for future surprises.\n\n# Troubleshooting Common Interview Problems\n\nMany of the situations discussed in this section stem from something that happened leading up to the interview, such as how the participants were recruited. The best troubleshooting approach is to prevent these problems from occurring through proper screening and clear setting of expectations. Realistically, though, they will still come up.\n\n# When the Participant Is Reticent\n\nAre you sure that your participant is holding back? As discussed in Chapter 6, his default demeanor and speaking rhythm may simply be out of sync with yours.\n\nIf you conclude that he is indeed uncomfortable, try to identify the cause and make a change in the way you are handling the interview. You might simply need to accept the awkwardness and be patient with yourself and with him, looking toward a point where he becomes more comfortable. If he is connecting better with one of your colleagues, ask that person to lead the rest of the interview. If there are too many interviewers, ask one of them to step back. If you aren’t giving your participant enough verbal space to reflect and respond, slow down and let him talk. If your participant needs more structure, fall back to straightforward, direct questions.\n\nConsider which aspects of your topic might be making him uncomfortable. Even if an interview doesn’t explore social taboos, you may be tapping into an element of personal insecurity about his job, his competence, his intelligence, and so on. Or you can change the topic, share your enthusiasm for his talent, or reveal something about yourself.\n\nSometimes you might find yourself in a different situation than you had anticipated. For example, an interview with a certain type of professional turns out to be an interview with that person and his manager. If you can’t get the interview you want (perhaps by gently suggesting you interview them each separately), be aware of the dynamics and adjust your questions appropriately. Ask the manager questions about herself or about her understanding of how the work is performed.\n---\nIf all else fails, consider asking your participant outright to identify the source of his discomfort. Tell the participant that this information is important to you and your work and that you are deeply interested, but you are concerned that he isn’t comfortable with the conversation. Ask what would be better, even if it means a different time or a different location.\n\n# When the Participant Isn’t the Right Kind of User\n\nAssuming you’ve screened your subject, you might wonder how that person can end up being wrong for the study. If you are surprised—or even uncomfortable—at how reality differs from what you expected, that’s a crucial insight. But don’t be hasty to dismiss the participant.\n\nIf you’ve taken the time to travel to this participant’s home or workplace, you should complete the interview. Consider what you might do with the 45 minutes you could save by cutting out early and how that stacks up against the possibility that you might learn something by interviewing this person about his experience and perspective. Reset your expectations and see what you can get out of the session. Afterward, revisit your screening criteria. You may have uncovered the fact that a word or phrase in the criteria is being interpreted differently by participants (for example, “late-model car” could mean one thing to your team and another to the people you are recruiting). Also, if you have identified additional factors for the rest of the participants, you might want to rescreen them.\n\n# NOTE\n\n# GETTING THE RIGHT PARTICIPANT AND THE RIGHT CONTEXT\n\nIn several studies, I recruited participants who were users of various devices (like laptops, video cameras, and MP3 players). They had told us they owned these devices and used them for whatever tasks we were interested in. But several times I found myself at the interview, discovering that the device in question wasn’t actually at their home, where the interview was conducted. One person worked for an airline and had homes in two cities. Another person met us at his girlfriend’s house, where none of his stuff was located. Another lived with roommates and her young children, while her computer was at the home of their father. And so on. After this happened a few times, I updated the language of my screener to ensure that the interview would take place in their primary residence and where the device was, and that they would be prepared to show us the device during the interview.\n\nDuring another project, we were seeking people who were actively sharing certain types of information. One participant was indeed actively sharing this information, but only with his\n\nOptimizing the Interview 121\n---\nimmediate family, with whom he lived some of the time. We hadn’t specified that “sharing” should take place with a broader network, and even though we had reviewed the screener with our client, no one had seen this as a concern. From this interview, it emerged that we all had different ideas of what “sharing” meant. Our client was very concerned since they had conceived of sharing as a different behavior. In the interview itself, we focused on learning everything we could from this participant, but in the aftermath we had a number of intense conversations with the client to determine whether or not this participant was acceptable for the study.\n\n# When the Participant Won’t Stop Talking\n\nAs you settle into a rhythm with participants, you may realize that they talk extensively, requiring little or no prompting from you. Before you try to “fix” this issue, ask yourself whether this really is a problem. You have prepared extensively and have a lot of questions you’re hoping to ask, but are you getting what you need from this participant? If you don’t feel in control, you might be annoyed, but keep the emotional factor separate and assess the interview in terms of the information you need. In some cases, they won’t be answering your questions at all. Give them space to tell the story they’ve chosen to tell you and then redirect them back to your question. For example, consider the following exchange, which is drawn from a real experience:\n\nQ: What kind of food do you prepare for yourself?\n\nA: When I was a child [long story about her mother, etc., etc.]\n\nQ: So how does that experience as a child impact the decisions you make now for your family?\n\nYour last resort is to interrupt. If you must interrupt, frame it appropriately—“Excuse me! I’m so sorry to interrupt, but I know we have a limited amount of time, and I want to make sure we cover the topics we’re here to learn about.”\n\nNOTE CONFERENCE INTERRUPTUS\n\nI was at a conference in Bangalore. The last session of the day included a fairly spirited Q&amp;A. There were two microphones going around, and while an audience member and a panelist were going back and forth on one mic, I got the other. The discussion was degrading; the audience member was fixated on some issue and was not going to let it go, but there was no resolution. The conversation had devolved into posturing and deflection. People began to get annoyed and mutter and shift in their seats. They saw me with the microphone and began,\n\n122 Chapter 8\n---\nquietly at first and then more insistently, to encourage me to interrupt. I could see that interrupting was within the norm for this culture, but even as I was standing up and being cheered on, it was extremely difficult for me to interrupt. I succeeded in opening my mouth, but nothing came out. Twice. Meanwhile, the droning, time-wasting back-and-forth continued, and my fellow attendees were losing patience with me. Finally, I was able to interrupt, but it was a significant challenge, even with all the affirmation! In an interview, I find interrupting just as difficult and do it only when I absolutely have to.\n\n# When You Feel Uncomfortable or Unsafe\n\nUnless you are going to a public or familiar corporate location, don’t conduct interviews on your own. When you arrive at a location, verify that everyone feels safe. Pay attention to the difference between unsafe and uncomfortable1. If you feel unsafe, don’t go in. If you feel uncomfortable, try to set that feeling aside and proceed (see Figures 8.1 and 8.2).\n\n# FIGURE 8.1\n\nCheck your gut reaction. If you feel uncomfortable, it may still be okay to proceed.\n\n1 See http://johnnyholland.org/2009/06/lets-embrace-open-mindedness/ (scroll down to the section entitled “Getting Out of the Comfort Zone”) for some thoughts about acknowledging people’s discomfort in new or different situations). Coming to grips with this discomfort is a wonderful way to grow as an interviewer.\n\n# Optimizing the Interview\n\n123\n---\n# 5\n\n# FIGURE 8.2\n\nIf you feel unsafe, pay attention to that feeling and stay away from dangerous places.\n\nThere will be plenty of strange interviews. It’s an hour or two of your life; if you aren’t in danger, do your best to learn what you need to learn, acknowledge that life is interesting, and add the experience to your set of war stories.2\n\nWomen are unfortunately more likely to encounter awkwardness and comments that push the boundaries. If you feel increasing discomfort in response to someone else’s behavior, take a moment to pause and identify what’s happening. You might want to call for a bathroom break. If you are at risk, leave. Otherwise, you can ignore the behavior (but not the person) or restate your objectives and give the participant the opportunity to agree to continue with that focus. Of course, be aware of your own limits and be prepared to leave if the situation deteriorates.\n\n2 Danger is a personally subjective issue. In this video https://vimeo.com/9217883, Luis Arnal describes his design-research adventures, including arranging with gang leaders to gain access to Brazilian slums (known as favelas) for fieldwork, the consequences of inadvertently photographing an FBI undercover operation, and (if not dangerous then perhaps uncomfortable) participating in one of Spencer Tunick’s massive nude photo shoots.\n\n124 Chapter 8\n---\n# NOTE\n\n# THE MINOR MELTDOWN\n\nAfter a long few days of fieldwork, my client and I headed to Los Angeles’s Toy District to interview a wholesaler. Driving separately, we had each struggled naïvely through traffic the way that out-of-towners do and were searching for parking. I left my car in a no-parking spot and went to verify our meeting location. Our interview was with a small business owner. I was picturing a typical retail setting, with a familiar storefront, street numbers, etc. Instead, I found a street filled with stalls jammed with merchandise, with few prominent building numbers (many were just scrawled in marker on the outer edges of the stalls). Something about this did not feel right, so I called our recruiter and got confirmation that we were indeed in the right place.\n\nI left my car in a lot and walked to meet my client, who was still in his car, circling. I got into his car and related my impressions as he navigated traffic, still looking for parking. The long days, the daunting traffic, the unfamiliar surroundings, and the parking problems had been accumulating until something within him snapped. He turned red, made a sudden turn, and floored the accelerator. Fortunately for me, his venting of emotions gave me space to be “the calm one” (although no doubt I had fed his anxiety with my own). We drove a few blocks, and I made some very concrete suggestions about where to park. Once calmness returned, we both could see that there was nothing really wrong, but we had just reached the end of our ropes. We got some food and walked back to our interview. We were overwhelmed and exhausted, and the lack of familiarity caused a brief and intense descent into fear. That experience with the fight-or-flight reflex helped me more finely parse the difference between discomfort and danger.\n\n# Interview Variations and Special Cases\n\nWhile I’ve devoted much of this book to the optimal case where you and your participant have arranged the best possible interview situation, there are inevitably exceptions. In this section, I’ll look at how to deal with some of these situations:\n\n- You and your participant are not in the same location.\n- You meet your participant in a neutral location, out of his context.\n- You have only a short amount of time for the interview.\n- You are interviewing people as “professionals” rather than as “consumers.”\n- You have multiple participants in a single interview.\n\nOptimizing the Interview 125\n---\n# When Your Interview Isn’t Face-to-Face\n\nPhone interviews are a fairly common alternative to face-to-face interviews, especially when geographic distance makes a face-to-face interview unrealistic. Since you won’t have as much context (see Figure 8.3), look for other ways to compensate. Ask participants beforehand to send some digital photos of their environment or to describe elements you won’t be able to see during the call. When arranging the interview, establish their expected location. (For example, will they be in their car in traffic, or will they be at home caring for their children?) At the same time, confirm the length of the interview. For most people, an hour is a long time to be on the phone.\n\nDuring a phone interview, a lack of facial cues makes it a bit harder to adjust your pace and rhythm to the participant. Experiment with giving your participant an extra beat of silence to ensure she feels permitted to speak, and to allow her to continue to speak. If silence is making her uncomfortable (you get a, “Hello? Are you there?”), pick up the pace a bit and introduce verbal handoffs (such as, “Go ahead…please continue…”).\n\nIf you use technologies like Skype (for audio or video) and FaceTime, you are introducing other complicating factors:\n\n- Your participant might not be fully proficient at using these tools. It’s not ideal to begin the interview having your participant exasperated and feeling incompetent.\n- You are subject to the variability of Internet connection speeds (and software reliability) on both ends. Four minutes of reconnecting and dropping calls is not acceptable, so arrange for a technology test before the interview.\n\n# FIGURE 8.3\n\nWhen the interviewer and participant can’t see each other, it’s anyone’s guess how their contexts differ.\n\n126 Chapter 8\n---\nNot everyone is fully literate in video conferencing. Consider your audience. You might want to warm up the interview with a discussion of the communication context (“It’s unfortunate we couldn’t meet with you face-to-face. Do you regularly meet with people via Skype?”).\n\n# When Your Interview Is in a Market Research Facility\n\nFocus group companies offer meeting rooms designed for market research, with mirrored-wall observation rooms, video recording, and all the other accoutrements. It would be a mistake to consider these facilities as neutral third places. When you invite people to come to a facility to be interviewed, they are coming to your house. Unfortunately, all the comfy couches, Nerf balls, and tasty snacks don’t change that. You must be the host instead of the guest. Even if you don’t feel settled in this new environment yourself, you must welcome them into your space. You can ask them to bring something of theirs (photos, artifacts, or a collage) to the interview, but this approach is a definite compromise.\n\n# When Your Interview Is Very Short\n\nIf you can get only a short amount of time from people, warm them up ahead of time. Get them thinking about your topics by emailing them some key questions to think about. They don’t need to write up their answers ahead of time; they can just be reflecting on these topics and be prepared to share some perspective. You won’t have time to probe too much. Stick to the agreed-upon time unless they offer to talk longer, and then make an explicit request for a follow-up interview.\n\n# The Differences in Interviewing Professionals vs. Consumers\n\nConsumer interviews will probably take place in the home. When interviewing professionals, you might find yourself on a trading floor, in a hospital, in a restaurant, in an office, in a manufacturing facility, or in any other kind of environment. Professionals might have to perform their work tasks intermittently or continuously as they are interviewed, so you might be doing bouts of passive observation, or you might be asking for narration of processes rather than exploring other topics. Depending on what you need to do when interviewing professionals, you need to be very specific in your interview request—duration, environment, role, and so on.\n\nConsumers might default to treating your interview like a visit. Professionals often frame the interview as a meeting. You can choose to operate within those expectations, or you can seek to shift them, but keep in mind where your participant is coming from.\n\nOptimizing the Interview 127\n---\n# Interviewing Multiple Participants\n\nWe often ask other family members to join interviews, or we may speak to colleagues simultaneously when interviewing professionals. This is best when you aren’t expecting power dynamics to significantly impact the interview (such as a subordinate being asked to explain his career goals in front of his boss; or a teen being asked about her alcohol consumption in front of her parents). If need be, you can break the interview into separate chunks for each participant individually and for the group together.\n\nIn terms of group dynamics, your goal should be to get the participants talking extemporaneously, even to each other. Do not conduct two parallel identical interrogations; instead, gently lead a conversation by throwing your questions open and using eye contact and specific probes directed at individuals to encourage them to contribute. As you hold back, they will step forward.\n\nInstead of this:\n\nInterviewer: When did you start drinking Kombucha?\n\nP1: About six months ago.\n\nInterviewer: How about you, when did you start drinking Kombucha?\n\nP2: It was about four months ago.\n\nInterviewer: And what is it about Kombucha that draws you to it?\n\nP1: I like the taste.\n\nInterviewer: What about you?\n\nP2: I like the way I feel after.\n\nAim for this:\n\nInterviewer: When did you each start drinking Kombucha?\n\nP1: About six months ago.\n\nInterviewer: [Pause]\n\nP2: Oh, for me it was about four months ago.\n\nInterviewer: And what is it about Kombucha?\n\nP1: I like the taste.\n\nP2: You do? I actually can’t stand the taste but…I like the way I feel after.\n\nP1: But tell them about what happened when you drank that tiny bottle last week!\n---\nYou’ll have more success with people who already know each other. As I mentioned earlier when considering the number of interviewers, people influence each other simply by being together. The more people you include, the more you’ll experience that effect.\n\n# Using Different Interviewing Techniques at Different Points in the Development Process\n\nRegardless of your business objectives, you always want to understand how the participant makes sense of the world, and what problems and concerns they have. You may be early in the development process and have broad questions, or you may be further along and have hypotheses (concepts, animations, storyboards, designs, wireframes, and more). In the latter case, spend the first part of the interview understanding the participant’s workflow, objectives, pain points, and so on. Then, when you share the artifacts you’ve brought, you have a better chance at understanding why they are responding the way they do. If you aren’t interested in that amount of detail and just want reactions to your prototype, you’re better off doing usability testing, not interviews.\n\n# Improving as an Interviewer\n\nNow that you’ve learned some techniques for interviewing, you can hone and refine your performance further by practicing, reflecting, critiquing, collecting, and sharing.\n\n# Practice\n\nDon’t forget that interviewing is like any skill: the more you practice, the better you get. Even the busiest researcher only gets to do a certain number of interviews, so be creative in generating or finding other opportunities to practice. Take advantage of brief everyday encounters (say, that loquacious taxi driver) and do a little bit of interviewing, asking questions and follow-up questions. Cultivate a style of interacting socially that emphasizes listening, reflecting back the other person’s comments, allowing for silence, and so on. Try for longer and deeper conversations to build up your stamina.\n\nWhen you are in the field, remember that each interview is also a learning experience. Try something different once in a while. Use the interview guide from back to front while still maintaining rapport and keeping a comfortable flow; force yourself to count to five before everything you say; don’t just take notes, take copious notes.\n\n3 See http://en.wikipedia.org/wiki/Asch_conformity_experiments or http://en.wikipedia.org/wiki/Normative_social_influence for more.\n\n# Optimizing the Interview\n\n129\n---\n# Reflect\n\nYou can get the most out of any interview by reflecting on it. Football coaches review game films, and user researchers can do similarly. You have the material: audio, video, or transcripts. Otherwise, conduct and capture mock interviews specifically for this purpose. Look for moments that went well or moments that went slightly awry and think about what you would do differently. Don’t beat yourself up about how you handled it in the moment; the benefit of reflection is that you can stop time and consider a range of options.\n\nSeek out opportunities to be interviewed yourself. Although phone surveys or online customer satisfaction surveys use a different methodology, the participants aren’t thinking about that; they are just being asked questions. Sign up for market research databases or volunteer for grad student studies. Go through the experience and notice when it feels bad (and any time it feels right). You can use these insights to avoid, or replicate, such interview techniques.\n\nLeverage your past experiences with strangers, such as going on blind dates, working as a bartender or waiter, being interviewed for a job, and more. What principles did you develop in those situations? Consider what worked and what didn’t and why.\n\n# Critique\n\nIn addition to reviewing your own interviews, review other people’s, too (and ask them to review yours). Tag along during interviews and watch someone’s technique. Teach someone else how to lead an interview. Or ask someone to come along to your interviews and get his feedback. Also ask for feedback from the rest of your field team (even if you are the lead interviewer), or even from your research participants.\n\nCheck out interviews in the media: Terry Gross, Charlie Rose, Barbara Walters, Oprah Winfrey, and Marc Maron are good places to start (see Figure 8.4). Watch and listen as an interviewer, not just an audience member. Although the context of journalism (writ large) differs from user research, you will notice techniques both new and familiar.\n---\n# VITA\n\n# ONOMIN KLENOV MITRI\n\n# FIGURE 8.4\n\nMarc Maron is a comedian, not a journalist. His interviews (see Chapter 6) are a good source of both positive and negative examples.\n\n# And More\n\nCollect and share your fieldwork war stories.4 These experiences—the crazy household, the dog that does his business on your shoes, the GPS failure—are inevitable and are often hilarious (at least in hindsight). Exchanging these stories is a way of sharing techniques and creates learning opportunities for both the tellers and listeners.5 A culture of exchange—wherever you can find it—is going to help you grow your own skills. You can check out (and contribute to) a growing archive of fieldwork war stories at www.portigal.com/series/WarStories.\n\n4&nbsp;&nbsp;As in this Merriam-Webster definition: “A recounting of a memorable personal experience, especially one involving challenge, hardship, danger, or other interesting features.”\n\n5&nbsp;&nbsp;In Per Brandström’s thesis Boundless Universe: The Culture of Expansion Among the Sukuma-Nyamwezi of Tanzania, he describes how anthropologists in the field often gather at a hotel bar and “release a torrent of stories about bizarre and remarkable happenings and experiences in exotic settings, and each anthropologist will try and top the others’ wildest stories... When the laughter dies away and the entertainer is transformed into the scientist, a sudden change of scene has taken place. The anecdotes and the wild stories are stowed away. Now order is the rule of the day; facts and theories will be presented.”\n\n# Optimizing the Interview\n\n131\n---\nTake an improv class. Improv training helps develop many aspects of interviewing, such as being in the moment, holding back judgment, and listening.6 Alternatively, meditation can help you be present during interviews and develop the mental energy it takes to focus deeply on someone else. Connect with other interviewers online7 and at conferences.8 Read books about interviewing (Hey, you’re doing that right now! Well done!) and about interpersonal communication.9 As you learn more, you can identify your own personal style and adjust for it.\n\n6&nbsp;&nbsp;I’ve given a number of talks about improv in the context of design and design research. Video from one presentation is at www.ustream.tv/recorded/2595655 and the slides are at www.slideshare.net/steveportigal/yes-my-iguana-loves-to-chacha-improv-creativity-and-collaboration.\n\n7&nbsp;&nbsp;Try the anthrodesign group at http://tech.groups.yahoo.com/group/anthrodesign/.\n\n8&nbsp;&nbsp;In addition to design and UX conferences, check out ethnography conferences such as EPIC (www.epicconference.com).\n\n9&nbsp;&nbsp;For example, books by Deborah Tannen; see www9.georgetown.edu/faculty/tannend/.\n---\n# Summary\n\nInterviewing is made of people, and as such your experiences in the field will be unpredictable and surprising. Be prepared for what might go awry and how you will deal with it.\n\n- If you feel your participant is reticent, be sure it’s not just a difference between her speaking rhythm and yours. Try to identify what’s making her uncomfortable and make adjustments. If necessary, ask about any possible discomfort. Or just accept the awkwardness and move forward until she opens up.\n- You may not initially feel a participant is right for the study. Once you are there interviewing, stick with it. If he isn’t what you expected (despite deliberate screening), that is something worth reflecting on later; meanwhile, what can you learn from him now?\n- If you think your participant is talking too much, ask yourself if that’s because you are feeling out of control or because you aren’t getting the information you want. If you must interrupt, apologize and remind him that you value his limited time.\n- In a phone interview, lack of visual cues makes it harder to adjust your pace and rhythm to the participant. Give her an extra beat and give yourself permission to feel awkward in those small moments of silence or overlap.\n- If you have only a very brief amount of time for your interview, prime your participant ahead of time with some questions or topics you plan to discuss.\n- When interviewing several people at once, avoid asking each person the same question in turn. Use eye contact to create a more free-flowing dialogue where some questions are addressed to an individual while others are thrown to the group. Allow them to follow-up each other’s points and even ask each other questions.\n- Be aware of the difference between discomfort and fearing for your safety. Develop a tolerance for the former but do not compromise on the latter.\n- Improve your interviewing skills by practicing, varying from your habitual approach, reviewing transcripts and videos, and seeking critiques from others.\n\n</interviewing_users>",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        840,
        0
      ],
      "id": "30d677bd-aa94-4faa-adbe-f552864f14fc",
      "name": "Load Interviewing Users"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "3a86f4f7-8173-4d92-92a1-ea0130541b4c",
              "name": "jobs_framework",
              "value": "=<JTBD_framework>\n\n# Jobs to be Done: Theory to Practice\n\n---\n# INTRODUCTION:\n\n# THE FAILURE THAT LED TO SUCCESS\n\n# INSPIRED BY FAILURE\n\nEarly in my career as a product engineer, I experienced the ultimate professional disappointment: for 18 months I put my heart and soul into creating a product that failed in the marketplace.\n\nIt was 1984, and I was part of the IBM PCjr development team. We were working on a product that was supposed to revolutionize home computing. In advance of its release, the Washington Post wrote, “the PCjr will quickly become the standard by which all other home computers are measured.” So, you can imagine my surprise when, the day after we introduced the PCjr, I woke up to read the headlines in the Wall Street Journal declaring, “PCjr is a flop.”\n\nI was shocked! As we learned over the next few months, they were right. It was a flop, an embarrassment that cost IBM over a billion dollars and put a blemish on its reputation.\n\nThe humiliation of failure had a profound effect on me. I was determined to never let that happen again. In the weeks that followed I wondered how the Wall Street Journal had been able to see this correctly, and so quickly. It occurred to me that if we knew what metrics they (and potential customers) were going to use to judge the value of our product well before we introduced it, we would have the\n---\nopportunity to design our product to address those metrics and achieve a positive result.\n\nThis set me on a mission: I wanted to figure out a way to identify the metrics that customers use to judge the value of newly released products early on in the product planning process.\n\n# THE BREAKTHROUGH\n\nOver the next five years, I studied and tried out many new tools that looked promising, including voice of the customer, quality function deployment (QFD), TRIZ, Six Sigma, and conjoint analysis. I studied everything that was written about these tools and used them in my product planning activities. I conducted hundreds of customer interviews and dozens of quantitative studies. I also worked with IBM statisticians to learn how to best apply conjoint, factor, and cluster analysis to segment markets in a meaningful way. I worked as an internal IBM consultant, using what I learned to help different internal teams formulate market and product strategies. IBM management was very supportive throughout this process, which is something I appreciate to this day.\n\nIt was in North Sydney, Australia, with an IBM team in 1990 when I had a mental breakthrough. Six Sigma thinking seeks to improve the quality of the output of a process by identifying and removing the causes of defects. It uses a set of quality management methods, mainly empirical, statistical methods, to address process deficiencies. It occurred to me\n---\nthat we could apply Six Sigma and process control principles to innovation if we studied the process that people were trying to execute when they were using a product or service, rather than studying the product itself. Once we made the process the subject of our investigation, we’d be able to break it down into process steps, study each step in detail, and attach metrics to each step that we could measure and control in the design of a product.\n\nI was so excited about this prospect that I struggled to sleep for days. As I thought about it more, I realized that to make this work I would have to figure out how to uncover the metrics that customers use to measure success and value as they go about executing these processes.\n\n# VALIDATING THE PROCESS\n\nIn October 1991, I left IBM and founded The Total Quality Group. The goal of this one-man consultancy was to apply my newly envisioned process, which I called CD-MAP (to denote the concept of customer-driven maps), to product strategy and planning initiatives.\n\nOne of my first clients was Cordis Corporation, a company that was trying to reinvent its line of angioplasty balloon products. I interviewed interventional cardiologists to break down and analyze the process they went through to restore blood flow in a blocked artery. Through this qualitative research effort, I carefully constructed 75 uniquely defined\n---\ncustomer need statements that I called desired outcomes. The statements described the metrics that interventional cardiologists were using to judge and measure their success as they tried to restore blood flow in an artery. With these customer-defined metrics in hand, I conducted quantitative research to discover which of those outcomes were underserved—important to the interventional cardiologists, but not well satisfied. I discovered several.\n\nI then facilitated a series of strategy sessions to help the Cordis team use these insights to create a new product line. By mid-1993, the company launched 19 new products, all of which became number 1 or 2 in the market.\n\nCordis’ market share increased from 1% to more than 20%, and its stock price more than quadrupled. Needless to say, I was thrilled: this was validation that my method worked. Tying customer-defined metrics to the underlying process the customer was trying to execute was the key to success.\n\n# ADVANCING THE PROCESS\n\nI engaged in dozens of innovation initiatives over the next several years, achieving similar results with companies such as Motorola, Pratt & Whitney, Medtronic, AIG, Allied Signal and Telectronics. Making process refinements with every application, I learned how to apply the process in multiple industries and for hardware, software, and service.\n---\nofferings. The process became very robust as I continued to rid it of inefficiencies and variability and established a strict set of rules for defining desired outcome statements. As the decade progressed, I decided to rename the company and offering to communicate its focus on strategy and innovation, and in 1999, the company became Strategyn and the data-driven process became Outcome-Driven Innovation® (ODI).\n\nAlso, in 1999 I was granted my first patent on the ODI process. It was the first of 12 patents I would eventually receive regarding my strategy and innovation process.\n\nIn late 1999, I had the distinct pleasure of introducing Outcome-Driven Innovation and our research and segmentation techniques to Harvard Business School professor Clayton Christensen. We met in his Harvard office on several occasions in the 5 years that followed. I introduced Clay to ODI and showed him examples of how the process was executed and the results it delivered our clients.\n\nClay was quick to key in on the fact that the focus of our approach was not on the customer or the product, but rather on the underlying process the customer was trying to\n\n18\n---\nexecute, or, as he eventually came to call it, the “job” the customer was trying to get done.\n\nClay was kind enough to cite Strategyn and me as originators of these practices in his 2003 book, The Innovator’s Solution, in which he popularized the idea that people “hire” products to get a “job” done. To this day, Clay continues to be a proponent of Jobs-to-be-Done Theory and a key contributor to its development.\n\nClay also introduced me to Mark Johnson and Matt Eyring, who I enjoyed working with on a number of joint activities in the early days of Innosight. I was honored that an offer was made to me to join Innosight as a partner in 2004, although I respectfully declined the offer. While Innosight’s focus on disruptive innovation was exciting, my focus on Jobs-to-be-Done Theory and ODI remained my top priority.\n\nIn 2002, Harvard Business Review (HBR) published my article called “Turn Customer Input into Innovation,” which described Outcome-Driven Innovation and its successful application at Cordis. The success of that article helped our team to grow Strategyn as a business and inspired me to write a book on Outcome-Driven Innovation called What Customers Want: Using Outcome-Driven Innovation to Create Breakthrough Products. Released in 2005, this seminal book explained in detail how ODI transforms Jobs-to-be-Done Theory into an effective innovation.\n\n19\n---\npractice. Since that time, I have had the honor of writing other articles that were published in HBR and MIT Sloan Management Review.\n\nThe most rewarding part of my journey has resulted from being a hands-on ODI Practitioner. That is my passion. I have led and continue to lead hundreds of innovation engagements with inspiring people in the world’s most admired companies. Every week I have the privilege of learning from top thinkers in companies across a wide range of industries. In 2016, the Strategyn team and I have worked with companies such as B. Braun, HD Supply, Minitab, Panasonic, Kawasaki, WL Gore, Momentive, The Medicines Company, Roche, P&amp;G, Medtronic, Oracle, Johnson &amp; Johnson, Arm &amp; Hammer, Harte Hanks, and Terumo. I am a practitioner at heart.\n\nYears of hands-on experience applying ODI have been the key to continued process improvement and our advancement of Jobs-to-be-Done Theory. To this day, my team and I have ongoing ODI best practice reviews to share our collective knowledge and improve our thinking, tools and practices. Our goal remains the same—to transform innovation from an art to a science.\n\nIn the September, 2016 Harvard Business Review article, “Know Your Customers’ Jobs to be Done,” Clayton Christensen states, “Innovation can be far more predictable—and far more profitable—if you start by\n\n20\n---\nidentifying the jobs that customers are struggling to get done.\n\nStrategyn has collected data through formal research that supports Christensen’s claim and shows just how much more predictable innovation becomes when using Jobs-to-be-Done Theory and Outcome-Driven Innovation.\n\nTo obtain this data, we engaged a Harvard Business School trained independent researcher to study the success rates of traditional innovation methods vs. our own innovation process, Outcome-Driven Innovation. The results of that study showed that while the success rates of traditional innovation processes average 17%, the success rate of Outcome-Driven Innovation is 86%.\n\nThis means that 86% of the products and services launched by our clients using ODI were a success. This data validates Christensen’s claim that the innovation process is more predictable if you start with a focus on the job-to-be-done. In fact, it is five times more predictable. The reason for the success of ODI is simple: a company can dramatically increase its chances for success at innovation if it knows precisely what metrics customers use to measure success and value when getting a job done.\n\nHere are the details of the study:\n---\n# JOBS-TO-BE-DONE THEORY & OUTCOME-DRIVEN INNOVATION IMPROVES INNOVATION SUCCESS RATES\n\nIn order to accurately determine the success rate for traditional innovation processes, the researcher found success rate reports from 12 different sources, including the Harvard Business Review, the consulting firm Frost & Sullivan, the professional services firm PricewaterhouseCoopers, the Product Development Management Association (PDMA), the Corporate Strategy Board and others.\n\n- Frost & Sullivan reported (i) that only one in 300 new products significantly impacts a company’s growth and (ii) that only 1% of new products recoup their product development costs.\n- The Corporate Strategy Board reported that over the past four decades, of the 172 companies that spent time in the Fortune 50, only 5% sustained a growth rate greater than the growth rate of the gross domestic product.\n- PricewaterhouseCoopers reported that only 11% of all venture investments get to any capital liquidity.\n- R.G. Cooper reported that new products succeed 25% of the time.\n- The Product Development Management Association (PDMA) claims that new products succeed 59% of the time.\n---\n# The 12 sources studied\n\nand the innovation success rates they cited are summarized in the table:\n\n|Source|Rate|\n|---|---|\n|Frost & Sullivan; \"Growth Process Toolkit: New Product Development;\" 2008.|0.3%|\n|Frost & Sullivan, \"Growth Process Toolkit: New Product Development;\" 2008.|1%|\n|Andrew Campbell and Robert Park 'Stop Kissing Frogs; Harvard Business Review, July-August 2004.|1%|\n|Dr. John Sviokla, The Calculus of Commerce, Diamond Cluster International, Inc 2004.|39|\n|Corporate Strategy Board, \"Stall Points,\" 1998. Cited in Clayton Christensen and Michael Raynor; \"The Innovators Solution;\" page 5, Harvard Business School Press, 2003.|5%|\n|Andrew Campbell and Robert Park; 'Stop Kissing Frogs; Harvard Business Review July-August 2004|10%|\n|Kevin J. Clancy and Randy L Stone; \"Don't Blame the Metrics;\" Harvard Business Review, June 2005.|10%|\n|Corporate Strategy Board, \"Overcoming Stall Points,\" 2006.|10%|\n|PricewaterhouseCoopers, 'Shaking' the Money-Tree;\" slide 33, U.S Venture Liquidity 2001-2007, Q3 2008.|11%|\n|Dr. Robert G. Cooper, \"Doing it Right; \" Product Development Institute Inc,, 2006.|67%|\n|Dr. Robert G. Cooper, \"Doing Right;\" Product Development Institute Inc,, 2006.|25%|\n|Abbie Griffin; \"Drivers of New Products Success;\" Product Development & Management Association; 1997.|59%|\n|Average|17%|\n|Strategyn|86%|\n\nIn order to study the success rate of our Outcome-Driven Innovation methodology, the researcher conducted interviews with representatives of 43 Strategyn clients that had used ODI to launch a product or service or to engage in an operational or marketing innovation initiative.\n---\nNo incentives were offered to those who participated, and, to encourage candor, anonymity was assured.\n\nThe researcher asked companies to judge the success of the ODI initiative they undertook based on their choice of one of four success metrics: revenue, market share, customer satisfaction, or return on investment. The company representative was re-contacted to confirm agreement with the categorizations.\n\nOf 21 projects that made use of the ODI methodology and resulted in product launches, 18 were rated successes by the sponsoring company—an 86% success rate. Five of these product launches received industry awards. I’ll describe some of these projects as case studies for success later in this book.\n\n|Strategyn clients interviewed|43|\n|---|---|\n|ODI-based products entered into development|49|\n|Pending launch|28|\n|Launched|21|\n|Declared a success after launch|18|\n|Success Rate|86%|\n\nThe 21 launches were categorized as follows: new product (10), new service (1), product enhancement (4), service enhancement (4), and operational enhancement (2). For the three product launches that were considered unsuccessful, the sponsoring companies indicated that they did a poor job of executing the commercialization of the product.\n---\n|Company|Industry|What was launched|Success Criteria|Case Study|Award|Success|\n|---|---|---|---|---|---|---|\n|Company A|Medical devices|New product|Revenue| | | |\n|Company B|Hardware|New product|Market share| | | |\n|Company C|Software|New product|Revenue| | | |\n|Company D|Financial services|New product|Customer Sat| | | |\n|Company E|Industrial|New product|Revenue| | | |\n|Company F|Medical devices|New product|Revenue| | | |\n|Company F|Medical devices|New product|Customer Sat| | | |\n|Company G|Software|New product|Revenue| | | |\n|Company H|Consumer electronics|New product|Revenue| | | |\n|Company I|Hardware|New product|Market share| | | |\n|Company J|Manufacturing|New service|Customer Sat| | | |\n|Company F|Medical devices|Product enhancement|Revenue| | | |\n|Company F|Medical devices|Product enhancement|Revenue| | | |\n|Company K|Software|Product enhancement|Revenue| | | |\n|Company K|Software|Product enhancement|Revenue| | | |\n|Company L|Medical devices|Service enhancement|Customer Satisfaction| | | |\n|Company M|Business services|Service enhancement|Customer Satisfaction| | | |\n|Company N|Financial services|Service enhancement|Customer Satisfaction| | | |\n|Company O|Emergency services|Service enhancement|Revenue| | | |\n|Company P|Aviation|Operational enhancement|ROI| | | |\n|Company Q|Aviation|Operational enhancement|ROI| | | |\n\nSubtotals: 18\n\nTotal: 21\n\nSuccess Rate: 869\n---\n# THIS BOOK\n\n“What is the value of Jobs-to-be-Done Theory and how do you put the theory into practice?”\n\nThis book answers these questions. I reveal to you the hidden implications of Jobs-to-be-Done Theory and explain how to put Jobs-to-be-Done Theory into practice using Outcome-Driven Innovation®.\n\nThe structure of this book systematically takes you through three phases – from Theory, to Process and finally to Practice.\n\n|THEORY|PROCESS|PRACTICE|\n|---|---|---|\n|Needs Framework|Outcome-Driven Innovation@|Practitioners and Implementation|\n\nThe story told in this book can be summarized as follows:\n\n- Companies fail frequently at innovation because they struggle to understand and rationalize all their customer’s needs.\n- Jobs Theory provides a needs framework that makes it possible to categorize, define, capture, organize and prioritize customer needs.\n- A strategy framework, built around Jobs Theory, enables a company to correctly categorize, understand, and employ the 5 strategies that drive growth.\n\n26\n---\n# Outcome-Driven Innovation\n\n- Outcome-Driven Innovation ties customer-defined metrics to the customer’s job-to-be-done, transforming every aspect of opportunity discovery, marketing and innovation.\n- Prospective practitioners can assess their ability to put Jobs Theory and ODI into practice with detailed insight into a typical innovation initiative.\n- Companies should employ a proven three-phased approach to build a competency in Outcome-Driven Innovation.\n\n# Chapter 1\n\nChapter 1 introduces us to the root cause of failure in innovation. Why do so many projects fail?\n\n# Chapter 2\n\nChapter 2 introduces the solution: the Jobs-to-be-Done Needs Framework.\n\n# Chapter 3\n\nChapter 3 introduces the Jobs-to-be-Done Growth Strategy Matrix to explain how and when to use the five strategies that drive growth.\n\n# Chapter 4\n\nChapter 4 introduces our latest thinking regarding the execution of the Outcome-Driven Innovation process.\n\n# Chapter 5\n\nChapter 5 includes six case studies of companies that applied the Outcome-Driven Innovation process and achieved impressive results.\n---\n# Chapter 6\n\nStarting with Chapter 6, we introduce the Practice: a description of the 84 steps that comprise the Outcome-Driven Innovation process. Developed over the past 25 years, these are the steps a practitioner must take to successfully execute ODI.\n\n# Chapter 7\n\nChapter 7 describes a three-phase approach for helping your organization use ODI to build a competency in innovation.\n\n# Chapter 8\n\nChapter 8 is about the “Language of Jobs-to-be-Done” – the lexicon of innovation.\n\n# Chapter 9\n\nLastly, Chapter 9 points you to useful resources – videos, articles, and books that may be helpful on your journey of learning and practice.\n\nInnovation is far from simple.\n\nAn effective innovation process must produce answers to the following questions:\n\n1. Who is the customer?\n2. What job is the customer trying to get done?\n3. What are the customer’s desired outcomes?\n4. How do they measure value?\n5. Do segments of customers exist that have different unmet outcomes?\n6. What unmet outcomes exist in each segment?\n\n28\n---\n# 7. What segments and unmet outcomes should we target for growth?\n\n# 8. How should we define our value proposition?\n\n# 9. How should we position our existing and pipeline products?\n\n# 10. What new products must we create?\n\nThe qualitative, quantitative, and analytical methods that comprise our Outcome-Driven Innovation® process reveal answers to these questions and more.\n\nODI replaces luck with a predictable process.\n\nThis book is part of my lifelong journey. For the past 25 years, I’ve worked with the best and brightest people in industry and I have seen innovation through the lens of many companies. I’ve had the privilege of contributing to the creation of products that save and protect lives as well as other products that make those lives more enjoyable.\n\nIt is my sincere hope that this book will help you and your organization on your quest for innovation success. Contact me to share your stories and insights: ulwick@strategyn.com.\n\n29\n---\nTHEORY\n     30\n---\n# 1. WHY DO INNOVATION PROJECTS FAIL?\n\nThe goal of innovation is straightforward: to come up with solutions that address unmet customer needs. Today’s most popular approaches to innovation fall into one of two types: those that begin with a focus on solutions (or ideas) and those that begin with a focus on customer needs.\n\nIn what I call the “ideas-first” approach, companies brainstorm or otherwise come up with product or service ideas and then test them with customers to see how well the ideas address the customer’s needs. In the “needs-first” approach, companies first learn what the customer’s needs are, then discover which needs are unmet, and then devise a solution that addresses those unmet needs.\n\nAs I will explain, the “ideas-first” approach is inherently flawed and will never be the most effective approach to innovation. It will always be a guessing game that is based on hope and luck, and it will remain unpredictable. The “needs-first” approach to innovation, while not inherently flawed, is often flawed in its execution. Recognizing when an execution is flawed and executing the approach correctly are the keys to success in innovation. This structural flaw in the needs-first approach is corrected in the Outcome-Driven Innovation process.\n---\n# THE IDEAS-FIRST APPROACH IS INHERENTLY FLAWED\n\nMany companies adhere to the “ideas-first” approach and have developed support systems and organizational cultures that reinforce its use. Companies that follow this paradigm believe that the key to success in innovation is to be able to generate a large number of ideas (the more, the better) and to be able to quickly and inexpensively filter out the ideas that will likely fail. They believe this approach gives them a better chance of coming up with a greater number of breakthrough ideas.\n\n|IDEAS|SCOPING|GATE|STAGE|CREATE|BUSINESS CASE|\n|---|---|---|---|---|---|\n|GATE|STAGE|2|2| |DEVELOPMENT|\n|GATE|STAGE|3|3| |TESTING + VALIDATION|\n|GATE|STAGE|5|5| |LAUNCH|\n---\nMany academics, managers, and consultants support this thinking. Creators and supporters of many of the popular gated or “phase gate” development processes, for example, state that the first step of the development process is idea generation.\n\nApproximately 68% of large businesses have adopted some form of gated development, which means that this same percentage have adopted, at least to some degree, the ideas-first mentality. Examples demonstrating the prevalence of this mind-set abound. [1]\n\nIn their book, Innovation to the Core, Strategos CEO Peter Skarzynski and Rowan Gibson say that, “Successful innovation is a numbers game… the chance of finding a big, new opportunity is very much a function of how many ideas you generate, how many you pick out and test with low-cost experiments.” [2]\n\nHarvard Business School professor Teresa Amabile states in a frequently-cited article that, “All innovation begins with creative ideas.” [3]\n\nReferences:\n\n1. Robert Cooper, “Winning at New Products: Accelerating the Process from Idea to Launch,” 3rd ed. (Da Capo Press, 2001), 311.\n2. Peter Skarzynski and Rowan Gibson, “Innovation to the Core” (Chicago: Strategos, 2008), 137.\n3. Teresa M. Amabile, Regina Conti, Heather Coon, Jeffrey Lazenby, and Michael Herron, “Assessing the Work Environment for Creativity,” Academy of Management Journal 39, no. 5 (October 1996), 1154.\n---\nNearly everyone in a major corporation has participated in a brainstorming session in which, without knowing the customer’s needs, they were encouraged to generate hundreds of ideas and were told that there is no such thing as a bad idea. You can probably still picture the walls of Post-It notes.\n\nOthers who support the ideas-first approach have promoted the benefits of executing the approach quickly. Many refer to this accelerated ideas-first approach as “failing fast,” the idea being that when many ideas are generated and tested quickly, the best ideas are revealed faster. Since it is accepted that an ideas-first approach is going to generate many failures, it seems logical to try and weed out the failures quickly.\n\nThis concept was touted by Tom Peters in *Thriving on Chaos. Peters said companies should, “Test fast, fail fast, adjust fast—pursue new business ideas on a small scale and in a way that generates quick feedback about whether an idea is viable.” [Tom Peters, Thriving on Chaos: Handbook for a Management Revolution* (New York: Knopf/Random House, 1987), 479.]\n\nIBM founder Thomas Watson, who years ago said, “If you want to succeed, double your failure rate,” also supported this thinking and adopted a management style that did not punish failure.\n---\nThe fail-fast approach is still well supported today. For example, the authors of the recently published *Innovators Guide to Growth believe that, “If you fail fast and fail cheap, you have actually done your company a great service.” [Scott D. Anthony, Mark W. Johnson, Joseph V. Sinfield, and Elizabeth J. Altman, The Innovator’s Guide to Growth, Putting Disruptive Innovation to Work*, (Harvard Business Press, 2008), 94.]\n\nAs a result of this ideas-first thinking, an entire ideation industry has evolved to compete on developing ways to generate and evaluate more and more ideas, faster and faster.\n\nBut there is a problem: despite its popularity, academic support, and widespread use, the ideas-first approach to innovation cannot be counted on for predictable growth and is inherently doomed to failure.\n\n# There are three reasons for this:\n\nFirst, generating more ideas does not meaningfully improve the probability that someone will come up with the optimal idea to satisfy unmet customer needs. People are in effect brainstorming ideas without ever knowing what all the customer’s needs are or which of those needs are unmet. We know that in any given market a customer has 50 to 150 needs (how we know this will be\n---\ndiscussed later) and that anywhere from 5-80% of those needs may be unmet.\n\nThe mathematical probability of someone coming up with an idea that satisfactorily addresses all the customer’s unmet needs without knowing what they are or whether or not they are satisfied is close to zero. [Given the number of possible ways that just 15 unmet needs could be satisfied by products and services in any given market, millions of ideas would have to be generated before an exhaustive set of ideas could be created. If you assume three competing ideas for each of 15 unmet needs in various combinations, then you are generating ideas on the order of three to the power of 15, which is 14 million ideas. The chances of any one idea effectively addressing 15 unmet needs are one in 14 million. Furthermore, in most markets, we find there are more than 15 unmet needs.]\n\nGenerating more ideas that fail to address unmet customer needs is misguided and doing something bad faster does not lead to better results.\n\nThis approach to innovation is analogous to expecting a sharpshooter to hit a target without knowing what the target is. It is like expecting a doctor to recommend the right treatment without knowing what is wrong or what the symptoms are.\n\nThis brings us to a second reason why the ideas-first approach is doomed to failure: the evaluation and filtering processes are flawed.\n\n36\n---\nBecause the customer’s unmet needs are unknown, the evaluation and filtering processes used today can easily miss great ideas and fail to filter out bad ideas. Let’s remember what the evaluation and filtering process is supposed to do: separate the useful ideas from the useless ones. Or, in other words, choose the ideas that best address the customer’s unmet needs. And yet, this evaluation and filtering process is typically executed without knowing what the customer’s needs are.\n\nLacking explicit knowledge of customers’ unmet needs, managers rely on intuition or evaluate proposed concepts using methods such as conjoint analysis, paired comparisons, and forced-choice scaling techniques, along with surveys and qualitative methods such as focus groups. These methods and others like them rely on customers to evaluate how well a proposed idea will address their unmet needs without truly understanding the product or technology and how it explicitly relates to those needs. Such an evaluation and filtering process is faulty in several respects. The first and most obvious one, mentioned earlier, is that chances are great that the best solution is not even in the consideration set. But there is also the fact that customers may not be able to make the connection between the technology and their needs. It is not surprising, then, that companies using the ideas-first approach to innovation struggle to achieve success rates greater than 10-20%.\n\n37\n---\nThe third reason why the ideas-first approach is doomed is that customers cannot articulate the solutions they want. In most cases, the customer is not a scientist, engineer, researcher or materials expert. They don’t know what solutions are possible, but why should they?\n\nThe question I like to ask is, “Why are we even asking customers what solutions they want?”\n\nWhy should a company depend on the customer to know the best solution?\n\nWhy hire the customer to do the job of the marketing, development, and product planning team?\n\nComing up with the winning solution is not the customer’s responsibility. It is the responsibility of the company.\n\n38\n---\n# THE NEEDS-FIRST APPROACH IS OFTEN FLAWED IN EXECUTION\n\nThose who have recognized the inherent flaws in the ideas-first approach often attempt to follow a needs-first approach to innovation. Using this approach, companies first attempt to understand the customer’s needs, and then figure out which are unmet and devise a concept that addresses those unmet needs.\n\n|UNCOVER|NEEDS|\n|---|---|\n|SCOPING| |\n|GATE|STAGE|\n|IDEAS| |\n|GATE|STAGE|\n|2|2|\n|DEVELOPMENT| |\n|GATE|STAGE|\n|3|3|\n|TESTING + VALIDATION| |\n|GATE|STAGE|\n|LAUNCH| |\n|GATE|STAGE|\n|5|5|\n\n39\n---\nThis thinking, though different from the ideas-first approach, is also supported by many academics, businesses, and suppliers.\n\nTheodore Levitt, for example, in his 1960 landmark Harvard Business Review article, “Marketing Myopia,” states, “An industry begins with the customer and his or her needs, not with a patent, a raw material, or a selling skill.” [1]\n\nSince then, others have drawn a similar conclusion.\n\nHarvard Business School professor David Garvin has noted, “Studies comparing successful and unsuccessful innovation have found that the primary discriminator was the degree to which user needs were fully understood.” [2]\n\nIn theory, if all the customer’s unmet needs are known, then ideas can be generated to address them—and these ideas will have obvious value.\n\nOver the years, many methods have been utilized to capture customer needs. These include focus groups, personal interviews, customer visits, and ethnographic, contextual, and observational research methods in addition to interviewing techniques such as voice of the customer (VOC), lead user analysis, and storytelling.\n\n[1] Theodore Levitt, “Marketing Myopia,” Harvard Business Review 38, no. 4 (July-August 1960).\n\n[2] David Garvin, A Note on Corporate Venturing and New Business Creation (Boston: Harvard Business School Press, 2002), 5.\n---\nDespite the available needs-gathering methods, companies nearly always fail to uncover all or even most of the customer’s needs.\n\n# How is this possible?\n\nWhile nearly every manager agrees that the goal of innovation is to devise solutions that address unmet customer needs, a common language for communicating a need does not exist.\n\nIn research we conducted, we found that 95% of managers say there is internal disagreement on what a need is and how a need should be defined. Marketing and development teams in particular have strongly opposing views on what constitutes an actionable need statement. Consequently, while many employees may have customer knowledge, companies rarely have a complete list of agreed-upon customer needs. Is there anyone in your organization that knows all the customer’s needs? Is there agreement across the organization on what the customer’s needs are? Is there agreement on which needs are unmet? If not, then how can there be agreement on what products and services to produce?\n\nThe sad reality is that despite all the talk about satisfying customer needs, there is very little understanding of what characteristics a customer need statement\n---\nshould possess and what the structure, content, and syntax of a need statement should be.\n\nAbbie Griffith and John Hauser loosely defined “customer need” in their 1991 article “Voice of the Customer” as “a description, in the customer’s own words, of the benefit that he, she or they want fulfilled by the product or service.” [Abbie Griffin and John Hauser, “Voice of the Customer,” Marketing Science 12, no. 1 (Winter 1993), 4.]\n\nToday we know that obtaining inputs in the customer’s own words will more often than not result in the wrong inputs. Most managers, consultants, and academics agree that companies must look beyond the customer’s own words to extract the kind of input that is needed, but they cannot seem to agree on whether or not a need is a description of customer benefit, a measure of customer value, a statement of a problem, or something else entirely.\n\nWe also find that managers cannot agree on how the statement should look, what information it should contain, how it should be grammatically structured, or what types of words and phrases should be used or avoided to ensure variability is not introduced into the statement—variability that can adversely affect later prioritization of unmet needs. Managers find themselves in a position that is analogous to that of a chef who knows that certain ingredients are required to produce a certain taste but is unable to figure out\n\n42\n---\nprecisely what combination to use. And once forced into that position, getting it right becomes a process of trial and error.\n\nMany academics, consultants, and supplier firms end up regarding the collection of these customer inputs as an art. In fact, some of the most popular approaches today utilize anthropologists to “seek out epiphanies through a sense of Vuja De,” as IDEO general manager Tom Kelley says in *The Ten Faces of Innovation*. He goes on to say that anthropologists have a half a dozen distinguishing characteristics that include, for example, practicing the Zen principle of “beginner’s mind,” embracing human behavior with all its surprises, and drawing inferences by listening to their intuition. Our opinion is that while this approach works for IDEO, it makes innovation more of an art than a science. [1]\n\nOthers do not discriminate one type of input from another. For example, Gerry Katz, the vice president of Applied Marketing Science, Inc., writes, “[In distinguishing between needs and solutions] Ulwick adds the term desired outcomes... a useful description to be sure, just as Christensen has popularized the term jobs. But neither of these is conceptually any different from the other terms that have been in use since at least the mid-1980’s: wants, needs, requirements, benefits, problem, tasks that the customer is trying to accomplish, and jobs which the customer is trying to get done.”\n\n43\n\n[1] Tom Kelley makes that statement on page 17 of *The Ten Faces of Innovation* (New York: Doubleday, 2005).\n---\nAll these terms are not conceptually the same. As we shall show, the nuanced differences between these terms, as revealed through Jobs-to-be-Done Theory, represent a breakthrough in innovation—one that can easily be overlooked when viewed through a traditional VoC lens.\n\nTo make matters worse, there is also a widely held assumption amongst company managers that customers have latent needs, or needs that customers are unable to articulate.\n\nFor 20 years, this belief has been supported and perpetuated by many well-respected individuals and organizations. In their 1991 best seller, *Competing for the Future*, Gary Hamel and C. K. Prahalad warn companies of the risk they run if they cannot get a view of the needs customers can’t articulate.\n\nThe Product Development Management Association (PDMA) states that “customer needs, either expressed or yet-to-be-articulated, provide new product development opportunities for the firm.” [From the definition of “customer needs” in *The PDMA Glossary for New Product Development* (Mount Laurel, NJ: PDMA, 2006), http://www.pdma.org/npd_glossary.cfm.]\n\nPeter Sharzynski and Rowan Gibson explain in *Innovation to the Core that “radical innovators are deeply empathetic; they understand—and feel—the unvoiced need of customers.” [Peter Skarzynski and Rowan Gibson, Innovation to the Core*, 69.]\n---\nEven the process-oriented P&amp;G CEO, A. G. Lafley, says in *The Game-Changer that “great innovations come from understanding the customer’s unmet needs and desires, both articulated and unarticulated—that is, not only what they say, but, more important, what they cannot articulate or do not want to say.” [A. G. Lafley and Ram Charan, The Game-Changer* (New York: Crown Business, 2008), 45.]\n\nAs a result of this belief, many companies assume that it is impossible to capture a complete set of customer need statements and that they have no choice but to execute the innovation process without knowing all of them. But this conclusion is far from the truth.\n\nAs amazing as it sounds, the truth is companies routinely try to satisfy customers’ needs without a clear definition of what a need even is. It is like trying to solve a word puzzle without knowing what a “word” is. So, let’s not assume customers have latent needs.\n\nWhy does it matter? Take a look at your organization. Everything it does is based on what unmet needs the company decides to target. The marketing team must know the customer’s needs in order to define the company’s value proposition, segment markets, position products and services, and create marketing communications. The development team must know the customer’s needs so it can understand the strengths and weaknesses of the company’s products,\n\n45\n---\ndecide what new features to add to existing products, and what new products to create. The R&D department makes technology investments based on its understanding of customer needs. Finally, the sales team’s success depends on its ability to show customers that the company’s products meet their needs.\n\nHow to get a handle on customer needs is an unsolved mystery—and that mystery is killing innovation. Before a company can succeed at innovation, managers must agree on what a need is—and the types of needs that customers have.\n\nThe key to solving this mystery lies in Jobs-to-be-Done Theory.\n---\n# 2. JOBS-TO-BE-DONE NEEDS FRAMEWORK\n\nImagine the implications of knowing all your customer’s needs. How many people in your organization today know all your customer’s needs? Imagine if they all shared a common understanding of what a need is. How would decision-making improve if everybody in your organization had knowledge of all your customer’s needs? How much more effective would your product and marketing teams be if it were possible to determine with a high level of confidence exactly what customer needs are underserved? What possibilities would arise if it became possible to discover segments of customers with unique sets of unmet needs? Knowledge of all the customer’s needs changes everything. So how can it be achieved?\n\nHarvard Business School marketing professor Theodore Levitt said, \"People don't want to buy a quarter-inch drill. They want a quarter-inch hole!\" Clayton Christensen said, “People buy products and services to get a job done.” In his most recent book he says, “Customers don’t buy products; they pull them into their life to make progress.”\n\nThese are the basic constructs of Jobs-to-be-Done Theory, but these constructs are only the tip of the iceberg. Jobs-to-be-Done Theory has a game-changing implication:\n---\n# Jobs-to-be-Done Theory\n\nJobs-to-be-Done Theory provides a framework for (i) categorizing, defining, capturing, and organizing all your customer’s needs, and (ii) tying customer-defined performance metrics (in the form of desired outcome statements) to the job-to-be-done.\n\nKnowing all the customer’s needs in a given market dramatically changes the way a company approaches the innovation process. With a complete set of customer needs in hand, a company is able to discover hidden segments of opportunity, determine which needs are underserved and overserved, decide which strategies to pursue, simplify ideation, test concepts for their ability to get a job done in advance of their development, and align the actions of marketing, development, and R&D to systematically create customer value.\n\nWith knowledge of all the customer’s needs and which are unmet, a company can predict which new concepts and offerings will win in the marketplace. Evaluating a new concept against all the needs (when those needs are defined as the metrics customers use to measure value when getting a job done) will reveal how much better a proposed concept will get the job done.\n\nBecause customers are loyal to getting a job done, customers will switch to new solutions when they are able to get the job done significantly better. In our experience, new products that get the job done 20% better or more are very likely to\n---\nwin in the marketplace. Knowing that a product will get the job done 20% or more is the key to predictable innovation. ODI makes this possible.\n\nWhile applying Jobs-to-be-Done Theory over the past 25 years, I have developed the Jobs-to-be-Done Needs Framework (see the figure on the next page).\n\nThis framework introduces the types of customer needs that must be considered to gain a deep understanding of what a customer is trying to accomplish. They include:\n\n1. the core functional job-to-be-done,\n2. the desired outcomes tied to the core functional job-to-be-done,\n3. related jobs,\n4. emotional and social jobs,\n5. consumption chain jobs, and\n6. the buyer’s financial desired outcomes.\n\nWhile a job describes the overall task the customer is trying to execute, an outcome is a metric the customer uses to measure success and value while executing a job. For every functional and consumption chain job there exists a set of up to 50 or more desired outcome statements.\n\nThe Jobs-to-be-Done Needs Framework reveals the complexity involved in understanding all the needs in a market. It is not as if the customer has a handful of needs, or that there is just one customer. A diverse group of customers in a given market often collectively have well over 100 needs. In more complex markets such as health care and social media, customers may have 200 needs or more.\n\n49\n---\n# JOBS-TO-BE-DONE NEEDS FRAMEWORK\n\n# JOB EXECUTOR\n\n# CORE FUNCTIONAL JOB\n\n|DEFINE|LOCATE|PREPARE|\n|---|---|---|\n|EXECUTE|MONITOR|MODIFY|\n\n50-150 desired outcome statements\n\nDesired outcome statement 51: Get the CORE JOB done\n\nDesired outcome statement 52: better and/or more cheaply\n\nDesired outcome statement n\n\n# JOB EXECUTOR\n\n# RELATED JOBS\n\n# EMOTIONAL JOBS\n\n# CONSUMPTION CHAIN JOBS\n\n|Related job statement 1|Emotional job statement|Purchase|\n|---|---|---|\n|Related job statement 2|Emotional job statement 2|Receive|\n|Related job statement 3|Emotional job statement 3|Install|\n|Related job statement 4|Emotional job statement 4|Setup|\n|Related job statement 5|Emotional job statement 5|Learn to use|\n|Related job statement n|Emotional job statement n|Transport|\n\nHelp get More Jobs Done\n\nAdd Emotional Appeal\n\nStore\n\nMaintain\n\nUpgrade\n\nRepair\n\nDispose\n\nImprove User Experience\n\n# CONFIRM\n\n# CONCLUDE\n\nDesired outcome statement 71\n\nDesired outcome statement 72\n\nDesired outcome statement n\n\n# BUYER\n\n# FINANCIAL OUTCOMES\n\nFinancial outcomeFinancial outcome 2Financial outcome 3Financial outcome 4Financial outcome 5Financial outcome n\nDesired outcome statement 71\n\nDesired outcome statement 72\n\nDesired outcome statement n\n\nEnhance Business Model\n---\nThe customers’ needs are multilayered and complex. Customers have needs related to buying, using, and owning a product. They have emotional and functional needs. Customer need statements are mutually exclusive—they are defined independent of each other. A complete set of needs is collectively exhaustive—it incorporates all the needs a customer has for a given job. Each need must be stated separately and categorized correctly. Why?\n\nThe goal of innovation is to devise solutions that address unmet customer needs. For a company to be successful at innovation, this means it must not only know all the needs in the market, but it must be able to determine which needs are unmet. It must also be able to determine if there are segments of customers with different unmet needs. These are the insights that enable the innovation process to become more predictable. Without these insights, innovation remains a game of chance; having them changes everything.\n\nWhat are the chances, for example, that a company will randomly conceptualize a solution that addresses 14 unmet needs in a segment of the market that represents about 25% of end users/job executors? It’s very unlikely to happen by chance. A company would have to know the segment exists and precisely what needs are underserved before it could predictably achieve success.\n\nBut how long would it take a product planning team to conceptualize a solution that addresses those same 14 unmet\n---\nneeds if they knew the segment existed and exactly what those unmet needs were? In the case of the Bosch circular saw product team (see the case study in chapter 5), it took just 3 hours. This is the power of the ODI process. Innovation is transformed from a game of chance to a science when the customer’s desired outcomes (customer metrics) are known in advance of ideation.\n\nOne important factor that cannot be overlooked is that most markets are not homogeneous—meaning that in nearly every market, customers do not agree on what needs are unmet. Some customers in nearly every market struggle more than others to get a job done. This confirms what we learned in marketing 101—in nearly every market exists segments of customers with unique sets of unmet needs.\n\nDiscovering segments of customers with unique sets of unmet needs and determining precisely what unmet needs exist in a segment requires statistically valid market research, not just observation or other qualitative research methods. Customer personas that are built around demographic and psychographic data and claim to represent customer “segments” are highly misleading as they usually create phantom targets.\n\nTrying to guess at what needs-based segments exist and which needs are unmet introduces risk and variability into\n---\nThe innovation process. This is why statistically valid quantitative research is an essential part of the ODI process.\n\nAll of this begins with understanding what a need is and what type of needs customers have. The Jobs-to-be-Done Needs Framework provides an important function. Given all the customer insights that companies consider each day, the framework reveals what inputs are needed, how they should be categorized and organized, why they are captured, and how they should be used. The framework brings order to a historically chaotic practice.\n\n# THE CORE FUNCTIONAL JOB-TO-BE-DONE\n\nPeople buy products and services to get a job done. The job the end user is trying to get done is the core functional job. A deep understanding of the core functional job enables a company to create product or service offerings that get the job done significantly better than competing solutions.\n\nThe core functional job is defined in a single statement, such as cut a piece of wood in a straight line, pass on life lessons to children, or monitor a patient’s vital signs. How a company should go about and define the core functional job is discussed in Chapter 4.\n\nThe core functional job is the anchor around which all other needs are defined. It is defined first, then the emotional, related and consumption chain jobs are defined relative to the core functional job. For example, if the core functional\n---\nJob were defined as pass on life lessons to children, then we would seek to discover the customer’s emotional and related jobs as they are trying to pass on life lessons to children. All other jobs are in the context executing the core job.\n\nCompanies routinely want to know the functional jobs that customers are trying to get done for two reasons: (1) so they can discover new jobs to address (or new markets to target), and (2) to define a market they are already serving in a new way so they can use Jobs-to-be-Done Theory to discover how to serve it better. While the first activity requires a company to discover multiple functional jobs a customer is trying to get done, the latter requires a clear definition of just one functional job.\n\nMarket selection, the more complex scenario, is defined as the process of deciding what new markets a company should enter to establish attractive new revenue streams. To execute this process a company should first pick the customers (job executors) it would like to target and then determine all the functional jobs those customers are trying to get done. Next, through quantitative research, a company can determine which of those jobs are most important and least satisfied and will make the most attractive markets to target for growth. This exercise is critical for startups and established companies who are making investment decisions that will drive their growth.\n---\nWhile new market discovery is important, we usually find ourselves helping companies better position their existing offerings and creating new products and services in core markets they have been entrenched in for years. So more often than not, we find ourselves trying to figure out the core functional job(s) an existing customer is trying to get done. While this is generally not too complicated, it can be when the offering is a platform-level solution.\n\nMore specifically, in an existing market where a company’s offering has many applications or purposes, it is more difficult to determine the core functional job(s) the customer is trying to get done. In situations like this, we employ qualitative research methods to uncover all the reasons a customer may use the offering, and then we use quantitative research and factor analysis to group together like attributes and discover the core jobs customers are trying to get done. This approach has proven effective in banking (where banks are a solution that are used to get many jobs done) and social media, an industry where the top players offer platform-level solutions that are used for hundreds of purposes.\n\nWhen defined correctly, a functional job-to-be-done has three unique and extremely valuable characteristics:\n\n1. First, a job is stable; it doesn’t change over time. It’s the delivery vehicle or the technology that changes. Take the music industry, for example. Over the years people have used many products to help them listen to music (the job-to-be-\n---\ndone). This has included record players, tape and cassette players, compact disc players, MP3s and streaming services. Through this decades-long evolution of drastically changing technology platforms, the job-to-be-done has remained the same. The job is a stable focal point around which to create customer value.\n\nSecond, a job has no geographical boundaries. People who live in the USA, France, UK, Germany, South Korea, China, Russia, Brazil and Australia have many jobs in common that they are trying to get done. The solutions they use to get those jobs done may vary dramatically from geography to geography, but the jobs are the same. The degree to which the customer’s desired outcomes are underserved may also vary by geography, depending on the solutions they use, but their collective set of desired outcomes are the same. Consequently, knowledge of the job-to-be-done in one geography can be leveraged globally.\n\nThird, a job is solution-agnostic. The job-to-be-done does not care if your company provides product, software, or service offerings. The job has no solution boundaries. This means that a deep understanding of the job will inform the creation of a solution that combines hardware, software and service components. It also informs a digitalization strategy—ways to use technology to get a job done better.\n---\n# DESIRED OUTCOMES ON THE CORE FUNCTIONAL JOB\n\nBy focusing on the core functional job the customer is trying to execute and studying it as you would study a process, it becomes possible to uncover the metrics that customers use to measure success and value as they execute each step in that job. These metrics are included in specially formed need statements we call “desired outcomes” (see chapter 4).\n\nWhile defining the functional job correctly is important, uncovering the customer's desired outcomes (the metrics they use to measure success when getting the job done) is the real key to success at innovation.\n\nTo uncover the customer’s desired outcomes, we dissect the core functional job into its component parts (job steps) using a job map. The job map becomes the framework from which to capture desired outcome statements.\n\nDesired outcome statements explain precisely how customers measure success and value as they go through each step of the core functional job. They describe how it is possible to get the job done more quickly, predictably, efficiently, and without waste. It is common to find that between 50 and 150 desired outcomes statements are applicable to the core functional job. For example, when trying to listen to music, a listener may want to minimize the time it takes to get the songs in the\n---\ndesired order for listening, or minimize the likelihood that the music sounds distorted at high volume.\n\nWe follow a strict set of rules when constructing desired outcome statements—for example, they are purposely designed and structured to be measurable, controllable, actionable, devoid of solutions, and stable over time. They are also structured so they can be prioritized for importance and satisfaction using statistically valid market research methods.\n\n# RELATED JOBS\n\nWhile getting the core functional job done, it may be important to the end user to get other functional jobs done as well. Knowing what those related jobs are is important as it can lead to the creation of a platform-level solution that gets many jobs done. It is not uncommon to find that 5 to 20 related jobs might be on the mind of the end user.\n\nWhile making a presentation, for example, a knowledge worker may want to emphasize a point projected on a screen, advance slides, time the presentation, or shut off the projector. Enabling the execution of all these related jobs done on a single platform describes how the telescopic pointer of years ago has evolved into today’s wireless presenter device. Its value increased as it enabled the presenter to get more related jobs done.\n\n58\n---\n# EMOTIONAL AND SOCIAL JOBS\n\nWhile getting the core functional job done, it may also be important to the end user to address important emotional and social jobs. Emotional jobs define how customers want to feel or avoid feeling as a result of executing the core functional job. Social jobs define how the customer wants to be perceived by others.\n\nFor example, a parent who is trying to pass on life lessons to children may want to feel appreciated (an emotional job) and be perceived as a caring parent (a social job).\n\nEmotional and social job statements are used to help inform the decisions that lead to the creation of the value proposition and the effective marketing, positioning, and design of a product or service.\n\nIt is not uncommon to find that 5 to 25 emotional and social jobs may be on the mind of the end user when executing the core functional job.\n\n# CONSUMPTION CHAIN JOBS\n\nProducts have a lifecycle. After a product is purchased (which is a separate job), it must be received, installed and set up. Then, someone has to learn how to interface with and use it. Someone may also have to transport, clean, store, maintain, upgrade, repair, and dispose of it. While people don’t buy a product so they can clean, repair and dispose of it, a product that simplifies product consumption along one\n---\nor more of these dimensions could differentiate itself in the marketplace. Dyson, for example, created the bagless system for collecting and disposing of dirt in a vacuum cleaner, making consumption more convenient. Shirt makers, who have differentiated themselves through non-iron shirts, serve as another example.\n\nThe jobs along the product lifecycle are called consumption chain jobs. Each consumption chain job is comprised of its own distinct set of desired outcome statements. The purchase process itself can be considered a consumption chain job as customers must research, evaluate and transact the purchase. This ‘purchase job’ is often worth analyzing to help improve the purchase process. We have completed extensive research with Harte Hanks doing exactly that, revealing significant opportunities for retailers to improve the way they sell their products to in-store consumers.\n\nOther consumption chain jobs are also a possible focal point for product improvement and competitive differentiation. Helping bio-meds more easily sterilize a surgical tool, for example, may result in a point of differentiation. Consumption chain jobs impact the customer journey and experience. Understanding the desired outcomes associated with relevant consumption chain jobs gives designers and engineers the information they need to be proficient at design-centered innovation. These inputs are an important ingredient in the recipe for innovation.\n\n60\n---\n# FINANCIAL DESIRED OUTCOMES\n\nWhen buying a product or service, the purchase decision maker (buyer) uses a set of financial metrics to decide whether to buy product A or product B, or to buy from supplier A or supplier B. An understanding of the buyer’s financial needs informs the decisions that lead to product and business model innovation. It is not uncommon to find that buyers consider 40 to 80 financial outcomes (or metrics) when making the purchase decision. A hospital administrator who is responsible for buying medical devices, for example, may be looking for products that reduce the patient’s length of stay, or reduce morbidity rates. These metrics have cost implications that drive the purchase decision.\n\nIn some cases, the buyer is also the user, which are separate roles. In cases like these, it is important to make sure the buyer is wearing the ‘buyer's hat’ when describing the financial metrics used when making the purchase decision. Otherwise outcome statements regarding the core functional job may be uncovered instead.\n\nJobs-to-be-Done Theory unlocks the mystery that has for decades been clouding the understanding of customer needs. Knowing how to classify all the customer’s needs changes everything.\n---\n# 3. THE JOBS-TO-BE-DONE GROWTH STRATEGY MATRIX\n\nOnce a company knows all the customer’s needs, which of those needs are underserved and overserved, and what unique underserved and overserved segments of customers exist, it must decide if and how it will target each segment. For example, managers would want to determine if they should (i) add a new feature set to its existing offering, (ii) develop a new low cost offering, (iii) create a new platform-level solution that gets the job done significantly better, or (iv) do something else entirely.\n\nA company must decide what strategy should be pursued to ensure it wins in the marketplace.\n\nOver the course of many client engagements, we have employed Jobs-to-be-Done Theory to help create a strategy framework that (i) explains what causes new product and service offerings to win or fail in the marketplace, and (ii) helps to select the growth strategy that fits the situation and will ensure a win in the marketplace.\n\nWhen we use Jobs-to-be-Done Theory to examine product successes and failures, we observe the same phenomenon time and time again: new products and services win in the marketplace if they help customers get a job\n---\ndone better (faster, more predictably, with higher output) and/or more cheaply.\n\nThis simple observation led us to the effective classification of five unique growth strategies companies can adopt in the quest to win in a market. It also resulted in the creation of the Jobs-to-be-Done Growth Strategy Matrix, a framework that illustrates when and how these strategies should be used. With this framework, companies can understand past successes and failures and can adopt a strategy to create winning products and services in the future.\n\n# ESTABLISHING THE THEORY\n\nHaving recognized that new products and services win when they get a job done better and/or more cheaply, we set out to transform this insight into a predictive framework for growth. We began by “categorizing the possibilities” using the matrix shown on the next page.\n\nThe matrix suggests that companies can create products and services that are (1) better and more expensive, (2) better and less expensive, (3) worse and less expensive, and (4) worse and more expensive.\n\n63\n---\n|Get|BETTER|BETTER|\n|---|---|---|\n|JOB DONE|+ More|+ Less|\n|BETTER|EXPENSIVE|EXPENSIVE|\n|Get|WORSE|WORSE|\n|JOB DONE|+ More|+ Less|\n|WORSE|EXPENSIVE|EXPENSIVE|\n|Charge MORE|Charge MORE|Charge LESS|\n\nThe matrix prompted us to ask what types of customers might be targeted with a product or service offering in each quadrant. Our experience and the work of others in this field led us to the following five conclusions regarding the four quadrants:\n\n1. A better-performing, more expensive product will only appeal to underserved customers. These are customers who have unmet needs and are willing to pay more to get a job done better.\n\n64\n---\n# 2.\n\nA better-performing, less expensive product will appeal to all customers.\n\n# 3.\n\nA worse-performing, less expensive product will appeal to overserved customers (those with no unmet needs). It will also appeal to nonconsumers. These are people whose current solutions don’t involve the market at all, or who are not even attempting to get the job done as they cannot afford any of the existing solutions.\n\n# 4.\n\nA worse-performing, more expensive product will only appeal to customers for whom limited (or no) alternatives are available. This happens in unique or atypical situations.\n\n# 5.\n\nSome products are “stuck in the middle” (to borrow a term from Michael Porter): they only get a job done slightly better or slightly cheaper. Such a product will likely fail to attract any new customers. This is clearly a poor strategy for a new market entrant, but it may help an incumbent company retain existing customers.\n\nNext, we place the customers in their respective quadrants, highlighting the differences in target customer-type:\n\n65\n---\n# THE JOBS-TO-BE-DONE GROWTH STRATEGY MATRIX\n\n|Get|Win|Win all types of underserved customers|\n|---|---|---|\n|Get|Win|customers only (under-loverserved)|\n|WORSE|Charge MORE|customers with limited options|\n|Get|Win|overserved customers and nonconsumers|\n|Charge LESS| | |\n\nWe concluded that each of the five situations warrant its own distinct strategy. With the goal of creating a framework for proactive strategy formulation, we asked, “What unique strategy can be employed in each of these five situations?”\n\nWe set out to define and name a type of strategy that would work for each unique situation. We chose a naming convention that built upon well-established strategy and innovation terminology and accurately described the uniqueness of the situation.\n\n66\n---\nThe five strategies we identified address all the situations a company can face as it contemplates a product or service strategy. The strategies are introduced in the Jobs-to-be-Done Growth Strategy Matrix shown below:\n\n| |DIFFERENTIATED|DOMINANT STRATEGY|\n|---|---|---|\n|Get|JOB DONE|all types of customers|\n|BETTER|SUSTAINING STRATEGY|SUSTAINING STRATEGY| |\n|Get|JOB DONE|WORSE|\n|DISCRETE STRATEGY|customers with limited options|DISRUPTIVE STRATEGY|\n|overserved customers and|overserved customers and|nonconsumers| |\n|Charge MORE|Charge LESS|Charge LESS| |\n\nThe product/service strategies introduced in this framework are defined as follows:\n\n- Differentiated strategy: A company pursues a differentiated strategy when it discovers and targets a population of underserved consumers with a new product or service offering that gets a job (or\n---\nmultiple jobs) done significantly better, but at a significantly higher price. Examples of offerings that successfully employed a differentiated strategy include Nest’s thermostat, Nespresso’s coffee and espresso machines, Apple’s iPhone 2G, the Herman Miller Aeron chair, Whole Foods’ organic food products, Emirates airlines’ international flights, Bang & Olufsen’s personal audio products, BMW sports cars, Sony’s PlayStation (original model), and Dyson’s vacuum cleaner and Airblade hand dryer.\n\n# 1. Dominant strategy\n\nA company pursues a dominant strategy when it targets all consumers in a market with a new product or service offering that gets a job done significantly better and for significantly less money. Examples of offerings that successfully employed a dominant strategy include Google Search, Google AdWords, UberX, Netflix’s streaming video, Progressive Insurance’s nonstandard automobile insurance, and Vanguard Group’s personal investment services.\n\n# 2. Disruptive strategy\n\nA company pursues a disruptive strategy when it discovers and targets a population of overserved customers or nonconsumers with a new product or service offering that enables them to get a job done more cheaply, but not as well as competing solutions. Examples of offerings that successfully employed a disruptive\n---\nstrategy include Google Docs (relative to Microsoft Office), TurboTax (relative to traditional tax services), Dollar Shave Club’s razor offering (relative to Gillette), eTrade’s online trading platform (relative to traditional financial brokerages), and Coursera’s online educational services (relative to traditional universities).\n\n# 1. Discrete strategy\n\nA company pursues a discrete strategy when it targets a population of “restricted” customers with a product that gets the job done worse, yet costs more. This strategy can work in situations where customers are legally, physically, emotionally, or otherwise restricted in how they can get a job done. Examples of offerings that successfully employ a discrete strategy include drinks sold in airports past security checkpoints, stadium concessions at sporting events, check-cashing and payday-lending services, and ATMs in remote locations.\n\n# 2. Sustaining strategy\n\nA company pursues a sustaining strategy when it introduces a new product or service offering that gets the job done only slightly better and/or slightly cheaper. Examples of offerings that successfully employ a sustaining strategy are plentiful.\n\n69\n---\nA company may have many products and services in one market, each employing different strategies, as defined above. For that reason, it is important to source examples at the product level, not at the company level.\n\nUber, for example, has offerings that make use of three of the strategies: UberBLACK employs a differentiated strategy, while UberPOOL employs a disruptive strategy (see figure below). The importance of this distinction becomes obvious when we begin to apply the model to predict the success or failure of a new product or service:\n\n|Get|UberBLACK|UberX|\n|---|---|---|\n|JOB DONE|\"the original UBER\"|\"better; faster; cheaper than a TAXI\"|\n|Get|Surge Pricing|UberPOOL|\n|JOB DONE|\"demand exceeds supply\"|\"share your ride and save\"|\n| |Charge MORE|Charge LESS|\n---\n# EMPLOYING THE FIVE GROWTH STRATEGIES\n\nThe Jobs-to-be-Done Growth Strategy Matrix can be used to prescribe proactive short- and long-term strategies for success, but to use it, a company must know whether there are underserved and/or overserved segments of customers in the target market. Without this knowledge, there is no way to know which strategy to adopt, and the chance of picking the wrong one is high. For example, in an overserved segment, a differentiated strategy would likely fail, as no customer is seeking a more expensive product or service that will get the job done better. Conversely, in an underserved segment, a disruptive strategy would likely fail, as no customer is seeking a cheaper product or service that would get the job done worse.\n\nThe most effective way to discover whether there is an underserved or overserved population is to segment a market around a complete set of prioritized customer desired outcome statements.\n\nOur Outcome-Based SegmentationTM methodology, which has always been part of our ODI process, was specifically designed for this purpose (see chapter 4).\n\nOnce a company knows where in the matrix its target customers can be found, it can adopt the appropriate strategies for each segment. Let us examine each strategy more closely.\n---\n# Employing a Differentiated Strategy\n\nA differentiated strategy works when a highly underserved segment of customers is targeted with a premium-priced offering that gets the job done significantly better. This strategy results in a disproportionate share of profits and is the strategy pursued by many of the world’s fastest-growing and most profitable companies.\n\nNest, for example, a recent entrant into the home thermostat market, beat Honeywell, White-Rodgers, and other well-established incumbent firms with a product that was targeted at a highly underserved segment of the market, superior in performance, and offered at seven times the price of competing solutions ($250 versus $35). While capturing less than 10% market share, Nest is estimated to have captured over 25% profit share while shaking up the industry and putting its competitors on the defensive.\n\nA differentiated strategy is attractive because it enables a company to enter a market at the high end, capture significant profit share, and work its way down market over time to gain additional market share. This is a way to move from employing a differentiated strategy with an initial product entry to employing a dominant strategy with other products over time. A company can successfully move down market by lowering the price of its older products as it introduces newer and better products into its portfolio, as Apple did with the series of iPhone product offerings, and/or\n---\nby using operational innovation as a means to lower production costs, as Uber did when it employed freelance drivers to supply rides in its UberX offering.\n\n# Incumbents have much to gain by pursuing a differentiated strategy\n\nas they can afford to target their existing products at well-served or even overserved customers once their new, high-profit products are introduced. This puts the incumbent in a position of both profit and market share growth.\n\n# Employing a Dominant Strategy\n\nA dominant strategy is always the most appealing approach for a new market entrant to take because incumbents cannot defend against it. Our experience suggests that companies can win with a dominant strategy if they introduce a product or service that gets the job done (addresses the customer’s unmet desired outcomes) at least 20% better and at least 20% more cheaply. This can be measured with high precision and probability when evaluating a proposed concept against a complete set of desired outcome statements.\n\nNetflix’s streaming services, for example, offered greater convenience than traditional rental stores such as Blockbuster by making it easier to find, obtain, and consume movies. In addition, they reduced the cost of watching a movie by eliminating the annoying late-return fees and enabling customers to watch more content for a low monthly subscription rate.\n\n73\n---\nWe helped Kroll Ontrack enter the electronic evidence discovery market with a dominant strategy. While traditional competitors in this field gathered evidence manually, Kroll Ontrack created a solution that enabled legal teams to get the job done significantly better and more cheaply through the use of digital technology. This strategy led them to immediate success and market leadership that they have sustained for over a decade.\n\nIn any market, an incumbent or a new market entrant can win with a product or service that gets the job done significantly better and more cheaply. Incumbents are less likely to create such a product or service because it could dramatically cut their margins and may require an investment in a new product platform, capabilities, and resources.\n\n# Employing a Disruptive Strategy\n\nThe Jobs-to-be-Done Growth Strategy Matrix confirms that Clayton Christensen, who coined the term disruptive innovation, was correct: companies can win in overserved segments with products that enable customers to get a job done more cheaply, but not as well as competing solutions. Based on our model, we also agree with Christensen that a disruptive strategy successfully serves two customer segments: highly overserved customers (like users of Microsoft Word who switched to Google Docs) and nonconsumers—people who do not buy currently available products.\n---\nA disruptive strategy works in both situations, but for different reasons. It works for current consumers who are overserved, as Christensen’s theory suggests, and are willing to make some sacrifices to get the job done more cheaply. Nonconsumers, on the other hand, are underserved: they simply can’t afford any of the solutions that are currently available. If a product comes along that they can afford, it will allow them to get the job done better than they can currently.\n\nChristensen also correctly identified another phenomenon that occurs in the marketplace when he described disruptive innovation as “a process by which a product or service takes root initially in simple applications at the bottom of a market and then relentlessly moves up market, eventually displacing established competitors.” Seen through the Jobs-to-be-Done lens, the “process of disruption” is best described as the introduction of a series of products, the first of which employs a disruptive strategy that gets the job done worse and more cheaply, followed by a series of products that build on that technology platform, with more and more features, until the newest offerings get the job done better and more cheaply (figure on next page).\n\n75\n---\n# DOMINANT STRATEGY\n\nGet all types of customers\n\n# JOB DONE\n\n# BETTER\n\n- PRODUCT V4\n- PRODUCT V3\n- PRODUCT V2\n\n# Get JOB DONE\n\n# WORSE\n\n# DISRUPTIVE STRATEGY\n\noverserved customers and nonconsumers\n\n# Charge MORE\n\n# Charge LESS\n\nAlthough a new market entrant is more likely to pursue a disruptive strategy, incumbents have an equal or better chance at winning with a disruptive offering if they pursue it. The problem for many companies is that it is often a less profitable strategy. Proponents have to convince management that it will defend against competitors and new market entrants. Since a company is not limited to one product, it can choose, as Uber did, to create separate products to address overserved and underserved customer segments.\n\n76\n---\n# Employing a Discrete Strategy\n\nA discrete strategy is employed as a separate (discrete) part of an existing product strategy: with a discrete strategy, a company takes an existing product and sells it in a unique situation that justifies a higher price. A discrete strategy is best suited for situations in which a higher-priced version of the existing product would be very welcome—or where a captive clientele cannot object. Pursuing a discrete strategy can be very profitable.\n\nThe key to a successful discrete strategy is the ability to identify situations in which the customer, in need of the company’s product, has restricted or no access to it. In such a situation, the company can justify charging a higher price for its purchase. For example, people who are unable to cash a check at a bank because they do not have a bank account have no choice but to pay high fees to cash their checks at an independent check-cashing center. Stubhub.com also capitalizes on this scarcity strategy by allowing tickets that are sold out to be resold or auctioned to people for what the market will pay, often at much higher-than-normal prices.\n\nAs another example, consider airline travelers who are legally prohibited from taking bottles of drinking water through security. This restriction enables concessions at the gates to employ a discrete strategy, as they are now justified in charging significantly more for water (and many other\n---\nfood and beverage items) to travelers. Similarly, movie theaters, sporting arenas, and theme parks restrict what visitors can bring in and consequently are able to employ a similar strategy.\n\nRestrictions resulting from high demand can also justify higher prices. Airlines, for example, typically charge more for seats when supply is tight. It should be noted that although employing a discrete strategy may hold the potential for high profits, it can also be viewed as exploitative by customers and result in public backlash and/or reputational damage as it did in 2016 with pharmaceutical giant Mylan over the high cost of EpiPens.\n\n# Employing a Sustaining Strategy\n\nA sustaining strategy is good for products or services that get the job done just slightly better and/or more cheaply. We define “slightly” as less than 5% better or cheaper. New market entrants should avoid a sustaining strategy, as they will not be offering anything enticing enough to lure customers away en masse from a favorite brand or product. The risk is too high to make a switch. Customers generally will only switch to a new product if it gets the job done upwards of 20% better—which is characteristic of a differentiated or dominant strategy. Here again, using desired outcome statements as the basis for evaluating whether a product will get the job done better (and how much better) is a critical step in bringing data-driven decision making to the innovation process.\n---\nSustaining innovation is a good strategy for an incumbent to follow to maintain market position, market share, and margins. In established markets, getting the job done slightly better and slightly more cheaply lets a company take share from a competitor.\n\n# The Jobs-to-be-Done Growth Strategy Matrix\n\nreveals which growth strategies are available for a company to pursue in a given situation.\n\nAs I shall show in the next chapter, the qualitative and quantitative research methods included in the Outcome-Driven Innovation process secure the information that is needed to determine what situation a company is in.\n\nOnce a company knows what underserved or overserved segments exist and what customer needs are underserved and overserved, it is in a position to use the matrix to select the best strategy for pursuit. Without this ability, innovation remains a game of chance.\n\n79\n---\nPROCESS\n     80\n---\n# 4. OUTCOME DRIVEN-INNOVATION\n\nA company’s success at innovation is dependent on the innovation process it chooses to employ. A process fraught with defects and deficiencies will produce unpredictable results.\n\nWhen it comes to creating an effective innovation process, cobbling together a hodgepodge of incompatible practices and relying on qualitative insights alone just doesn’t work. What companies need is a comprehensive, customer-centric, data-driven innovation process that is built upon Jobs Theory. That is why our Strategyn team has spent the last 25 years creating and refining our Outcome-Driven Innovation (ODI) process. ODI rids the innovation process of its deficiencies.\n\nWhile Jobs-to-be-Done is the theory, Outcome-Driven Innovation is the process that puts it into practice.\n\nODI is a strategy and innovation process that enables companies to conceptualize and invent new solutions that help customers get a job done better and/or more cheaply. It has an 86% success rate because it begins with a deep understanding of the job-to-be-done and employs unique quantitative research methods that enable companies to analyze markets in ways that have never before been possible.\n\n81\n---\nMore specifically, ODI links a company’s value creation activities to customer-defined performance metrics related to the job they are trying to get done—a truly revolutionary concept in the field.\n\nBy supplying a definition of customer needs that the entire organization can embrace, ODI offers a rigorous, controlled approach to needs gathering, needs-based segmentation, competitive analysis, opportunity identification, idea generation and validation, market sizing, and the formulation of market and product strategy. The result is a predictable approach to innovation.\n\n# Define the Customer\n\n# II. Define the job-to-be-done\n\n# III: Uncover Customer Needs\n\n# IV. Find Segments of Opportunity\n\n# V. Define the Value Proposition\n\n# VI. Conduct the Competitive Analysis\n\n# VII: Formulate the Innovation Strategy\n\n# VIII: Target Hidden Growth Opportunities\n\n# IX. Formulate the Market Strategy\n\n# X Formulate the Product Strategy\n\nAs shown in the figure, the Outcome-Driven Innovation process is comprised of 10 key steps.\n\n82\n---\nThe ODI process begins with a definition of the customer and ends with a market and product strategy that creates value for that customer.\n\nThis chapter outlines the process we use and the steps we take to turn Jobs Theory into practice.\n\n# I. DEFINE THE CUSTOMER\n\nBefore a company can understand the customer’s needs, company managers must agree on exactly who the customer is.\n\nGaining such agreement is not easy. When we ask company managers who their customer is, we typically hear, “We have many customers.” Often, they add that customers include both “internal stakeholders and external customers.” To further complicate matters, external customers are typically said to include: influencers, decision makers, buying groups, end users, operators, installers, and others. In a medical device company, for example, external customers include the surgeon, patient, insurer, nurse, operating-room manager, and hospital buying group, among others. It’s true that a company has many customers, but is there a way to simplify matters?\n\nLet’s start with the “Why?” question. Why do we need to know who the customer is? Obviously, we want to know who it is we’re trying to serve, but there is a more tactical reason. From a strategy and innovation perspective, we must\n---\nidentify the customer so we can gain the insights we need to create products and services that will get the job done better and/or more cheaply.\n\nSo, the question becomes: Who holds these insights? Through our work, we have discovered that there are three key customer types (or job executors) that must be considered: the end user (or functional job executor), the product lifecycle support team, and the purchase decision maker.\n\n# THE CORE JOB EXECUTOR\n\nThe core job executor is the person who uses the product or service to get the core functional job done. In many situations, the core job executor and the purchase decision maker are different people. The core job executor can provide your company with the functional metrics (desired outcomes) it needs to figure out how to create a product that will get the job done faster, more predictably, and more efficiently, with higher output or throughput.\n\nFor a medical device manufacturer, the core job executor of a surgical tool is the surgeon. The surgeon may be seeking products or services that will minimize the likelihood of removing healthy tissue or quickly determine the points of affixation for attachment. Core job executors are also able to provide your company with a list of their emotional jobs and related jobs, two other key inputs identified in the Jobs-to-be-Done Needs Framework.\n---\n# THE PRODUCT LIFECYCLE SUPPORT TEAM\n\nThe product lifecycle support team is comprised of the people who install, set up, store, transport, maintain, repair, clean, upgrade, and dispose of the product. In certain situations, the end user may also be part of the product lifecycle support team. Not all of these consumption chain jobs apply in every situation, but the people responsible for the ones that do apply can provide your company with the desired outcome statements that will lead to a product that requires less support.\n\nA product that does not have to be installed, set up, stored, transported, and so on, is far more valuable than one that does. Simplifying or eliminating these consumption chain jobs has two key benefits: (i) it can lower the cost of product ownership, which satisfies the needs of the purchase decision maker, and (ii) it makes the product more convenient to use, which satisfies the needs of the core job executor. All of those responsible for supporting the product throughout its lifecycle are key customers because their insights make it possible for the company to create a more positive customer experience.\n\n# THE PURCHASE DECISION MAKER\n\nThe purchase decision maker is responsible for seeking out and evaluating alternative offerings and deciding which to buy. The purchase decision maker can provide your company with the financial desired outcomes it needs to\n---\nfigure out how to create a product or service that will get the job done more cheaply. For example, the buyer of a surgical tool (who could be an operating room manager, a hospital administrator, or someone holding another title altogether), may be seeking products that will reduce the patient’s length of stay or reduce the likelihood of a recurrence. Financial metrics such as these drive the buying decision.\n\nBy focusing on the core job executor, product lifecycle support team, and purchase decision maker, a company will gain the insights it needs to create a product or service that will get a job done better along multiple dimensions—and more cheaply. More importantly, if your company creates a product or service that addresses the unmet needs of all three of these customers, it will find that influencers will recommend it, distributors and retailers will carry it, those on social media will promote it, people will buy it, and your internal stakeholders will be satisfied by the financial rewards.\n\n# II. DEFINE THE JOB-TO-BE-DONE\n\nMaking the core functional job the unit of analysis is the cornerstone of successful innovation. The core functional job is the stable, long-term focal point around which all other needs are defined and around which value creation should be centered.\n\nDefining the core functional job-to-be-done correctly is a prerequisite to predictable success. Getting it wrong is a big problem, and getting it right is not\n\n86\n---\nthat easy. Defining the job too narrowly will limit the discovery of growth opportunities. Defining the job too broadly will result in non-actionable insights.\n\nFrom our experience, most products only get part of a job done. The goal is to discover the entire job the customer is trying to accomplish. This is why it is incorrect to ask a customer, “What job did you hire that product to do?” as this may not reveal the entire job. Asking this question is a common mistake. It is indicative of a product-centric mindset.\n\nTo avoid defining the job too narrowly, work directly with customers to understand not why they bought your product, but how your product fits into what they are trying to accomplish. Ask, “Why are you using that product? What job are you ultimately trying to get done?”\n\nFor example, if a stove top kettle maker were to ask its customers, “What job did you hire that product to do?” it is likely they would say that they hired it to “Boil water.” That may be correct, but boiling water is just a step in the job the customer is ultimately trying to get done—which is to prepare a hot beverage for consumption. If the stove top kettle maker defines the job too narrowly, then it is at risk of a competitor coming along (like Keurig) with a solution that gets the entire job done on a single platform.\n\n87\n---\nIt is not uncommon for a new competitor to overtake a market by finding the capabilities, resources, funding, technology, and know-how to create an offering that gets the entire job done.\n\nOn the other hand, defining the job too broadly can make it difficult, if not impossible, for the company to tackle the job in its entirety. To prevent this from happening, think about the company, its products and its capabilities and ask, “Can and will the company address this job from beginning to end over time?” If the company does not have or is not willing to acquire the capabilities, resources, funding, and technology and know-how to tackle the broader job then the job is defined too broadly from a practical standpoint.\n\n# Take the customer’s perspective\n\nWhen defining the core functional job, think about the job from the customer’s perspective, not the company’s. For example, a company that supplies herbicides to farmers may conclude that growers are trying to kill weeds, while the growers might say the job-to-be-done is to prevent weeds from impacting crop yields.\n\n# Don’t overcomplicate it\n\nWhile the Jobs-to-be-Done Needs Framework is multilayered and complex, a functional job statement is not. It is important to emphasize that a well-defined functional job statement, and all the need statements we describe, are one-dimensional and mutually exclusive. Cramming everything\n\n88\n---\ninto one complicated statement or a “job story” makes it impossible to later quantify exactly where the customer is underserved. The goal is to separately define all the causal factors that contribute variability to getting the job done. This is often accomplished with 100 or more separate statements, not just one.\n\n# Leave emotion and other needs out of it\n\nWhen defining the core functional job, make sure it is defined as a functional job, and not as a hybrid of functional, emotional and social jobs. A functional job definition does not have social and emotional dimensions. The emotional and social jobs related to the core functional job are defined in a series of separate emotional job statements.\n\nAlso, do not include desired outcomes in the functional job statement. They, too, must be stated separately. So, if the job is to cut a piece of wood in a straight line, don’t say: accurately, safely and quickly cut a piece of wood in a straight line. “Accurately, safely and quickly” vaguely describes needs associated with getting the job done. A statement like: stay awake and occupied while I make my morning commute more fun also fails this test. Here the functional job may be more like: stay awake during a morning commute.\n\n# Define the job, not the situation\n\nDo not define the job-to-be-done as a situation that customers may find themselves in. Rather, define the job around what the customer decides to do in that situation.\n\n89\n---\nExample, commuters may find themselves on a long, boring commute, but having a long and boring ride to work is not a job—it is a situation which commuters find themselves in. You cannot study the job of overcoming boredom because it is not a functional job.\n\nRather, consider what commuters choose to do when they are on a long, boring commute. What they may do is stop at a quick service restaurant to get breakfast while commuting to work (the actual functional job-to-be-done).\n\nSimilarly, a customer may feel bored while waiting in line at a doctor’s office, but again, overcome boredom is not the job, nor is the job to fill time while waiting. Rather, what the customer chooses to do when they are bored is the real job-to-be-done. For example, while you are standing in line waiting to see the doctor, you may choose to use your smartphone to stay informed on topics of interest, book a flight, pay bills, or execute other jobs using a smartphone application. These are the jobs-to-be-done.\n\n# Define the job statement in the correct format\n\nA job statement always begins with a verb and is followed by the object of the verb (a noun). The statement should also include a contextual clarifier. In the job statement listen to music while on the go, the contextual clarification is made by adding “while on the go” to the job statement. Commuters who stop at quick service restaurants on the way to work are trying to get breakfast while commuting to work where “while\n---\n# III. UNCOVER CUSTOMER DESIRED OUTCOMES\n\nWith the core functional job defined, the next step in the ODI process is to create a “job map” for that job. A job map is a visual depiction of the core functional job, deconstructed into its discrete process or job steps, which explains, in detail, exactly what the customer is trying to get done. A job map does not show what the customer is doing (a solution view); rather, it describes what the customer is trying to get done (a needs view).\n\nA job map is focused on the underlying goals of the actions being taken. For example, you wouldn’t say an anesthesiologist is looking at the display (a solution that describes what action the anesthesiologist is taking). Instead, you would say the anesthesiologist is monitoring the patient’s vital signs, which is the underlying goal of looking at the display.\n\nIn addition, a job map is not a customer journey or customer experience map: it does not describe the journey the customer goes through to buy, receive, set up, use, upgrade, clean and maintain a product. These activities are consumption chain jobs that are captured separately and\n\n91\n---\ntreated differently. If you are focusing on the customer journey, you are not focused on the core functional job.\n\nA good job map will describe what the customer is trying to get done independent of all the competing solutions that customers are using. In other words, it will be accurate for all customer situations, regardless of the products they are using to get the job done. A completed job map represents the ideal process flow for that job: with all of the steps in the ideal order for efficient execution.\n\nWe create the job map for a number of reasons:\n\n- The completed job map lays out the long-term strategy for the organization—which is to devise a solution that gets the entire job done on a single platform or with a single offering (which may include hardware, software and services).\n- It is often the case that innovative ideas can come from analyzing the job map, as it points out holes and inefficiencies in existing offerings.\n- From a tactical standpoint, the job map serves as a framework and a guide for capturing the customer’s desired outcomes. For this reason, it is best to create the job map before attempting to capture desired outcome statements.\n\n92\n---\n# THE UNIVERSAL JOB MAP\n\nOur analyses of hundreds of jobs have revealed that all jobs consist of some or all of eight fundamental process steps: define, locate, prepare, confirm, execute, monitor, modify and conclude (see the universal job map). This insight is essential for creating a framework around which customer needs (desired outcomes) are gathered. (To learn more about job mapping, see “The Customer-Centered Innovation Map” in the May 2008 issue of Harvard Business Review.)\n\n|DEFINE|LOCATE|PREPARE|CONFIRM|\n|---|---|---|---|\n|Plan|Gather|Set Up|Validate|\n|Select|Access|Organize|Prioritize|\n|Determine|Receive|Examine|Decide|\n\n|EXECUTE|MONITOR|MODIFY|CONCLUDE|\n|---|---|---|---|\n|Perform|Verify|Update|Store|\n|Transact|Track|Adjust|Finish|\n|Administer|Check|Maintain|Close|\n\nOnce a job map is created for a specific functional job, desired outcomes are captured for each step in the job map.\n\nFor any given job-to-be-done, we often uncover between 50 and 150 desired outcome statements.\n\nCustomers know perfectly well how they measure success when executing a job, and are very capable of dictating those metrics. Those metrics, put another way, are their desired outcomes. A corn farmer, for example, may want to minimize\n---\n# THE DESIRED OUTCOME STATEMENT\n\nDesired-outcome statements must conform to a specific structure and follow a set of stringent rules. This is necessary because differences in structure, terminology, and syntax from statement to statement can introduce unwanted sources of variability that alter the importance and satisfaction ratings customers will give to the statements in a survey. This, in turn, will affect the way customers end up prioritizing innovation opportunities.\n\nA desired outcome statement includes a direction of improvement, a performance metric (usually time or likelihood), an object of control (the desired outcome), and a contextual clarifier (describing the context in which the outcome is desired).\n\nMinimize the likelihood that the music sounds distorted when played at high volume is one example of an outcome statement related to the job of listening to music.\n\nWhen creating a desired outcome statement, remember the following structure:\n\nOutcome statement = direction of improvement + performance metric + object of control + contextual clarifier\n---\n(See my article, “Giving Customers a Fair Hearing,” in the Spring 2008 issue of the MIT Sloan Management Review for additional details on what a need is and the rules to follow when documenting outcome statements.)\n\nDesired outcome statements can be uncovered using any of the popular interviewing methods, such as one-on-one interviews, focus groups, and observational and ethnographic interviews.\n\nWhile most qualitative research has a short shelf life, a complete set of desired outcome statements is an important company asset for years to come, as desired outcomes don’t change over time—only the solutions that address them do.\n\nWith a complete set of desired outcome statements in hand, a company can gain quantitative insights into its market that were never before possible.\n\n# IV. FIND SEGMENTS OF OPPORTUNITY\n\nMarket segmentation is a tool that companies use to target unique offerings to groups of customers that will value them. Over the years, many methods of market segmentation have been developed and implemented.\n\nQualitative methods, including the creation of personas, are used to segment markets using demographic, psychographic, or behavioral categories or stereotypes. Quantitative methods, such as conjoint analysis, aim for greater precision.\n---\nthrough the use of numerical values and calculations. Unfortunately, nearly all segmentation methods, whether qualitative or quantitative, fail to distinguish between customers with different unmet needs, which is the only form of segmentation that will deliver real value.\n\nWe have conducted hundreds of segmentation studies for companies in dozens of industries and have concluded that the differences in people’s needs do not come from different demographics or psychographics. In fact, we have proven that demographic, psychographic, and behavioral and attitudinal data will nearly always fail to explain why customers have different unmet needs. A 28-year-old man from Montana with a college degree can have the same unmet needs as a 55-year-old woman from Florida who dropped out of high school. Both, for example, may be unhappy with their internet service.\n\nThe only way to discover segments of customers with unique sets of unmet needs is to segment the market around unmet needs.\n\nUntil the creation of ODI, this had not been possible, as customer need statements designed for this purpose had not yet been invented. Desired outcome statements defined around the core functional job make effective needs-based segmentation possible.\n---\nCustomers have different unmet needs because subsets of customers often encounter added difficulties that the other customers do not face. These added difficulties create additional unmet needs for that group of customers. For example, in work we completed for Bosch, we discovered that some tradesmen who use circular saws to cut wood in a straight line (the job-to-be-done) had to make more finish cuts (for instance, to fit crown molding in a corner) than others. This means they had to make more blade height and angle adjustments. Because they encountered these additional complexities, they had unmet needs that other tradesmen did not have.\n\nIn work that we completed with an automotive company, we discovered that some drivers who were trying to reach a destination on time (the job-to-be-done) struggled more than others because they had to go to multiple locations during the day, rather than simply to the one destination. Because they had to go to many places, they encountered many different traffic patterns and associated problems (backed up traffic, parking difficulties, etc.). These added complexities made predicting travel time (to accomplish the job-to-be-done) much more difficult. In other words, this group had unmet needs that other drivers did not have.\n\nIn nearly all of the markets we have analyzed, some segments of customers struggle more than others to get a job done. We argue that this presents a unique opportunity—but to seize\n---\n# Outcome-Based Segmentation Methodology\n\nIt, companies must segment the market using unmet needs and not demographic, psychographic, or behavioral data. Our Outcome-Based Segmentation methodology is executed in four steps:\n\n1. First, we analyze the job-to-be-done and capture all of the customers’ needs in the form of desired outcome statements. (The special syntax of these outcome statements guarantees precision and comparability).\n2. Next, we field a survey that is administered to a statistically valid representative sample of customers (usually between 180 and 3,000 customers). Their answers reveal how important it is that they achieve each outcome and how well the solution they use today satisfies each outcome. With this data, we determine which outcomes are most underserved and overserved. Underserved and overserved outcomes represent innovation opportunities.\n3. Third, we use factor analysis and cluster analysis to segment the market into groups of customers with unique sets of unmet desired outcomes.\n4. Last, we include profiling questions we include in the survey to understand what factors cause complexity and make some customers struggle more than others to get the job done. The survey also collects information that reveals the degree to which the different segments we uncovered are underserved and overserved.\n---\n# Why does all of this matter?\n\nIf you do not know what underserved and overserved segments and desired outcomes exist, you will not know which growth strategy to pursue. You will be guessing at innovation and competing on luck. Knowing if and why segments of customers have different unmet needs is the key to an effective market and product strategy. A new product will fail if it doesn’t address unmet needs in a segment of the market that is large enough to warrant the investment. A value proposition will fail to connect with customers if it does not align with unmet customer needs.\n\nWhen we conduct segmentation analysis, we find segments of customers that are underserved (they have unmet needs), overserved (they’re getting extraneous features, perks, or services they don’t value), and appropriately-served (all of their needs are satisfied without any extraneous features). One market may have three underserved segments, while another market may have three overserved segments. A disruptive strategy in the former case would fail, as no segment of the market is overserved. A differentiated strategy in the latter case would fail, as no segment of the market is underserved.\n\nBecause no market is homogeneous, outcome-based market segmentation is an essential ingredient in the formulation of market and product strategy. The key is to discover\n---\n# meaningful segments—hidden segments that offer the opportunity for value creation.\n\n# V. DEFINE THE VALUE PROPOSITION\n\nA number of years ago we worked with Coloplast’s wound care product team. More specifically, we focused on wound care nurses (the core job executors) whose job-to-be-done was to treat a wound. We used our Outcome-Based Segmentation methodology to reveal a segment of underserved nurses, and the findings resulted in a new value proposition that led to double-digit growth in less than six months. How did Coloplast achieve these results? To paraphrase hockey great Wayne Gretzky, Coloplast “skated to where the puck was going to be.”\n\nAt the time, all other wound care companies had built their value propositions around some variation of “We help wounds heal faster.” Coloplast figured out that talking about speed of healing was akin to skating to where the puck had been. Sure, at some point in the past, wound care nurses had been underserved along that dimension and that value proposition had resonated with them. But those days were long gone.\n\nWhen we conducted Outcome-Based Segmentation for Coloplast, we found a segment of wound care nurses whose top unmet needs had nothing to do with speed of healing. Instead, 10 of their top 15 unmet desired outcomes related to “making sure the wound doesn’t get worse.” It turns out that in many wound treatment situations, the patient unwittingly\n---\nmakes the wound worse, and avoiding those complications was a challenge for nurses. Coloplast realized that preventing complications was where the puck was going to be.\n\nColoplast went to market with its new wound care value proposition: “We prevent complications.” Without changing its products or its pricing—simply by focusing its messaging and sales efforts on nurses’ unmet outcomes—Coloplast achieved double-digit growth.\n\nThis is not an isolated incident. Our first success repositioning an existing product line was with Cordis Corporation back in 1992. Cordis experienced a 3-point increase in market share by aligning the strengths of its products with the unmet needs of the interventional cardiologist. In 2014, Arm & Hammer’s Animal Nutrition division realigned its value proposition and achieved over a 30% increase in year-to-year revenue.\n\n# What is the secret to a winning value proposition?\n\nThe unmet needs of today represent the winning value propositions of the future. Knowing which desired outcomes are underserved—enables a company to secure a unique and valued competitive position. This is the essence of strategy, and it is best tackled through the effective use of Jobs Theory. To secure a winning value proposition, a company must (1) know where in the job customers are underserved, (2) define the value proposition that communicates to\n\n101\n---\ncustomers that their needs can be satisfied, and (3) do everything in its power to satisfy the targeted unmet needs better than its competitors.\n\nThe best way to figure out where the customer is underserved is through the application of Outcome-Based Segmentation. It was designed for this purpose. To create a winning value proposition, a company must know why a segment of customers is underserved, along which dimensions they are underserved, and to what degree. Once a company knows those three things, it can define a value proposition in a way that communicates its intent and ability to address all the unmet needs.\n\nOnce the value proposition is defined, the company must fulfill its promise. First, it must point out to customers ways in which its product or service already addresses the unmet needs it has discovered. Next, it must accelerate development of product and service features in the pipeline that further address the targeted unmet needs. Finally, it must create or invent new features that address any remaining unmet needs that are within the sphere of its value proposition. Coloplast worked over a period of years to address all of the unmet needs associated with preventing complications.\n\nA value proposition that is tied to unmet needs aligns company employees around a common vision and is integral to a company’s long-term success.\n\n102\n---\n# VI. CONDUCT THE COMPETITIVE ANALYSIS\n\nWhy should you conduct competitive analysis? Is it merely to see which features of competitors’ products are technically superior? Or is the goal to gain the insight that is needed to create products and services that get a job done better and/or more cheaply than competing solutions? We argue that the latter should be the goal. Therefore, comparing feature sets— “speeds and feeds” —of competing products is a waste of time. It is an outdated approach that provides irrelevant information.\n\nWe conduct competitive analysis by having customers quantitatively evaluate competing offerings against a complete set of desired outcome statements. That process reveals precisely which offerings get the job done better and which get it done worse. These customer insights help along two fronts: (1) they pinpoint precisely which desired outcomes to address to offset the strengths of competing offerings, and (2) they reveal which underserved desired outcomes exist in the market as a whole, thus offering a path for leapfrogging all competitors and establishing a unique and valued competitive position.\n\nThe same survey that is fielded to gather the data needed to perform the Outcome-Based Segmentation analysis is used to gather the information needed for this type of competitive analysis. In the survey, we determine the importance of each desired outcome and the level of satisfaction job executors have with the leading products (the competitive product set).\n\n103\n---\nOnce this work is completed, an evaluation of competing products can begin. This can best be understood through the example of Bosch's ODI-based competitive analysis with dummy data of the competitive North American circular saw market.\n\n# DESIRED OUTCOME\n\n|STATEMENT|IMP|SAT|OPP|DeWalt|Makitz|\n|---|---|---|---|---|---|\n|Minimize the likelihood that debris flies up in the air when guiding the blade along the cut line, e.g., into the user's face, eyes, etc.|8.9|3.2|14.5|3.1|3.3|\n|Minimize the likelihood of inadvertently moving off the cut line/path when the cut path/line gets covered with dust|8.7|3.8|13.5|4.2|3.4|\n|Minimize the time it takes to set the angle of the blade; e.g., make a bevel adjustment; etc.|8.6|4.1|13.0|5.0|3.6|\n|Minimize the likelihood of snagging the cord on the material when making a long cut|8.2|3.7|12.7|3.8|3.6|\n|Minimize the time it takes to place a saw back in service when the power cord is cut track when finishing the cut|7.0|2.5|11.5|2.5|2.5|\n|Minimize the likelihood that the cut goes off|7.8|4.2|11.4|3.6|4.8|\n|Minimize the time it takes to secure the saw from falling when it is not in use, e.g., from a ladder; rafter, etc.|6.7|2.7|10.7|3.0|2.6|\n|Minimize the likelihood of dropping the saw when lowering it from ladder/roof|7.8|5.1|10.5|5.0|4.8|\n\nFirst, we defined the job executor and the job-to-be-done: tradesmen who are trying to cut wood in a straight line. Then, we captured 75 desired outcome statements through\n---\ncustomer interviews. Next, we surveyed 270 tradesmen, including users of the two best-selling brands, DeWalt and Makita. We asked the job executors to rate the importance of each of the 75 outcomes and their level of satisfaction with the circular saw they used.\n\nThe table shows the results of that survey for eight of the outcome statements. It lists the outcome statement, the importance of the outcome, the satisfaction with the outcome, the opportunity score calculation, and the satisfaction scores of DeWalt and Makita circular-saw users.\n\nWith this type of quantitative data on each of the 75 outcome statements, Bosch was able to draw some solid conclusions:\n\n- Bosch was able to determine which of the 75 desired outcomes were “table stakes.” Table stakes are desired outcomes that are very important and very satisfied by existing products. Therefore, they cannot be ignored by a new entrant into the market.\n- Bosch could see which outcomes were better satisfied by DeWalt and which were better satisfied by Makita. This not only revealed the strengths and weaknesses of each competitor, but enabled Bosch to determine the technical reasons for their success, thus setting the direction for ideation.\n- Because 14 of the 75 outcomes had an opportunity score greater than 10, Bosch could safely conclude\n\n105\n---\nthat these 14 outcomes were underserved outcomes (unmet needs). Eight of these 14 outcomes are shown in the table above.\n\n- Bosch knew that satisfying the 14 unmet outcomes significantly better than DeWalt and Makita would enable Bosch to occupy a unique and valued competitive position: it would be satisfying unmet needs that no other competitor had been able to satisfy. This is the essence of strategy and the reason for competitive analysis.\n- Bosch could see whether and where DeWalt or Makita had strengths that were adding cost but not value, as represented by outcomes with strong satisfaction values, but low importance scores. With this insight, Bosch was able to avoid adding features that were unnecessary and costly.\n\nODI-based competitive analysis reveals customer insights that are not ordinarily available to an organization. Knowing how customers measure value and how competing offerings stack up enables an organization to create products and services that get the job done better and/or more cheaply, which is the ultimate goal of any innovation process.\n---\n# VII. FORMULATE THE INNOVATION STRATEGY\n\nIs there a way to choose an innovation strategy that relies on something better than gut feelings and hunches? The answer is yes: there is a highly reliable way to pick a winning innovation strategy. An innovation strategy, as we define it, is a plan that details which outcome-based segments and which underserved outcomes a company is going to target and how it is going to target them (either with existing offerings, improved products and services, or altogether new offerings). The innovation strategy also outlines the order in which the segments will be targeted and provides a timeline for implementation.\n\nIt’s easiest to understand the process when you see it in action. Consider the work we did with the Bosch circular saw product team. One segment we discovered through Outcome-Based Segmentation was comprised of tradesmen that mostly cut 2x4s. Customers in that segment were overserved because they were getting more benefits than they needed or wanted from the saws they were using. They made short cuts where precision did not matter and all of their needs were satisfied. On the other extreme, we found an underserved segment of tradesmen who routinely made long, finish cuts that required precision, and who often had to make angle cuts that required them to adjust the blade height and angle. That segment had 14 unsatisfied outcomes.\n\nWith knowledge of these segments, we were able to formulate the innovation strategy. Success in any market comes by helping customers get a job done better and/or\n---\nmore cheaply, and Bosch had a number of options to consider. One option was to target the overserved segment with a circular saw that got the job done more cheaply (a disruptive strategy). While a viable option, it did not align with Bosch’s desire to create a premium-brand circular saw for the North American market. Another option was to introduce new laser-based technology to the market. While this sounded exciting, that technology would have had little impact on getting the job done better and would have added to the cost, a sure recipe for failure.\n\nThe option that Bosch pursued was to stick with existing technology and to add features to the platform that would address the 14 underserved outcomes in the one underserved segment, yet cost less than competing solutions (a dominant strategy). This was their innovation strategy. They knew precisely what segment and unmet outcomes to target and what technology platform to use to achieve their goals. Bosch engineers addressed the unmet needs with the CS20 circular saw, which was the company’s best-selling circular saw in North America for over 10 years.\n\nWhen building an effective innovation strategy there is no room for hunches or guesswork: the qualitative, quantitative, and analytical methods that comprise our ODI process provide the insights needed to formulate a robust and reliable innovation strategy.\n\n108\n---\n# VIII. TARGET HIDDEN GROWTH OPPORTUNITIES\n\nDeciding which unmet desired outcomes to target for growth is the essence of strategy and the most important decision a company will make. Everything a company does is tied to this decision.\n\nTo make this decision, we again rely on the statistically valid quantitative data we have gathered to conduct the Outcome-Based Segmentation analysis. One quantitative study usually provides us with all the data we need to effectively execute the entire ODI process.\n\nOnce the outcome-based segments are discovered and segments are targeted for pursuit, we are ready to determine which unmet needs should be targeted in each segment to (i) help the customer get the job done better, and/or (ii) help the customer get the job done more cheaply.\n\nTo prioritize the opportunities, we employ our Opportunity Algorithm. This algorithm enables us to determine which outcomes are (i) important to customers, and (ii) not satisfactorily achieved with the solution(s) they are currently using to get the job done.\n\n# THE OPPORTUNITY ALGORITHM\n\nThe mathematical formula we use is as follows:\n\nOpportunity score = outcome importance + max(outcome importance – outcome satisfaction, 0)\n\n109\n---\nThis formula calculates the opportunity score for each desired outcome statement, thus revealing those that represent the best opportunities for growth. For example, if 200 out of 270 circular saw users (74% or 7.4 on our scale) rate the outcome minimize the likelihood that the cut goes off track at a 4 or 5 for importance (on a scale of 1–5, with 5 representing highest importance), and only 75 of the 270 users (28% or 2.8 on our scale) rate the satisfaction of the outcome at a 4 or 5 (on a scale of 1–5, with 5 representing greatest satisfaction), then that outcome has an opportunity score of (7.4) + (7.4 – 2.8) = 12.0. In our experience, an opportunity score of 10 or greater indicates that the outcome is underserved.\n\n# THE OPPORTUNITY LANDSCAPE\n\nThe Opportunity Landscape shows visually which outcomes are underserved and overserved. As shown in the figure, there are three main sections: (1) the underserved section (on the right), which includes all outcomes with an opportunity score of 10 or greater, (2) the appropriately served section (in the middle), and (3) the overserved section (on the left), in which the outcomes’ satisfaction exceeds their importance.\n\nAll of the outcomes included in the quantitative survey are plotted on this landscape, revealing with a high degree of precision where the targeted segment is underserved and overserved.\n\n110\n---\n# OVERSERVED OUTCOMES\n\n# Importance\n\nThis approach clearly points out which outcomes to target for growth. The upper right section of the landscape points out the table stakes, which are important outcomes that existing products satisfy and that new products must also satisfy to win in the marketplace. The overserved outcomes in the left-most area become targets for cost reduction. If existing products include costly features that address these overserved outcomes, replacing them with lower-cost features can help customers get the job done more cheaply.\n\nThe outcomes in the lower part of the shaded area on the right are the most underserved. Addressing those outcomes will enable the customer to get the job done better.\n---\nThe chance that a development team will develop a product that addresses the most underserved outcomes to target if they don’t know precisely what those underserved outcomes are is extremely low. But with the knowledge of precisely what those underserved outcomes are, the team’s chance for success goes up dramatically.\n\nBut what if the development team knows precisely what those underserved outcomes are? The chances for success go up dramatically. This is the power of Outcome-Driven Innovation.\n\nThe Opportunity Algorithm and the Opportunity Landscape are invaluable tools when trying to figure out which outcomes to target for growth.\n\n# IX. FORMULATE THE MARKET STRATEGY\n\nThe Outcome-Driven Innovation process includes qualitative research methods that are used to discover the customer’s job-to-be-done and their desired outcomes. It also includes quantitative research methods that are used to discover outcome-based segments of opportunity and to identify which desired outcomes in each segment are underserved—these are needs that are unmet. With this information in hand, a company has the customer-centric, data-driven inputs it needs to formulate a market strategy.\n\nAn effective market strategy should align the strengths of a company’s product offerings with the customer’s unmet\n---\nneeds. This is best accomplished through the marketing activities shown in the figure below. We recommend the following steps:\n\n1. Decide which offerings to target at each outcome-based segment.\n2. Communicate the strengths of those offerings to customers in the target segment.\n3. Include an outcome-based value proposition in communications.\n4. Build a digital marketing strategy around unmet outcomes.\n5. Assign leads to ODI-based segments.\n6. Arm the sales team with effective sales tools.\n\n|Target existing offerings at|Highlight value proposition in|Assign leads to ODI-based segments|\n|---|---|---|\n|Define the value proposition|Enable sales team to align solution with customer needs| |\n|Message existing product strengths|Build online campaigns around outcomes| |\n\nLet’s look at how each element of the market strategy is enhanced when it is informed by outcome-based market research.\n\n113\n---\n# Decide which offerings to target at each outcome-based segment\n\nThe first step in defining the market strategy is to determine which current product offerings to target at each of the outcome-based segments that have been discovered. This should be decided based on “fit”: choose the offerings that best satisfy the unmet outcomes of customers in each outcome-based segment. For example, we once helped a manufacturer of industrial pumps discover a segment of customers that were underserved because they frequently encountered conditions that led to cavitation (the formation of air bubbles). The company had a number of products that addressed this problem well, but it had never targeted those products at the underserved segment with the right messaging. Knowing to target those offerings at that segment was the first step to success.\n\n# Communicate the strengths of those offerings to customers in the target segment\n\nIn one of Strategyn’s first engagements, we helped Cordis discover that one of its existing products satisfied a number of outcomes that were not well-satisfied by top competing offerings. The “un-messaged strengths” of this product were subsequently communicated to customers. The result was a significant increase in market share: from 1.5% to 5% over the next six months. Knowing that a product has features that are a competitive strength in a segment of the market is an important insight when it comes to aligning a product portfolio with customer needs.\n\n114\n---\n# Include an outcome-based value proposition in communications\n\nUsing ODI, Coloplast’s wound care division discovered a segment of wound care nurses that had 15 underserved outcomes, 10 of which were associated with making sure a wound did not get worse. While Coloplast’s competitors focused on how their products helped wounds heal faster, Coloplast decided to go with an outcome-based value proposition. It promoted the fact that its products would “prevent complications” and highlighted the product features that addressed the associated outcomes. With this new value proposition, the company achieved double-digit growth in less than six months.\n\n# Build a digital marketing strategy around unmet outcomes\n\nWhen potential customers use Google to find and evaluate product alternatives, they rarely start by entering the product name and model because they have yet to discover it. Rather, they enter keywords or phrases that are associated with the job-to-be-done, such as a job step or a specific desired outcome they are trying to achieve. With ODI-based research, these keywords and phrases are known to the company, which can use them as the foundation for online campaigns, dramatically improving buyer awareness of its product. Any time a potential customer uses Google to find out how to address an unmet outcome they will see the\n---\ncompany’s ad and find its product. A similar strategy can be used to improve SEO results for those same keywords.\n\n# Assign leads to ODI-based segments\n\nMany companies process all leads in the same way even though customers have different unmet outcomes. However, by using a short 5–10 question survey (on a website or lead-generation tool), a company can accurately determine which outcome-based segment a specific prospect belongs to. With this insight, the prospect can be guided toward the solution that will best address their underserved outcomes.\n\n# Arm the sales team with effective sales tools\n\nLastly, the sales team can be taught how to identify what outcome-based segment a customer or prospect belongs to and guide the conversation accordingly. Approaching a customer with the right value proposition and a clear understanding of their situation and unmet needs goes a long way to building credibility. In 2014, Arm & Hammer’s Animal Nutrition Division used ODI to align its offerings, messaging, and sales efforts around certain underserved segments and outcomes it had discovered. The result was impressive: The Animal Nutrition Division achieved over 30% year-to-year revenue growth from 2013 to 2014 without changing its product or pricing—a clear demonstration of the power of aligning marketing and sales efforts around the customer’s job-to-be-done.\n\n# X. FORMULATE THE PRODUCT STRATEGY\n\n116\n---\nAn effective product portfolio strategy will guide a company in (i) improving its products to better serve the unmet needs of customers in each targeted outcome-based segment, and (ii) will offer a solution that eventually gets the entire job done on a single platform.\n\nOnce the underserved outcome-based segments are uncovered and prioritized, the company can take the seven courses of action shown in the figure below for each segment:\n\n|(1)|Borrow features from other company offerings.|\n|---|---|\n|(2)|Accelerate offerings in the pipeline and R&D.|\n|(3)|Partner with or license from other firms.|\n|(4)|Acquire another firm to fill a gap.|\n|(5)|Devise a new feature set.|\n|(6)|Devise new subsystems and/or ancillary services.|\n|(7)|Conceptualize the ultimate solution.|\n\n|Borrow features from other company offerings|Partner with or license from other firms|Devise a new feature set|\n|---|---|---|\n|Define the value proposition|Conceptualize the ultimate solution| |\n|Accelerate offerings in the pipeline and R&D|Acquire another firm to fill the gap|Devise new subsystems and/or ancillary services|\n\nLet’s look at how each activity is enhanced when it is informed by outcome-based market research.\n\n117\n---\n# Borrow features from other company offerings\n\nWhy reinvent the wheel? Innovation does not necessarily require invention. Innovation is the ability to use technology (existing or new) to address an unmet customer need. Knowing exactly which outcomes are underserved in a target segment allows a company to analyze its product portfolio to see if any of its current products or services possess a feature that addresses one or more of those outcomes. This can save significant development time and effort.\n\nWhen we helped Microsoft discover opportunities to improve its software assurance offering, it turned out that many of those opportunities could be addressed with tools the company used internally to get the job done. Instead of starting from scratch, the assurance teams were able to package internal products for commercial use.\n\nA catalog of product features and the desired outcomes they address could be a valuable asset for any company, but especially for big company with hundreds or even thousands of offerings. Such a tool makes it possible for product teams across the company to leverage what the company has already invented.\n\n118\n---\n# Accelerate offerings in the pipeline and R&D\n\nWhen we helped Cordis discover opportunities in the angioplasty balloon market, one underserved outcome rose to the top of the list: minimize the likelihood of restenosis—that is, the recurrence of the blockage. Upon receiving this insight, my contacts at the company told me that the R&D team was working on a device, called a stent, which had the potential to address this unmet outcome. Recognizing the size of the opportunity and the importance of being first to market, the R&D team put additional resources on the project and was the first to market with a product that generated $1 billion dollars in revenue over the next few years.\n\nThe stent had already been in the works, but it was just one of about 40 initiatives in total. It was only when the company gathered and prioritized its customers’ underserved desired outcomes that it realized that the stent deserved more funds and attention. Other initiatives were less lucky: those that did not speak to customers’ needs were defunded altogether.\n\nLeveraging efforts that are already under way can save time and effort when creating products and services that will get the job done better.\n\n# Partner with or license from other firms\n\nWe have often worked with hardware manufacturers who discover that many of the underserved outcomes remaining in the market cannot be addressed with a hardware solution: a software or service offering is required.\n---\nAt that point, it makes sense to partner with or license from a firm that has expertise in that area.\n\nKnowing precisely what needs are underserved makes choosing a partner easier. For example, we worked with an automobile manufacturer that discovered it did not have the capabilities it needed to address the underserved outcomes in a market of interest. With the list of prioritized underserved outcomes in hand, we evaluated over 100 possible partners. The goal was to look at the potential partners and determine how well they could address each of the underserved outcomes. Through this analysis, we found the three firms that held the most promise. The company interviewed management from the three firms and eventually picked an effective partner.\n\nA prioritized list of underserved outcomes makes the perfect scorecard against which to evaluate firms that will help you get more of a job done and/or get the job done better.\n\n# Acquire another firm to fill a gap\n\nArm & Hammer’s Animal Nutrition Group acquired a business, Vi-COR, that provided it with a complementary product to use in its dairy business. The framework Arm & Hammer used to help justify the acquisition was grounded in ODI-based research: The group was able to demonstrate that its current offering failed to get the entire job done and showed that Vi-COR’s products were going to help address some high-priority underserved outcomes.\n\n120\n---\nVi-COR also provided a service component that helped address other top opportunities identified in dairies. Company management determined that Vi-COR was operating in a very important niche, providing a very important solution to dairy producers. Without the ODI prioritized list of underserved outcomes, the company might have overlooked this important potential acquisition.\n\n# Devise a new feature set\n\nKnowing what features to add to a product to help customers get more of the job done and/or get the job done better is the key to success in product innovation. Adding the right features is dependent on knowing what needs are underserved. Knowing, for example, which 15 of the customer’s 100 desired outcomes are underserved lets a company focus its efforts on those 15, thereby ending wasted effort and increasing the chances of success to a dramatic 86%.\n\nCompanies do not lack ideas. They often have thousands of ideas. What they need is insight into the customer’s underserved outcomes. This is what the ODI process provides. Once everybody in the organization knows precisely what the customer’s unmet outcomes are, all company resources can be aligned to address them—resulting in the systematic and predictable creation of customer value.\n\n121\n---\n# Devise new subsystems and/or ancillary services\n\nHardware and technology-based companies often stunt their growth potential because they resist adding a necessary service component. When the entire job-to-be-done is defined and the underserved outcomes are revealed, a company may realize that the only way to satisfy the remaining underserved outcomes is by adding an ancillary service offering. With a list of underserved outcomes in hand, a company can define exactly what value the service offering must deliver.\n\nAdvanced Medical Optics followed this approach when it added a service offering to complement its sale of lenses, insertion systems, laser vision correction systems, and other devices for cataract and refractive surgical procedures. Offering this service had immediate positive results on its Net Promoter Score, the perception of its overall business practices, and its Customer Loyalty Index. Two years later, AMO was awarded the prestigious Omega Management NorthFace Award, which recognizes world-class customer satisfaction.\n\n# Conceptualize the ultimate solution\n\nA company’s ultimate goal should be to provide an offering that gets the entire job done on a single platform. Such a platform often requires hardware, software, and service subsystems or components. Conceptualizing this ultimate solution provides a company with a long-term vision of\n---\nwhere it needs to go and what will be necessary to secure or maintain a market leadership position.\n\nWith the ultimate solution in mind, a company is in a position to make the decisions that will allow it to stay on track, stay focused, and not let a competitor own the ultimate platform-level solution.\n\nFor example, the ultimate solution we presented to an agricultural company we were working with required skills and capabilities that went far beyond the company’s capabilities at that time. As the years went by, the company watched a competitor make the acquisitions that were required to create, build, and own this platform-level solution. This got management’s attention. With no time to waste and clarity in where the market was heading, the company worked to make its own acquisitions so it could remain relevant in the market.\n\nBy taking the seven steps outlined above, a company can systematically create solutions that will get a job done better and/or more cheaply. Defining the actions it will take is the essence of an effective product strategy.\n\n123\n---\n# CASE STUDIES\n\n# MICROSOFT\n\nDiscovering hidden growth opportunities\n\nMicrosoft was under pressure to build additional value into its Software Assurance offering. In exchange for a flat fee, corporate customers received operating system upgrade rights if they signed a multiyear contract.\n\nHowever, there was mounting evidence that the offering was not providing the right mix of benefits to customers at a time when IT budgets were facing increased scrutiny. Microsoft was aware that some key customers were questioning the value of the offering. Even more telling, renewals of Software Assurance agreements were declining, putting a significant amount of potential revenue at risk. “We were a business facing a potential crisis,” recalls Dave Wascha, a Microsoft director.\n\nTraditionally, Microsoft had viewed the Software Assurance offering simply as a vehicle for the efficient purchase of software upgrades. The market was changing, however, and Microsoft realized that the Software Assurance offering needed to change with it. As one tech reporter observed, “There appears to be some disconnect between how Microsoft wants to sell its software and how businesses want\n---\nto buy.” Improvements were necessary to give customers additional reasons to purchase.\n\n# Software License Management\n\nSoftware license management is not a trivial task for large corporations, and it typically involves multiple stakeholders. Microsoft focused on understanding the jobs of two particular decision makers—procurement managers and IT professionals. Procurement managers are responsible for understanding, selecting, and negotiating license agreements (their job-to-be-done). IT professionals work closely with procurement managers in assessing upgrade needs, evaluating agreements, implementing licensing renewals, and managing software licenses once purchased (their jobs-to-be-done).\n\nDrawing on interviews with procurement managers, the ODI Practitioner dissected the job of purchasing a license agreement, uncovering approximately 75 desired outcome statements. Customer interviews were also conducted with IT professionals, resulting in the discovery of well over 100 desired outcome statements related to their core functional job-to-be-done and related job statements.\n\nTwo ODI-based quantitative surveys were created and deployed. Approximately 100 procurement managers and 300 IT professionals prioritized their respective desired outcome statements for importance and level of satisfaction.\n\n125\n---\n# The results of the Outcome-Based Segmentation analysis\n\nrevealed underserved segments of procurement managers and IT professionals. Dozens of underserved outcomes were revealed for both IT professionals and procurement managers. Wascha recalls that as they started to look at the job the job executors were trying to get done, “We realized that we were only really engaging with the customer in one tiny piece of their job—the purchase of the software. But this was just part of a much bigger challenge that they faced. We were not engaging with them in many of these other areas that were very important to them and where they were very dissatisfied.”\n\n|10.0|OPPORTUNITY|IMPORTANCE|MAX (IMPORTANCE - SATISFACTION, 0)|\n|---|---|---|---|\n|9.0|8.0|Over-Served| |\n|7.0|Limited Stakes, Opportunity|Qpp >10| |\n|6.0|Ripe for Disruption|Solid Opportunity|pp 12|\n|5.0|4.0|Potential for Disruption|Opportunity|\n|3.0|2.0|Opp >15|Extreme Opportunity|\n|1.0|Appropriately Served|Under-Served|Opportunity|\n|0.0| | | |\n\n0.0     1.0      2.0     3.0     4.0     5.0     6.0     7.0     8.0     9.0     10.0\n\nIMPORTANCE      IT Pro Jobs\n\nIT Pro Outcomes\n\nProcurement Manager Outcomes\n\n126\n---\n# The Opportunity Landscape for Purchasing and Managing Software Licenses\n\nThe Opportunity Landscape for purchasing and managing software licenses revealed a number of related jobs and desired outcomes that were underserved. Many could be addressed by products already developed, but not previously integrated into the offering.\n\nBased on this improved understanding of the job its customers were trying to accomplish, Microsoft adopted a lifecycle management view of the business, from the customer’s perspective. Microsoft discovered opportunities related to software acquisition and deployment at the start of the lifecycle. In the middle of the lifecycle, there were opportunities in the areas of maintenance, training, patching, and security. Finally, at the end of the lifecycle, Microsoft identified opportunities to create value for customers during disposal of old PCs—an immense issue for many of its customers.\n\n# The Innovation and the Impact\n\nOne of Microsoft’s most profound discoveries was that the company had already developed many solutions for internal use that would help customers achieve their desired outcomes and get jobs done.\n\nHowever, those solutions had never been packaged together in a cohesive and compelling offering. According to Wascha, “The most amazing thing is that we really did not write that many new lines of code to meet customer needs. Rather, it was about looking at the job in its flowchart, looking at\n---\nsoftware assets that we already had, and then piecing them together as solutions to each part of the job.\n\nFor example, Microsoft discovered that customers were having trouble keeping track of the number of PC software licenses they owned—a necessary step in compliance. Microsoft already had a licensing server that could address this need, but the company had never considered including it as a part of the Software Assurance offering. Similarly, IT professionals were having difficulty anticipating potential software conflicts when they deployed a new operating system. Again, Microsoft already had a tool that could address this need, one that the company had been using internally. Microsoft decided to include a version of that tool in its Software Assurance offering.\n\nCustomers also wanted to reduce the time and cost involved in training employees to use the upgraded software. To address this, Microsoft implemented a training voucher program that gave employees access to certified Microsoft trainers. Once again, this was a program that Microsoft had already developed but had never been made a formal component of the Software Assurance offering.\n\nMicrosoft also uncovered an unmet need related to prevention of internal security violations. As in the other examples, Microsoft already had a successful product that it was able to make part of the Software Assurance package. The product included rule templates that enabled companies\n\n128\n---\nto quickly set software and PC access restrictions for different groups of employees—a key element of internal security. And the list of enhancements to the Software Assurance offering could go on.\n\nThe benefits to Microsoft from adopting the ODI approach were dramatic and immediate. In the year Microsoft announced the changes to the Software Assurance offering, they beat their revenue goal by over 10%. This was even before the fully revised product was available. Customer satisfaction increased, and complaints about Software Assurance dropped.\n\nIn subsequent years, Microsoft was able to substantially grow the Software Assurance business and dramatically increase annual renewal rates. Microsoft discovered it was sitting on a growth business once value was measured from the customer’s perspective. Wascha noted, “Salespeople loved the new product offering. They felt they had something of value to offer.”\n\n# KROLL ONTRACK\n\nDiscovering hidden growth opportunities Kroll Ontrack was faced with a strategic opportunity and a challenge. The opportunity lay in the potential market for an electronic document discovery solution for the legal industry. The challenge? Creating an effective market strategy for a business still in its infancy.\n---\n“The term ‘paperless office’ was just coming into vogue,” notes Andrea Johnson, Kroll Ontrack’s vice president of marketing and communications. Lawyers were finding that many documents relevant to a legal proceeding were available only in electronic form. Competitors who had historically served the market were able to meet the paper discovery needs of lawyers but were ill-equipped to manage the discovery of these electronic records.\n\nIn response to a client’s request, Kroll Ontrack started a small business focused on electronic document discovery. It struggled at first to define a strategy based on customer needs. As Ben Allen, CEO of Kroll and former Kroll Ontrack president, explains, “We knew the potential for electronic discovery—all of the underlying foundational elements suggested that this would be an important industry opportunity. What we didn’t know was how to understand what clients wanted to achieve in a way that could be translated into an efficient and effective strategy for growth. The electronic discovery market was so new that if you asked clients what features they wanted, they didn’t know what you were talking about.”\n\nIn order to define a market strategy for a product offering that was still in its infancy, Kroll Ontrack relied on Strategyn’s ODI methodology. “After going home and reading 17 strategy books,” Allen recalls, “what struck me about Strategyn’s ODI thinking was the concept that\n---\noutcomes wouldn’t change over time. We were really at the stage where we were trying to figure out what lawyers were trying to accomplish, not what features they wanted.\n\nDrawing on interviews with lawyers (the job executors), the ODI Practitioner uncovered approximately 100 desired outcome statements related to finding information that supported or refuted their cases (the job-to-be-done). The outcome statements were rated for importance and satisfaction by a statistically valid sample of the population. Outcome-Based Segmentation and other analyses were performed.\n\n|0.0| |OPPORTUNITY = IMPORTANCE + MAX (IMPORTANCE - SATISFACTION, 0)|9.0| | | | | | | |\n|---|---|---|---|---|---|---|---|---|---|---|\n|8.0|Over-Served|Table ~Limated| | | | | | | | |\n|7.0|Disruption| |Ripe for|Opp &gt;10| | | | | | |\n| | |5.0|6.0|Opp &gt;12|High Opportunity| | | | | |\n|4.0|Potential %r|Disruption| | | | | | | | |\n|3.0| | | | | | | | | | |\n|2.0|Opp &gt;15|Extreme| | | | | | | | |\n|1.0|Appropriately Served| |Under-Served|Opportunity| | | | | | |\n|0.0| | | | | | | | | | |\n|0.0|1.0|2.0|3.0|4.0|5.0|6.0|7.0|8.0|9.0|10.0|\n\nIMPORTANCE\n\nElectronic Discovery Outcomes\n\nInformation Management Outcomes\n\n131\n---\n# The innovation and the impact\n\nUsing ODI, Kroll Ontrack gained a better understanding of the opportunities presented by electronic discovery, and it used this knowledge to develop an effective product strategy. Kroll Ontrack focused on the job of e-document discovery and the outcomes that members of the legal community desired, which led the company to develop groundbreaking new solutions.\n\nFor example, Kroll Ontrack rolled out a new product called Harvester and some related imaging tools that addressed the top two underserved electronic discovery outcomes: Minimize the likelihood that relevant documents are excluded from capture, and Minimize the likelihood that information is inadvertently altered or destroyed while the data is being captured. Because two other outcomes, Minimize the likelihood of making coding errors and Minimize the time that it takes to obtain all information relating to a specific subject, were also important, Kroll Ontrack added a custom-coding feature to its online review tool.\n\nThe ODI-based research guided the pursuit of numerous other innovations as well. For example, Kroll acquired a clever search technology that employs clustering algorithms to enable a user to find documents associated with a keyword even if that keyword does not occur in the document. This was done to satisfy two of the outcome opportunities identified. In addition, Kroll Ontrack launched ESI Consulting, which offers clients expert guidance in tackling the task of capturing all relevant documents. Lastly, it rolled\n---\nout a new trial preparation tool that targeted litigation process outcomes.\n\nReflecting on the top opportunities that the ODI methodology revealed, Allen recalls, “There has been a ton of innovation at Kroll around these outcomes. These are the heart of it. We brought forward all elements that an electronic document has available and made them available to filter or search by. And we have continued to add features along the way.” By adding innovative features to its electronic discovery platform every quarter to address additional underserved outcomes, Kroll Ontrack made it very difficult for competitors to catch them.\n\nKroll Ontrack’s electronic discovery product employed a dominant strategy—it got the job done better and more cheaply than competing solutions. Prior to Kroll Ontrack, competitors had been attempting to address the challenges presented by electronic documents with modifications to the paper document discovery systems. In contrast, “Kroll Ontrack leapfrogged the competition with a revolutionary innovation,” observes Johnson, “because it added capabilities based on the job that customers were trying to get done rather than seeking to improve the current solution platform.”\n\nA myopic definition of the market ultimately cost the leading competitors their discovery business. Allen concludes, “If these big, well-established companies had understood the\n\n133\n---\noutcomes that customers really valued, they could have dominated this business. I think they saw themselves as paper document processing companies, not discovery solutions providers. The leaders today—none of them were players in the old paper discovery business.\n\n# Kroll’s Market Strategy\n\nKroll’s market strategy has paid off. Kroll Ontrack grew its revenue in this market from $11 million to over $200 million in about 6 years. For years, it was the industry leader in both market share and revenue. The company received acclaim from industry experts and customers for quality and was named the top electronic data discovery system by readers of Law Technology News. Kroll Ontrack was also recognized by Law Firm Inc. as the most-used electronic discovery provider for seven years in a row.\n\n# ARM & HAMMER\n\nArm & Hammer’s Animal Nutrition business (Church & Dwight) was determined to grow. Scott Druker, director of the business, chose to employ Strategyn and its Outcome-Driven Innovation methodology to formulate and drive its growth strategy. A mere year after adopting Strategyn’s Jobs-to-be-Done thinking, the business experienced over 30% revenue growth, far outpacing its competitors. Scott sat down with Tony Ulwick to talk about their journey.\n---\nUlwick: Scott, how would you describe the problem that Church & Dwight was trying to solve?\n\nDruker: We had gone through several product development efforts and launches in recent years that were disappointing despite the technical success of the products. The commercial response was lackluster. So, not wanting to repeat history and recognizing that innovation was an important aspect of our growth strategy, we asked ourselves, “Okay, how can we do things differently?” I was familiar with your work, and I thought it would be an interesting approach to take given the challenges we were facing with our animal nutrition products in the dairy market.\n\n# How would you describe Arm & Hammer Animal Nutrition’s traditional approach to innovation?\n\nWe relied largely on discussions that we’d had with customers, with people in the industry that we worked in, the dairy industry in particular. We’d talk to nutritionists and to dairy producers, asking, “What are some of your biggest issues?” We mainly focused on the nutritionists, who are the people the dairy producer hires to help put together the ration to feed the cows. Our products go into those rations, so even though the dairy producers are buying the products, most of our efforts were focused on the nutritionists.\n---\nWould it be fair to say that before using ODI, part of the issue was not knowing which customer to target to obtain the needed insights?\n\nWe’ve always known the end customer is the dairy producer, and ultimately the dairy cow, but yeah, we were basically getting our innovation information from a consultant that was being hired by the dairy producer. So yeah, I think absolutely part of our issue was we weren’t identifying the right people to speak to.\n\nWhy did you choose to go with Strategyn and ODI over other options?\n\nPrior to joining Church & Dwight and taking lead of the Arm & Hammer nutrition business, I led a business that sold anti-microbial actives and formulated products, and I was responsible for developing markets and new products. I first came across the ODI concept while reading The Innovator’s Solution, by Clayton Christensen. That book makes reference to your work and the concept of Jobs-to-be-Done, and that led me to read your book, What Customers Want. It was natural for me to decide that if I was going to do something to improve innovation, I might as well go to the people who wrote the book on it.\n---\nWe’re happy that you did. Let’s talk about the results. What surprising insights came out of the Strategyn/ODI research?\n\nThe research helped on many fronts. First, it helped clarify in our minds that the customer is the dairy producer, not the nutritionist. Next, understanding that the “job” they were trying to get done had little to do with nutrition and was focused squarely on optimizing herd productivity. Then it was certainly eye opening to see how many desired outcomes the dairy producer is trying to satisfy in a given day, in a given month, in a given year. I think we identified over 165 different desired outcomes. We homed in on optimizing dairy herd productivity, and when we started prioritizing the outcomes through quantitative research, the most surprising thing was how many opportunities there were, and how few of those opportunities were directly related to nutritional ingredients for the dairy producer. Our whole business is focused on supplying nutritional ingredients and supplements, so that was probably the most surprising thing.\n\nScott, how would you describe the market strategy that Strategyn recommended based on the customer insights?\n\nClearly the market strategy started with our collective recognition of whom we needed to target for value creation. Even though we don’t sell directly to the dairy producer, we need to make sure that we keep our eye on the dairy\n---\nproducer and the job they are trying to get done. We have relationships with various other components in the supply chain, but at the end of the day, we need to create value for the dairy producer.\n\nThe second major focus was changing our messaging and how we speak about things—moving away from talking about product benefits and features and toward talking about outcomes, and linking our products to the outcomes they satisfied. The third focus was taking a look at the job map, which had 15 steps in it, and saying, “Let’s take a step back and look at where we can position ourselves in the marketplace that impacts the majority of these steps.”\n\nThe other part of the market strategy is segmentation: recognizing that the normal demographic methods for segmenting customers, while helpful for sales resource prioritization, are not helpful for opportunity identification, and hence solution identification. One of the things I go back to, one of the surprising things that came out of the research, was that a large dairy or mega dairy can share many of the same unmet needs and outcomes as a small dairy. And geography wasn’t necessarily the determinant either: ultimately there were some key outcomes that decided what kind of segmentation there was. Thinking about that—the segments and how we position the business—has become an important part of our marketing strategy.\n---\n# How did the Outcome-Based Segmentation solution impact your market strategy?\n\nOutcome-Based Segmentation gave us a more realistic way to look at the market. Over time we had confused sales prioritization with real customer market segmentation. At the end of the day, we only have a certain number of salespeople, so we tend to want to call on the larger dairies, because if you get one of them, they have a measurable impact on your business. We just assumed that all those large dairies share certain needs, and that small dairies have completely different needs. The data showed that was not the case, so that absolutely was surprising.\n\n# What other market strategy recommendations provided your team with immediate value?\n\nOne of the key recommendations that we initially focused on was to go after the low-hanging fruit, to find out if and where our existing products addressed some of the most underserved outcomes that were identified. We basically got into a room, listed 165 of the outcomes on the wall, color coded the segmentation, and identified the 10 or 11 outcomes that all segments shared and identified as high priorities. We literally went through each one of our products and tried to see which outcomes those products could potentially help address.\n---\nWe then focused a lot on the redesign of our whole messaging. We took all our product literature and our website and redesigned and focused them on outcomes. Our whole marketing talk and speak turned to outcome-based, and that is very prevalent now in our whole business. People talk about outcomes. Now you hear salespeople saying, “We need to position this in terms of an outcome a person is trying to satisfy.” So that is rewarding, to hear people starting to think that way. I think some of the basic elements of the recommendations we followed pretty quickly.\n\nThere were several recommendations made around becoming a total solution provider to the dairy. We probably have been a little slower to respond on that, but it’s not ignored; it’s probably something I am spending more time on now, thinking about.\n\n# Was there a reason the organization was ready for change?\n\nYes. We had a product—a protective license product—that we had developed and launched. We spent seven years developing it based on hearing in the market that there was a need for it. I would argue and defend it as the best in the market, and we launched it to much fanfare. Then it kind of just did ho-hum. So that example was fresh in our teams’ minds, and we could say, “What went wrong here?” It’s not the product development, and certainly not our marketing. It’s certainly not our company’s reputation, and it’s not our\n---\nOverall knowledge of who to call on, or our ability to access any of the particular decision makers. It’s just that we didn’t ask the right people the right questions. That was probably one of the easiest ways to start convincing people: we had just had a fresh example of a product innovation that was just lackluster.\n\n# Of all the actions taken to date, which had the most impact on revenue?\n\nClearly, changing our messaging helped us differentiate our products versus competitors’. Whenever you pick up a trade journal in our industry, you see a cow in an ad and virtually the same story: “We can help improve milk production, protein production, fat production, dry matter intake.” It doesn’t matter which ad you are looking at; it is virtually the same thing. So, what we have been able to do is say, “That’s not really what the people are focused on.” It’s actually surprising when you think about it. Of the 165 outcomes that the dairy producer mentioned, not one of them identified any of those key points that you see in almost every one of the ads. So, we didn’t necessarily have to go change our pricing or products or redesign or reformulate the products. The biggest impact was changing the messaging so people understood, “Oh that’s what that product can help me get done.”\n---\n# Market Strategy Implementation\n\nCan you describe how the market strategy implementation rolled out?\n\nBy the end of 2013 we got all the results, and we spent the end of 2013 really going through the first stage of looking at our products, digesting the information, and asking ourselves, “Okay, how do we act on this data?” Second, we tried to understand how our products could address some of the underserved outcomes, and we started thinking about the segments and how we should change some of our sales conversations based on what segments a customer might fall into. By the time 2014 rolled around, we had really started the wholesale change to be forward facing to the market—changing our positioning and our Web design and promotional literature. By the first quarter of 2014 and certainly by the second quarter of 2014, we were full on into repositioning how we go into the marketplace.\n\n# Results Timeline\n\nHow long did it take for you to start seeing results?\n\nI would say we started to see results almost immediately. You start seeing the results in terms of the conversations you are having, and then you start seeing incorporation of products. We had a phenomenal 2014. Off the charts. The dairy economy helped—it was a factor in it. I think our execution, our messaging, and our positioning all contributed to an outstanding year.\n---\n# Can you share how the ODI-based market strategy impacted your revenue growth?\n\nI’ll say we grew revenue greater than 30% and the ODI process played a significant role in that growth. Every one of our products had double-digit growth.\n\nIn addition, in January 2015, we made an acquisition of a business, Vi-COR, that got us into more species than just dairy. It brought a very nice complementary product for us to use in dairy, but it also got us into the poultry and swine markets, which is exciting for the growth of our business.\n\nWhen we made this acquisition, the template I used to explain to our executive team why it made sense was generated from the ODI work. I was able to show them that here is a job map, and here are outcomes the dairy producer is trying to satisfy, and here is why Vi-COR’s products are going to help us with some of these key outcomes. Vi-COR also brings in a service component that helps address some areas that we identified as some of the top opportunities in dairies. I found that this small business was operating in a very important niche, providing a very important solution to dairy producers. I used the work from ODI to screen for acquisitions, and that work assisted in the acquisition.\n---\n# How did these successes impact the organization and you personally?\n\nProbably the biggest personal gratification I have is looking at my team and seeing that they are embracing the methodology. I think it helped them think more broadly about who we are as a business and what we do, and what opportunities are out there.\n\n# How would you describe your experience working with Strategyn?\n\nIt was terrific. I believe the agriculture nutrition industry was a little bit outside of where Strategyn normally works. All the same, you guys are great, professional, intelligent, right on time. Great communications—it was definitely really enjoyable to work with the group. And I speak for my whole team.\n\n# That is always good to hear. Thank you. And just as a final question, is there anything else you would like us to share with the readers of this case study?\n\nThat no one else in agriculture should try this! But more seriously, the thing that I would share is, once you get involved and you start to think about a market through this lens, the notion of defining your customer as a job executor, and then asking customers what job they are trying to get done instead of asking them what solutions they want is such a basic, simple, and obvious way to approach product.\n---\n# BOSCH\n\n# Discovering hidden growth opportunities\n\nWhen the Robert Bosch Tool Company decided to enter the North American professional circular saw market, many challenges stood in the way of its success. Randall Coe, director of product development, noted that management had four key objectives in mind: “We wanted to (1) enter the market with a saw that reflected the high-quality image carried by the Bosch name, (2) compete effectively and outperform the products produced by DeWalt and other competitors in the U.S. market, (3) ensure our product would be carried by the big-box retailers, e.g., Home Depot and Lowe’s, and (4) price the resulting product at a competitive industry price point while yielding the desired profit margin.”\n\nThere had not been much innovation in the circular saw market for many years, and it was perceived as both mature and commodity-like, so Bosch knew that success would depend on the company’s ability to uncover and\n---\ninexpensively address market opportunities that others had missed.\n\nTo identify opportunities for product innovation, the Bosch team targeted professional tradesmen (the job executors) who were responsible for cutting wood in a straight line (the job-to-be-done). They targeted roofers, framers, contractors, finish carpenters, plumbers and electricians. Through interviews with the professional tradesmen, the ODI Practitioner dissected the job-to-be-done into its component parts through the use of a job map and worked to capture a complete set of approximately 85 desired outcome statements.\n\nNext, ODI-based quantitative research methods were employed. Through a controlled online survey, approximately 270 professional tradesmen rated each desired outcome statement for (i) its level of importance, and (ii) the degree to which it was satisfied, given the circular saws they were currently using. This data was used to run a variety of data analyses (Outcome-Based Segmentation, competitive analysis, etc.).\n\nNot surprisingly, the results showed that in the market on average (when looking at all 270 responses combined), there were no unmet needs. This meant that to discover unmet needs, Outcome-Based Segmentation practices were required. Strategyn’s Outcome-Based Segmentation methods revealed four segments of opportunity, one of which\n\n146\n---\nmade a perfect target for Bosch. This hidden segment of opportunity, which was comprised of primarily finish and advanced carpenters, represented over 30% of all users. They were underserved because they made more finish and angle cuts and had to make frequent blade angle and blade height adjustments. The segmentation analysis and Opportunity Landscape for this segment clearly revealed that 14 of the customer’s approximately 85 desired outcomes were unmet with this segment of users.\n\nKnowing where to focus its efforts was the key to Bosch’s success, as it dramatically simplified idea generation.\n\n# The innovation and the impact\n\nThe team went through the list of 14 opportunities, systematically generating ideas that would better satisfy each underserved outcome. Coe reports, “We started by focusing on the underserved outcomes related to the cord and devised the DirectConnect™ cord system concept. This innovation, which connects the extension cord directly to the saw, reduces the chances that users will cut the cord or catch the plug on the material being cut when making a long cut, while maintaining their ability to lower the tool from a ladder to the ground using the cord. This system also reduces repair costs and down time because if the cord gets cut, the user can simply grab another extension cord and continue working. Satisfying all of these outcomes at the same time is what made this a true innovation.”\n\n147\n---\n“Next,” Coe says, “we focused on line-of-sight issues and devised a way in which the user can confirm that the cut is on track when starting the cut, while making the cut, and when approaching the end of the board. Designing a cutout in the table helped to better satisfy all of these underserved outcomes.” The team went on to address the remaining unmet outcomes, in all cases devising low-cost features that would dramatically improve customer satisfaction.\n\n# 10.0 OPPORTUNITY = IMPORTANCE + MAX (IMPORTANCE SATISFACTION, 0)\n\n# 9.0\n\n| |Over-Served| |Limited|\n|---|---|---|---|\n| |Ripe for|Disruption| |\n| | |Solid Opportunity| |\n| | |High Opportunity| |\n|Potential for|Disruption| | |\n|Appropriately Served|Under-Served|Opportunity| |\n| | |Extreme|Opp >15|\n\n0.0\n\n0.0    1.0     2.0     3.0     4.0     5.0     6.0    7.0     8.0    9.0     10.0\n\nIMPORTANCE\n\nBosch successfully addressed the 14 underserved outcomes in the newly discovered segment with a new product—the CS20 circular saw. Remarkably, Bosch accomplished this without increasing product cost—a prime management objective. This was largely due to the fact that the highly\n\n148\n---\nregarded DirectConnect™ system significantly cut product cost while adding customer value.\n\nMost new products and services fail to improve customers satisfaction in areas of unmet needs by more than 10%. Concept testing revealed that the CS20 circular saw was projected to increase the level of customer satisfaction by approximately 38% (with total satisfaction levels rising from 63% to 87%).\n\nBefore the saw was released, the Bosch team used these findings to help gain the support of two key distributors: Lowe’s and Home Depot. Given limited shelf space and a competitive market, Bosch had to convince them that the CS20 circular saw uniquely addressed a number of unmet customer needs and did so at a competitive price. The data made a convincing case, and Lowe’s and Home Depot requested that Bosch delay the release of the product by two months so that enough saws could be manufactured to meet the anticipated demand.\n\nBosch successfully entered the North American market with what quickly became one of the top-selling and top-rated circular saws. Bosch’s innovations, which addressed cord and line-of-sight issues, resulted in a highly successful product launch and dramatic improvements in customer satisfaction. Improvements in handling, adjustments, and other functions only added to the new value created.\n---\n# Discovering hidden growth opportunities\n\nAbbott Medical Optics, or AMO (formerly Advanced Medical Optics), is a leading provider of lenses, insertion systems, laser vision correction systems, and other devices for cataract and refractive surgical procedures.\n\nHistorically a technology-based company, AMO recognized the need to improve its approach to service innovation in an effort to attract and retain customers through secondary service offerings. Angelo Rago, AMO’s senior vice president of global customer services, noted that a cycle of incremental service improvements had resulted in “me too” service delivery mechanisms and support services— services that looked just like AMO’s competitors’ offerings. Worse, Rago and his team recognized that sales were being lost to competitors due to poor customer service.\n\nTo identify opportunities for service innovation, AMO targeted the materials managers (the job executors) who were responsible for replenishing ophthalmic lenses for cataract implant surgeries (the job-to-be-done). They targeted medical facilities in which cataract surgeries were performed.\n---\nThrough interviews with materials managers, the ODI Practitioner dissected the job-to-be-done into its component parts through the use of a job map and worked to capture a complete set of approximately 100 desired outcome statements. By studying the job map, AMO discovered that a traditional distinction between front-office and back-office responsibilities for materials management was artificial.\n\nNext, ODI-based quantitative research methods were employed. Through a controlled online survey, approximately 200 materials managers rated each desired outcome statement for (i) its level of importance, and (ii) the degree to which it was satisfied, given the service offerings they were currently using. This data was used to run a variety of data analyses (Outcome-Based Segmentation, competitive analysis, etc.). The analyses resulted in the discovery of a large segment of materials managers that had approximately 50 underserved outcomes (see the Opportunity Landscape).\n\nThe analysis of this segment revealed a flaw in AMO’s service delivery approach and in the process of obtaining ophthalmic lenses more generally. The process of communicating problems to AMO and its competitors frustrated materials managers. They were often unsure about whom to contact to get a particular problem resolved because the issues they confronted ranged from delivery and lens consignment to invoicing and returns.\n---\nmanagement recognized that delays often resulted because materials managers had to contact several people within AMO before finding someone who could help them. Matters were further complicated by the fact that the resolution of a given problem might require the involvement of several people and/or several layers of approval within AMO.\n\nWith knowledge of the customer’s underserved outcomes, an ODI Practitioner led a team of AMO sales, technical support, customer service, accounts payable, logistics, and IT infrastructure managers through the process of developing solutions to satisfy the most promising opportunities. Valuable solutions were conceptualized and later validated and implemented.\n\n# 10.0\n\n| |OPPORTUNITY|IMPORTANCE + MAX (IMPORTANCE SATISFACTION, 0)| |\n|---|---|---|---|\n|9.0| | | |\n|8.0|Over-Served| | |\n|7.0| | | |\n|6.0|Ripe for Disruption| | |\n|5.0| | | |\n|4.0|Potential for Disruption| | |\n|3.0| | | |\n|2.0| |Opp >15| |\n|1.0|Appropriately Served|Under-Served|Opportunity|\n|0.0| | | |\n\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0\n\nIMPORTANCE Lens Replenishment Outcomes\n\nVendor Interaction Outcomes\n\n152\n---\n# The innovation and the impact\n\nTo improve its service delivery approach, AMO transitioned from a transaction approach to customer service to a relationship approach to customer service. As Rago explained, “Before, we had a first-in, first-out approach to customer service. A customer had no relationship with the person who happened to answer the phone when they called. Now, the top clients are automatically directed to a dedicated advocate who can handle anything that the customer needs. The next tier of clients goes to regional customer care teams, or pods—a small team that works together to know the customer, and manage any concerns that the customer has.”\n\nAMO introduced advocates and regional customer care teams. Customers then had a single point of contact within AMO and a voice inside the company to address the range of issues they were confronting. If a customer issue required additional research, an AMO advocate or member of the care team took responsibility for problem resolution, ensuring that customers with tricky problems no longer had to navigate opaque internal processes without a guide. Physical proximity among team members of different functional areas also improved communication and coordination to resolve customer problems. As a result, the customer’s problems were resolved faster and more thoroughly.\n---\nIn addition, the customer service team assumed a more strategic role within AMO. Advocates and care team members reached out to customers on a regular basis to identify potential issues. Regional sales calls included customer care team members to ensure that everyone knew what changes were taking place and which accounts were being threatened. This enabled AMO to proactively head off potential account problems and better anticipate how to grow account revenues.\n\nAMO’s management team also learned that not having the right lenses on hand for a surgical case was a big problem for materials managers. Because this particular problem has more to do with the ongoing back-office operations of a surgical center than with vendor service and support, it had not occurred to AMO or its competitors to address it. But once the ODI methodology brought the problem to AMO’s attention, the company was able to develop an advanced schedule-planning and inventory management software module that facilitated accurate and timely replenishment of lenses based on upcoming case needs, current inventory, and other considerations.\n\nThe implementation of these service offerings had immediate positive results:\n\n- AMO’s Net Promoter score increased by nearly 10% in the year following introduction of the service innovations.\n---\nA MarketScope industry survey showed that industry perceptions of AMO’s overall business practices and of the quality of its products and services has improved significantly since introduction of the innovations.\n\nAMO’s corporate survey showed that its customer loyalty index improved by 14 percentage points in the year following the introduction of the innovations.\n\nTwo years later, AMO was awarded the prestigious Omega Management NorthFace Award, which recognizes world-class customer satisfaction.\n\n# HUSSMANN\n\n# Discovering hidden growth opportunities\n\nHussmann decided to reexamine its LED product line. Used to illuminate refrigeration cases for cold beverages and perishable and frozen foods, the product line offered reduced operating costs—especially when compared with fluorescent lighting. But in the four years following the launch of the product line, Hussmann had seen little reaction from customers. Convenience stores, supermarkets, and warehouse stores simply didn’t warm up to the idea.\n\n“LEDs showed minimal volume and little impact on the lighting business,” remarks Clay Rohrer, an innovation and business development manager at Hussmann. “We tried to penetrate the business for four years, and we were missing the boat.”\n---\nAnshuman Bhargava, a Hussmann LED product manager and also an innovation and business development manager, notes, “We were going out and searching the globe for new technologies that seemed to make sense. They were always focused on energy or controls, which were trends in the market. We weren’t tied to needs of the customer. We were tied to technologies.”\n\nLEDs, which offer energy efficiency, represented a potentially billion-dollar market, but customers were skeptical about the up-front costs and overall value of the technology. Hussmann knew that success would depend on the company’s ability to uncover and inexpensively address specific customer needs so that Hussmann’s LED product would stand out on performance dimensions that mattered to customers.\n\nTo find and exploit opportunities for competitive differentiation, Hussmann applied Strategyn’s ODI methodology. Drawing on the responses of shoppers, store merchandisers, and executive merchandisers, Hussmann dissected the complementary jobs of those key groups.\n\n“We had been selling refrigerated boxes, not merchandising solutions,” Rohrer remarks. “Historically, we had left the merchandisers alone and focused more on the product procurement people. Now, we went to different levels of\n\n156\n---\nmerchandisers and to the shoppers, and we combined insights from all these audiences.\n\nThis extensive, multi-audience effort resulted in the capture of over 300 desired outcome statements. Next, using ODI-based quantitative research techniques, Hussmann had 1,500 shoppers, 200 store merchandisers, and 50 executive merchandisers prioritize those outcomes.\n\nAmong the outcomes prioritized by executive merchandisers, many were underserved, as is highlighted in the Opportunity Landscape. Of these unmet outcomes, eight related to display case lighting: for example, executive merchandisers wanted to increase the likelihood that the lighting would be uniform and display the true product color.\n\nThese needs became the foundation for Hussmann’s LED innovation and differentiation efforts.\n\n# The innovation and the impact\n\nKnowing where to focus its efforts was the key to Hussmann’s success. The team went through the eight underserved outcomes, developed engineering specifications for each and a new portfolio of LED lights, and then began systematically devising low-cost features that would dramatically improve customer satisfaction on each outcome.\n\n157\n---\nRohrer reports, “We used ODI to tweak an existing design and didn’t have to redesign the whole thing. We looked at it from the ODI perspective of the job of illuminating products. What are the problem areas? What are the focus areas? Then we grouped the opportunities into common themes that we had to address to win the market. Uniform illumination, level of brightness, and energy efficiency were key things. We focused on them and developed solutions.”\n\n# 10.0\n\n|OPPORTUNITY|IMPORTANCE|MAX (IMPORTANCE SATISFACTION, 0)|\n|---|---|---|\n|9.0| | |\n|8.0|Over-Served|Table Limited|\n|7.0| | |\n|6.0|Disruption|Ripe for|\n|5.0| | |\n|4.0|Potential for|High Opportunity|\n|3.0| | |\n|2.0| |Opp >15|\n|1.0|Appropriately Served|Under-Served Opportunity|\n|0.0| | |\n\n0.0 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0\n\nIMPORTANCE\n\nMerchandising Outcomes\n\nIllumination Outcomes\n\nHussmann created an innovative line of LED products—the EcoShine LED Lighting System—and focused its value proposition on satisfying the eight underserved outcomes in the merchandising of perishable food products. The EcoShine system matched competitors on certain outcomes.\n---\nfor LEDs, such as energy efficiency and long life, but it was a breakthrough innovation because it added value on several new merchandising outcomes that competitors had overlooked. Hussmann advertises feature comparisons between the EcoShine line and its competitors on these specific outcomes. EcoShine boasts superior uniform horizontal and vertical lighting within a display case, reduced glare, and truer product colors (because the lighting is optimized for the display of meat, dairy, and produce). The product has been a hit in the market. “In only one year, we’ve gone from a fraction of a digit to double digits in market share in North America,” Bhargava notes. Backed by a strong sales commercialization effort, the product received favorable press coverage in industry publications such as Supermarket News, generated favorable buzz as a “home run” at trade shows, and created excitement among utility companies, who are providing incentives for customers to adopt this energy-efficient system.\n\nIn addition to generating immediate revenue growth (previously measured in thousands of dollars and now measured in tens of millions, according to Rohrer and Bhargava), the ODI process resulted in three other important benefits for Hussmann.\n\n1. Cost reductions: Hussmann differentiated its LED products without increasing product cost—a prime objective. Rohrer describes how this was possible: “We made\n---\nincremental changes to an existing platform in all the right areas, based on how customers measure value. We hit all the key outcomes at the right level without raising costs. In fact, we reduced costs dramatically because we were so focused on just changing the things that mattered.\n\n# 2. Enhanced speed to market:\n\nBhargava notes that having a prioritized list of customer needs, stated in clear, unambiguous language, made it possible to “move through the early stages [of product development] much more quickly … so that we could really get to work. We were able to translate the desired outcomes very clearly for engineering so that they understood what to develop. We didn’t leave anything for them to guess at.” He also notes that the insights gained through the process enabled Hussmann to set optimal prices based on the value of each SKU.\n\n# 3. Enhanced credibility:\n\nThe prioritized customer outcomes have changed the strategic dialogue within the firm. Rohrer states, “It is a whole different conversation with the executive team. It used to be a long decision process based on arguments over whether customers would buy some new product or not. ‘Oh, did you think of this? Of that?’ Now they see the exact need set and can evaluate how a solution might address those needs.” Bhargava concurred, “ODI brings a lot of credibility. You no longer get questioned by internal stakeholders—operations and engineering, supply chain, sales, and so on.”\n---\nBeyond these project benefits, ODI has created a fundamental shift in Hussman’s innovation culture. As Rohrer describes it, “We’ve shifted the culture from a technology-driven company to a customer needs-driven company.”\n\n161\n---\nPRACTICE\n       162\n---\n# 6. BECOMING AN ODI PRACTITIONER\n\nJobs Theory intuitively makes sense, and Strategyn, through its application of ODI, has proven that Jobs Theory is very effective in practice. With the contributions of leading academics like Clayton Christensen, and Jobs Theory champions and practitioners around the world, a new paradigm is on the horizon. I think it is safe to predict that companies will become more customer-centric, job-focused and outcome-driven. So, what is next?\n\nMany companies we’ve worked with over the years have wanted to put Jobs Theory and ODI into practice on a large scale. Most of them didn’t want to be dependent on a third-party consulting firm over the long term for their ongoing success. Instead, they wanted to have and use their own practitioners and make Jobs Theory and ODI part of their DNA and organizational fabric. What our clients and other companies often want to know is this: “How do we put Jobs Theory and ODI into practice within our organization?”\n\nIn this chapter and the next, I will answer that question. While the next chapter addresses the needs of the organization, this chapter is written for the practitioners—the individuals who will take it upon themselves to apply Jobs Theory, practice ODI, and drive change in their organizations.\n\n163\n---\nIn my days at IBM, I took on this role—the change agent, or the maverick as I was called. I was the internal consultant who wanted to help IBM find a better way to innovate. I took on the role of the practitioner as I tried to change the way people thought about innovation. I remember how I appreciated the help I received from internal IBM supporters, my mentors and managers. I also remember how I’d wished that someone would come along and offer me the process, tools and instructions I would need to be successful.\n\nNow that I have the process, tools, templates and instructions, I have shared them with you. You can find all of these materials embedded in our online platform at Strategyn.com/ODIpro. Mentoring support is also available. With these resources, you’ll be able to effectively lead strategy and innovation engagements within your organization.\n\nSo, do you have what it takes to become an ODI Practitioner? Is this course right for you? Let me help you decide.\n\nBecoming an ODI Practitioner is not easy and it’s not for everyone. Speaking as an ODI Practitioner, however, I can tell you that, to me, it is the most fulfilling and rewarding career I could imagine. As an ODI Practitioner, you have the opportunity to:\n\n164\n---\n- Work with the smartest and most inspiring people in business.\n- Work on projects that span dozens of markets, learning more about each market than would otherwise be possible.\n- Contribute to the creation of products and services that improve people’s lives.\n- Learn a valuable skill set that can be employed throughout your lifetime.\n- Train your mind to think in a uniquely disciplined fashion.\n- Contribute to the success of others and society as a whole.\n- Have fun along the journey.\n\n# What does the ODI Practitioner do?\n\nThe ODI Practitioner is responsible for mastering the application of Jobs Theory and performing all aspects of the ODI process in a wide variety of contexts to meet the specific needs and expectations of the organization. An ODI Practitioner must be able to:\n\n1. Initiate an ODI project.\n2. Uncover the customer’s needs.\n3. Gather quantitative data.\n4. Discover hidden opportunities for growth.\n5. Formulate the market strategy.\n6. Formulate the product strategy.\n---\nAs I detail the ODI Practitioner’s responsibilities for each of these 6 phases, I am going to reveal the 84-step process that our Strategyn ODI Practitioners follow when they engage with clients. This insight will help you get a good sense of what it takes to execute an ODI project and the skill sets that are required to do so. Then you can decide if a career as a Jobs Theory and ODI Practitioner in your organization is right for you.\n\n# I. INITIATE AN ODI PROJECT\n\nIn most companies that have adopted Jobs Theory and ODI, there is no shortage of possible applications. There is a good chance that you will be quickly overwhelmed with project opportunities.\n\nIn the first phase of an ODI engagement, the ODI Practitioner must secure, scope, plan, and initiate the project. The goal in this phase of the engagement is to gain the project team’s agreement on (i) the project plan and scope, (ii) who the customer is, (iii) the definition of the job-to-be-done, and (iv) the preliminary job map.\n\nThe 15 steps that the ODI Practitioner must take to effectively execute the first phase of a project are as follows:\n\n1. Familiarize the organization with the benefits of JTBD theory and ODI.\n2. Select a project to pursue using ODI.\n---\n# 3. Define the goals of the ODI project.\n\n# 4. Scope the ODI project.\n\n# 5. Define the project timeline.\n\n# 6. Select the ODI project team.\n\n# 7. Determine what types of needs must be captured for the project.\n\n# 8. Create screener(s) to recruit candidates for job map interviews.\n\n# 9. Recruit candidates for job map interviews.\n\n# 10. Prepare the job map interview guide.\n\n# 11. Understand the characteristics/structure of a job statement.\n\n# 12. Conduct customer interviews to define the core functional job-to-be-done.\n\n# 13. In complex markets, conduct quantitative research to define/validate the jobs that a platform solution gets done.\n\n# 14. Conduct customer interviews to create the initial job map.\n\n# 15. Gain the project team’s preliminary agreement on the job-to-be-done, job map and project plan.\n\nIn this phase of the project the ODI Practitioner is a project planner, a facilitator, a market researcher and a team builder.\n\n# II. UNCOVER THE CUSTOMER’S NEEDS\n\nIn the second phase of an ODI engagement, the ODI Practitioner must capture a complete set of customer needs.\n\n167\n---\nThis includes all of the desired outcomes on the core functional job along with the customer’s related jobs and emotional jobs. In addition, the desired outcomes on any consumption chain jobs of interest and the buyer’s financial metrics must be uncovered.\n\nThe goal in this phase of the engagement is to create the qualitative market research deliverable. It should contain a complete set of needs built around the Jobs-to-be-Done Needs Framework. The 18 steps that the ODI Practitioner must take to effectively execute the second phase of a project are as follows:\n\n1. Create screener(s) to recruit candidates for outcome-gathering interviews.\n2. Determine the format for conducting outcome-gathering interviews.\n3. Prepare the outcome-gathering interview guide.\n4. Recruit customer interview candidates for outcome-gathering interviews.\n5. Understand the characteristics of a desired outcome statement.\n6. Understand the structure of a desired outcome statement.\n7. Conduct outcome-gathering interviews.\n8. Uncover desired outcome statements on the job-to-be-done.\n9. Net desired outcome statements (organize, refine, finalize).\n\n168\n---\n# 25.\n\nUncover related jobs.\n\n# 26.\n\nUncover emotional and social jobs.\n\n# 27.\n\nUncover relevant consumption chain jobs.\n\n# 28.\n\nUncover desired outcomes on relevant consumption chain jobs.\n\n# 29.\n\nUncover the buyer’s financial desired outcomes.\n\n# 30.\n\nUncover factors that explain why some customers struggle more than others.\n\n# 31.\n\nGain the project team’s agreement on the final job map, outcomes, and other statements.\n\n# 32.\n\nEvaluate existing and pipeline products against needs (team exercise).\n\n# 33.\n\nCreate the qualitative research deliverable.\n\nIn this phase of the project the ODI Practitioner is a project manager, a qualitative market research practitioner, and a team builder.\n\n# III. GATHER QUANTITATIVE DATA\n\nIn the third phase of an ODI engagement, the ODI Practitioner must create, test, deploy and manage a survey that is fielded to a statistically valid sample of the customer population.\n\nThe goal in this phase of the engagement is to gather the data that is needed to (i) conduct Outcome-Based Segmentation analysis, (ii) conduct competitive analysis, (iii) determine what customer needs are underserved and overserved, (iv) determine the degree to which a need is\n\n169\n---\nunderserved and overserved, and (v) inform dozens of other downstream decisions that must be made to formulate the market and product strategy.\n\n# 3. Steps for Executing the Third Phase of a Project\n\n1. Determine the unit of analysis for the quantitative survey.\n2. Design the sample plan.\n3. Determine how to weight the data.\n4. Define any unique data analyses that are required.\n5. Construct the screening questions for the quantitative survey.\n6. Construct the profiling questions for the quantitative survey.\n7. Construct the willingness-to-pay questions for the quantitative survey.\n8. Format the outcome questions in the survey instrument for optimal results.\n9. Gain the project team’s agreement on the survey (instrument and questionnaire).\n10. Select a vendor for data collection.\n11. Translate the completed survey into required languages.\n12. Program the survey for fielding.\n13. Pilot/test the survey for fielding.\n14. Field the survey.\n15. Monitor the survey progress.\n---\n49. Prepare analytical tools for data analysis.\n\n50. Receive the data from the data collection vendor.\n\n51. Verify the data is valid (clean the data).\n\nIn this phase of the project the ODI Practitioner is a project manager, a quantitative market research practitioner, and a third-party research manager.\n\n# IV. DISCOVER HIDDEN OPPORTUNITIES FOR GROWTH\n\nIn the fourth phase of an ODI engagement, the ODI Practitioner must use the quantitative data that was collected in the previous phase to conduct Outcome-Based Segmentation analysis, competitive analysis and other analyses as required. The goal of this phase is to (i) run the analyses that are needed to address the key questions detailed in the scope of the project, and (ii) create the research deliverable.\n\nThe research deliverable explains what outcome-based segments were discovered, offers a description of each segment, reveals what hidden opportunities were discovered, and provides the information that is needed to formulate the market and product strategy.\n\nThe 10 steps that the ODI Practitioner must take to effectively execute the fourth phase of a project are as follows:\n---\n1. Weight the quantitative data.\n2. Create Outcome-Based Segmentation models.\n3. Determine which segmentation model to use.\n4. Conduct the analyses needed for segment profiling.\n5. Determine what variables underlie the segmentation model (complexity factors).\n6. Create a data-driven profile/description for each segment.\n7. Determine what outcomes are underserved/overserved in each segment.\n8. Determine the strengths and weaknesses of competitors in each segment.\n9. Identify which outcomes are most influential in the customer’s willingness-to-pay in each segment.\n10. Complete commonly requested data analyses.\n11. Create the opportunity discovery deliverable.\n\nIn this phase of the project the ODI Practitioner is a project manager, a quantitative market research practitioner, a data analyst, and a strategist.\n\n# V. FORMULATE THE MARKET STRATEGY\n\nIn the fifth phase of an ODI engagement, the ODI Practitioner uses the information resulting from the previously conducted data analyses to formulate a market strategy. The market strategy is usually constructed with the involvement of the project team.\n\n172\n---\nThe goal of this phase is to formulate, document, present, refine, and gain cross-functional agreement on the market strategy.\n\n# 12 Steps for Executing the Fifth Phase of a Project\n\n1. Determine the strengths of existing and pipeline products (team exercise)\n2. Determine what outcome-based segments and outcomes to target\n3. Define the value proposition for each outcome-based segment\n4. Define the value proposition for the product category\n5. Determine what existing and pipeline products to target at each segment\n6. Determine how to message each product\n7. Determine how to integrate the new value proposition into existing company promotional channels/materials, e.g., the website, etc.\n8. Propose an outcome-based digital marketing strategy, e.g., AdWords campaign, SEO optimization, etc.\n9. Create a customer acquisition tool that assigns customers to segments\n10. Gain the project team’s agreement on the market strategy\n11. Create the market strategy deliverable\n\n173\n---\n# VI. FORMULATE THE PRODUCT STRATEGY\n\nIn the sixth and final phase of an ODI engagement, the ODI Practitioner uses the information resulting from the previously conducted data analyses to formulate a product strategy. The product strategy, like the market strategy, is usually constructed with the involvement of the project team.\n\nThe goal of this final phase is to formulate, document, present, refine, and gain cross-functional agreement on the product strategy.\n\nThe 10 steps that the ODI Practitioner must take to effectively execute the sixth phase of a project are as follows:\n\n1. Determine the weaknesses of existing and pipeline products (team exercise)\n2. Determine what outcomes to target to address competitive weaknesses\n3. Determine what value creation opportunities to address in each segment\n4. Determine what cost reduction opportunities to address in each segment\n---\n# 79. Facilitate ideation to improve existing products\n\n# 80. Facilitate ideation to improve pipeline products\n\n# 81. Facilitate ideation to conceptualize new products/platforms\n\n# 82. Gain the project team’s agreement on the product strategy\n\n# 83. Create the product strategy deliverable for each product\n\n# 84. Create the product strategy deliverable for the product portfolio\n\nIn this phase of the project the ODI Practitioner is a project manager, a data analyst, a strategist, a facilitator, and a team builder.\n\n# What skills are required to be a good ODI Practitioner?\n\nGiven the demanding responsibilities of the ODI Practitioner, we recommend that candidates meet all (or at least most) of the following qualifications:\n\n- Process orientation and systems mentality.\n- Skilled and experienced in qualitative and quantitative research practices.\n- Superior creative problem-solving, analytical, and quantitative skills.\n- Previous experience on a product team.\n- Trained in Six-Sigma practices.\n---\n# Team leadership and group facilitation capabilities.\n\n- Strong communication skills with ability to synthesize, document, and present knowledge effectively.\n- Detail orientation. Highly organized.\n- Strong knowledge of PowerPoint, Excel, and Word.\n\n176\n---\n# 7. TRANSFORMING THE ORGANIZATION\n\nJobs-to-be-Done has exploded in popularity as of late. There is a reason for that: it is logical, complete, produces results and provides a mindset and language that the organization can quickly adopt. The decision to adopt a Jobs-to-be-Done mindset has had incredible results for many of the world’s most successful corporations, and Strategyn has led them in their efforts.\n\nSo, what will it take to transform your organization and build a Jobs-to-be-Done innovation competency?\n\nTo install Jobs-to-be-Done in an organization, you will need one trained internal ODI Practitioner per business unit. That Practitioner can complete the online education courses for ODI certification available at Strategyn.com/ODIpro over the course of a few weeks. Then they can begin executing an ODI project, which Strategyn can support if necessary. Narrowly-scoped projects can be completed in as little as 4 weeks in what we call a project sprint.\n\nWith ODI data in hand, the ODI Practitioner will work with a cross-functional product team in the business unit to turn the insights into action. This team typically includes marketing, sales, planning, engineering and R&D. They may participate in ideation, and product and market strategy formulation. It is recommended that this team complete an ODI course, although they do not need to be certified.\n\nIn a small organization with only 1 product, we recommend hiring Strategyn to gather the qualitative and quantitative\n---\ndata, and we will train a cross-functional team on how to use these data and insights. This will quickly and efficiently build an innovation competency.\n\nIn large organizations, we recommended the assembly of a team of internal ODI Practitioners who will form the core of an Innovation Center of Excellence. This team, armed with the appropriate training and support and the right tools is responsible for applying Jobs Theory and ODI practices to carefully selected markets and transforming the company into an outcome-driven organization.\n\nAs with any endeavor, picking the right team is essential for success. Building the team around or into an established Six Sigma program is a practice that we have seen work well. We find that Six Sigma certified practitioners with qualitative and quantitative market research experience are often the best at understanding and applying ODI within the organization. Alternatively, building the team from an established market research team would work well.\n\nThe rest of the organization can benefit from understanding the ODI innovation process and adopting a common language for innovation.\n\n178\n---\n# PROGRAM OVERVIEW\n\nBuilding an outcome-driven organization is best accomplished in three phases:\n\n|PHASE|PHASE II|PHASE III|\n|---|---|---|\n|Understand Your Customer's Job to be Done|Discover Hidden Opportunities in Your Market|Use New Customer Insights to Drive Growth|\n\nYour organization has the option of taking multiple cross-functional product teams through this process simultaneously.\n\nIn Phase I, the cross-functional product team for a selected product area participates in an intensive two-day workshop in which the ODI Practitioners engage the team and customers in a unique innovation journey. For the first time, the team sees its market through a “Jobs-to-be-Done” lens, and they learn what customer insights they need to drive outcome-driven decision making. The team walks away with highly valuable customer insights derived from ODI-based qualitative research. The time commitment associated with this phase is relatively low, yet it greatly moves the team toward its goal of being outcome-driven.\n\nIn Phase II, the ODI Practitioners lead the ODI-based quantitative research effort. With a statistically valid data set in hand, they conduct the analyses needed to inform the market and product strategies. With the insights that result\n---\nfrom these analyses, the company will be able to make data-driven business decisions for years to come.\n\nIn Phase III, the ODI Practitioners teach managers and employees across the business unit how to use these insights to formulate market and product strategies and to drive outcome-driven decision making. Let’s look at each phase in more detail:\n\n# PHASE I: UNDERSTAND YOUR CUSTOMER’S JOB-TO-BE-DONE\n\nThe best way to get started is to apply ODI to a market which you are very familiar with. During the Phase I workshop, the cross-functional product team will (i) learn the fundamentals of Jobs Theory and the ODI process, (ii) participate in a facilitated qualitative research discussion designed to obtain critical customer information from customers, and (iii) begin to use their newfound insights to make outcome-driven business decisions in their market. The completion of Phase I will boost the team’s ability to succeed at innovation because they will leave in agreement on (i) who the customer is, (ii) what functional and emotional jobs the customer is trying to get done, (iii) the job map, (iv) what a customer need is, and (v) what the customer’s needs are. Additional customer interviews may be necessary to gather a complete set of needs (or outcome statements).\n\nThe workshop employs the techniques and principles showcased in the Harvard Business Review article I co-authored\n---\n# The Customer-Centered Innovation Map\n\n(May 2008). Workshop participants typically include: the product team, a handful of external customers, and the ODI Practitioner who leads the effort. The Phase I workshop is designed to shift the product team’s thinking along a number of fronts (see the table below).\n\n# Expected Impact of Phase I: Qualitative Insights\n\n|Team Thinking Before Phase|Team Thinking After Phase|\n|---|---|\n|The product team disagrees on who the customer is (the buyer; user; installer influencer):|The product team agrees on who the customers are|\n|The team defines the market from a product-centric perspective (around the product or technology):|The team defines the market from a customer-centric perspective (around the job-to-be-done):|\n|The team doesn't know what job the customer is trying to get done|The team agrees on what job the customer is trying to get done and on the job map.|\n|The team can't agree on what a customer need is (purpose, structure, format; content)|There is cross-functional agreement on what a need is.|\n|The team believes customers have latent needs and needs - they can't articulate.|The team recognizes that customers can articulate their needs when they are defined around the job-to-be-done|\n|While the organization may collectively know most of the customer's needs, there is no agreed-upon list|There is a single, agreed-upon list of customer needs that is shared across functions.|\n---\nUpon completion of Phase I, the product team will share a common language of innovation and possess a unique set of customer insights (a job map and a set of desired outcome statements) that it can use to make customer-centric marketing and development decisions. Because the job map and customer outcomes are stable over time, these qualitative insights are an indispensable, long-term guide to success at innovation.\n\n# PHASE II: DISCOVER HIDDEN OPPORTUNITIES IN YOUR MARKET\n\nIn Phase II, the ODI Practitioner creates a questionnaire (an online survey) that is used to collect the quantitative data. The survey is administered to a set of job executors (usually between 180 and 3000 people) who are representative of the population. The ODI Practitioner uses a stringent set of quality standards that Strategyn has developed to ensure only valid customer data is collected.\n\nOnce the data is collected, the ODI Practitioner validates the responses and then conducts Outcome-Based Segmentation, along with other analyses, including competitive analysis.\n\nThe research that occurs during Phase II is also designed to shift the product team’s thinking along a number of fronts (see table).\n---\n# Expected Impact of Phase II: Quantitative Insights\n\n# Team Thinking Before Phase II\n\nNobody knows with certainty what customer needs are unmet and to what degree.\n\nThe segmentation model that managers use obscures differences in unmet customer needs.\n\nThe company's competitive strengths and weaknesses relate to speeds and feeds.\n\nThe market strategy is based on personas and qualitative insights.\n\nThe product team does not agree on what market strategy to pursue.\n\nThere is no agreement on what product and service concepts to pursue and invest in.\n\nThe model built from this data set will help the team conceptualize and evaluate ideas for possible pursuit for years to come.\n\n# Team Thinking After Phase II\n\nEverybody on the product team knows what needs are unmet and to what degree.\n\nMarketing and development managers use a segmentation model based on differences in unmet customer needs.\n\nThe company's competitive strengths and weaknesses relate to addressing unmet needs.\n\nThe market strategy is based on quantitative ODI-based market research.\n\nIt is data-driven.\n\nThe product team agrees on what market strategy to pursue and how to create customer value.\n\nThere is cross-functional agreement on what product concepts to pursue and invest in.\n---\n# PHASE III: USE YOUR NEW CUSTOMER INSIGHTS TO DRIVE GROWTH\n\nHaving valuable customer data is one thing. Knowing how to use it is another. While many applications of the data are possible, using the data takes training. Phase III is dedicated to teaching managers and employees across the business unit how to leverage their newfound customer insights. In both classroom training and hands-on workshops, the ODI practitioner will shift your product team’s thinking along a number of fronts, teaching them to make outcome-driven business decisions across a wide range of subjects. The types of data we capture and provide using our ODI-based research methods – the job map, opportunity landscape, desired outcome statements, outcome-based segments, opportunity scores, and so on – can be used to inform dozens of challenges.\n\nFor example, they can be used to:\n\n- Create an outcome-driven digital marketing strategy, e.g., Google AdWords and SEO campaign, etc.\n- Help the sales team deliver the right message to the right customer\n- Inform your marketing communications program\n- Reposition existing products around your competitive strengths\n- Make improvements to existing products and services\n- Conceptualize breakthrough, radical, and disruptive product ideas\n- Drive decisions on research and development\n- Inform merger and acquisition decisions\n\n184\n---\n# The education and training provided by the ODI Practitioner\n\nare also designed to shift the product team’s thinking along a number of fronts (see table below).\n\n# Expected Impact of Phase III: Implementation\n\n|Team Thinking Before Phase III|Team Thinking After Phase III|\n|---|---|\n|The team's focus is on beating the competition:|The team's focus is on helping customers get a job done better and/or more cheaply:|\n|Innovation is about coming up with ideas and seeing if they address unmet customer needs.|Innovation is about uncovering unmet customer needs and finding solutions that address them:|\n|Products are emotions:|Products are positioned around both functional jobs and outcomes and emotional needs.|\n|The person with the loudest voice or the one in the most senior position influences the product team:|Customer data and facts influence the product team:|\n|Technology, ideas, and capabilities drive strategy and decision-making:|Unmet customer needs dictate what ideas, technologies, and capabilities to invest in.|\n|Decisions are made using qualitative customer insights and intuition.|Decisions are made using quantitative customer insights. Intuition is not acceptable.|\n---\nA product team can expect to complete its three-phase outcome-driven journey in as little as four weeks.\n\nApplying the Outcome-Driven Innovation process changes everything. Your company will dramatically improve its chances for success.\n\nThank you for reading this book. Good luck on becoming outcome-driven and changing the way the world innovates. Reach out to me at ulwick@strategyn.com if you have questions or comments.\n\n186\n---\n# 8. THE LANGUAGE OF JOBS-TO-BE-DONE\n\nA common language of innovation has the power to unite an organization in its effort to build a competency in innovation. The introduction of Jobs Theory presents companies with an opportunity to redefine the language of innovation from the customer’s perspective; and an opportunity to understand and discuss innovation by seeing it through a new lens. These are the terms we use to define the concepts that comprise Jobs Theory and Outcome-Driven Innovation.\n\n# Definitions\n\n- Brainstorming – An unbounded method of idea generation that encourages the creation of many (often hundreds) of ideas.\n- Consumption chain jobs – The jobs that the product lifecycle support team must get done throughout the product lifecycle. These jobs include installation, set up, and storing, transporting, maintaining, repairing, cleaning, upgrading, and disposing of the product.\n- Creativity – The mental process by which an idea is triggered and conceived.\n- Customer – A constituent for whom the company chooses to create value. Key customers include the end user (the\n---\n# Customer Need and Strategy\n\nFunctional job executor), the purchase decision maker (buyer), and the product lifecycle support team (people who install, maintain, and repair the offering).\n\n# Customer Need\n\nA need is a functional or emotional job the customer is trying to get done; or a desired outcome: a metric that customers use to measure the successful execution of a functional job or a consumption chain job.\n\n# Desired Outcome\n\nA metric that customers use to measure the successful execution of a functional job or a consumption chain job.\n\n# Differentiated Strategy\n\nA company pursues a differentiated strategy when it discovers and targets a population of underserved consumers with a new product or service offering that gets a job (or multiple jobs) done significantly better, but at a significantly higher price.\n\n# Discrete Strategy\n\nA company pursues a discrete strategy when it targets a population of “restricted” customers with a product that gets the job done worse, yet costs more.\n\n# Disruptive Strategy\n\nA company pursues a disruptive strategy when it discovers and targets a population of overserved customers or nonconsumers with a new product or service offering that enables them to get a job done more cheaply, but not as well as competing solutions.\n---\n# Dominant strategy\n\nA company pursues a dominant strategy when it targets all consumers in a market with a new product or service offering that gets a job done significantly better and for significantly less money.\n\n# Emotional jobs\n\nStatements that describe the way customers want to be perceived or feel when executing a core functional job.\n\n# End user\n\nThis is a person who ultimately uses the product or service to execute the functional job the product is intended to perform. Also the functional job executor.\n\n# Financial outcomes\n\nThe financial metrics that the purchase decision maker uses to decide what product or service to purchase.\n\n# Functional job-to-be-done\n\nThe underlying process an end user is trying to get done in a given situation, and the focal point around which a market is defined.\n\n# Idea\n\nAn output of the creative process that defines a way in which specific unmet customer needs can be satisfied.\n\n# Ideas-first approach to innovation\n\nAn inherently flawed approach to innovation that starts with the generation of ideas and is followed by evaluation and filtering methods that determine which ideas customers like best without ever explicitly understanding their needs.\n\n189\n---\n# Industry\n\nThe collective set of companies that offer solutions to help customers get a job done.\n\n# Innovation\n\nThe process of devising a product or service concept that addresses the customer’s unmet needs, thus enabling the customer to get a job done better and/or more cheaply.\n\n# Job executor\n\nThe group of people who are targeted for value creation. The job executor could be the functional job executor (end user), the purchase decision maker (buyer), or someone who executes a consumption chain job, such as the installer.\n\n# Job map\n\nA visual depiction of a functional job, deconstructed into its discrete process steps. Unlike a process map, a job map does not show what the customer is doing (a solution-based view); rather, it describes what the customer is trying to get done (a needs-based view).\n\n# Job-to-be-done\n\nA statement that describes what a group of people are trying to achieve or accomplish in a given situation. A job-to-be-done could be a task that people are trying to accomplish, a goal or objective they are trying to achieve, a problem they are trying to resolve, something they are trying to avoid, or anything else they are trying to accomplish. A job is functional with emotional components.\n---\n# Jobs-to-be-Done\n\nAs a general concept, Jobs-to-be-Done is best defined as a perspective – a lens through which you can see and think about markets, customers, needs, competitors, and customer segments in a way that makes innovation far more predictable and profitable.\n\n# Jobs-to-be-Done Growth Strategy Matrix\n\nA framework that illustrates when and how to deploy a differentiated, dominant, disruptive, discrete or sustaining growth strategy.\n\n# Jobs-to-be-Done Needs Framework\n\nA visual depiction of the structure and relationship of all of the customer inputs that are needed to effectively execute the innovation process.\n\n# Jobs-to-be-Done Theory\n\nThe notion that people buy products and services to get a job done and that new products and services win in the marketplace if they help customers get a job done better and/or more cheaply. It is synonymous with Jobs Theory.\n\n# Market\n\nA group of people + the core functional job they are trying to get done. Parents (a group of people) who are trying to pass on life lessons to their children (the job-to-be-done) constitute a market. Dental hygienists who clean\n---\npatients’ teeth and farmers who grow a crop also constitute markets.\n\n# Market segment\n\nA group of job executors who have a unique set of underserved and/or overserved desired outcomes. They often struggle in a unique way to get the job done because they execute the job in a unique situation or circumstance.\n\n# Market segmentation\n\nThe process of discovering a group of job executors who have a unique set of underserved and/or overserved desired outcomes.\n\n# Market selection\n\nThe process of deciding what groups of people and jobs-to-be-done to target to create new revenue streams.\n\n# Market strategy\n\nA plan that a company devises in order to achieve and maintain a unique and valued competitive position in a market. A market strategy includes the creation of a value proposition, product positioning and messaging, and the formulation of a digital marketing strategy.\n\n# Needs-first approach to innovation\n\nAn approach to innovation in which companies first uncover the customer’s needs, then determine which are unmet, and finally devise solutions to address those unmet needs.\n\n192\n---\n# New market\n\nA new job that a group of people want to get done. New jobs can emerge, for example, when there are changes in government policy, scientific discoveries and to support the introduction of new technologies.\n\n# ODI-based research methods\n\nThe qualitative and quantitative research methods that are integral to the Outcome-Driven Innovation process.\n\n# Opportunity\n\nAn unmet need; a desired outcome that is both important and poorly satisfied (underserved), or a desired outcome that is unimportant and very well satisfied (overserved).\n\n# Opportunity Algorithm\n\nThe formula used to determine the degree to which a specific outcome or related or emotional job is underserved or overserved. The formula is: opportunity = importance + max (importance – satisfaction, 0). Importance is calculated as the percentage of people (in a statistically representative population) rating the outcome very or extremely important. Satisfaction is calculated as the percentage of people rating the outcome very or extremely satisfied.\n\n# Opportunity Landscape\n\nA visual depiction of the opportunities that exist in a market and the degree to which the customer’s desired outcomes are underserved or overserved.\n\n193\n---\n# Outcome-based creativity triggers\n\nA set of creativity triggers created by Strategyn that provide innovators with possible ways to address underserved unmet desired outcomes.\n\n# Outcome-Based Segmentation\n\nA method by which segments of customers with uniquely different underserved desired outcomes can be discovered, sized and targeted.\n\n# Outcome-Driven IdeationTM\n\nThe process of conceptualizing new platforms, business models, and features that address underserved segments and desired outcomes discovered through the use of ODI-based research methods.\n\n# Outcome-Driven Innovation® (ODI)\n\nA strategy and innovation process that ties customer-defined metrics (desired outcomes) to the job-to-be-done, making value creation (and innovation) measurable and predictable. The process employs qualitative, quantitative, and market segmentation methods that reveal hidden opportunities for growth. ODI has an 86 percent success rate—a five-fold improvement over the industry average.\n\n# Overserved market segment\n\nA segment of customers with many desired outcomes that are unimportant and well satisfied.\n\n# Process of disruptive innovation\n\nThe introduction of a series of products, the first of which employs a disruptive\n---\n# Product Lifecycle Support Team\n\nPeople (customers) who help install, set up, store, transport, maintain, repair, clean, upgrade, and dispose of the product, and perform other support services as necessary.\n\n# Purchase Decision Maker\n\nThe person responsible for executing the “buying” job: seeking out and evaluating alternative offerings and deciding which to buy.\n\n# Qualitative Research\n\nMarket research methods used to uncover customer desired outcomes and other inputs that comprise the Jobs-to-be-Done Needs Framework.\n\n# Quantitative Research\n\nMarket research methods used to gather the statistically valid data needed to conduct Outcome-Based Segmentation analysis and other data analyses that comprise the ODI process.\n\n# Related Jobs\n\nFunctional jobs the end user is trying to get done in conjunction with the core functional job. Getting more jobs done on a single platform makes the platform more valuable.\n\n# Segment Description\n\nA narrative that describes: (1) the situation or circumstances a job executor is facing, (2) the\n---\n# Functional Job and Emotional Jobs\n\nThey are trying to get done in that situation, and (3) the underserved and overserved desired outcomes associated with the functional job. It is synonymous with the term outcome-based persona.\n\n# Strategyn\n\nThe company that pioneered Jobs-to-be-Done Theory and created the Outcome-Driven Innovation process.\n\n# Sustaining Strategy\n\nA company pursues a sustaining strategy when it introduces a new product or service offering that gets the job done only slightly better and/or slightly cheaper.\n\n# Underserved Market\n\nA market in which many of the customer desired outcomes are important and poorly satisfied.\n\n# Unmet Need\n\nA segment of customers with many desired outcomes that are very important and poorly satisfied.\n\n</JTBD_framework>\n",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1000,
        0
      ],
      "id": "44a543d8-8913-4cdc-91d5-f75a8740cb7e",
      "name": "Load JTBD"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.0-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        2360,
        220
      ],
      "id": "317127db-74ef-4356-9bbd-48b54e05f5fb",
      "name": "Google Gemini Chat Model",
      "credentials": {
        "googlePalmApi": {
          "id": "flZ3VabFlV6wrHU6",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "d0e17a8f-4f84-418e-8ff0-dbd0e27859ff",
              "name": "sample_quesitons",
              "value": "=<sample_questions>\n\n\n# Introduction\n\nTrying to learn from customer conversations is like excavating a delicate archaeological site. The truth is down there somewhere, but it’s fragile. While each blow with your shovel gets you closer to the truth, you’re liable to smash it into a million little pieces if you use too blunt an instrument.\n\nI see a lot of teams using a bulldozer and crate of dynamite for their excavation. They are, in one way or another, forcing people to say something nice about their business. They use heavy-handed questions like “do you think it’s a good idea” and shatter their prize.\n\nAt the other end of the spectrum, some founders are using a toothbrush to unearth a city, flinching away from digging deep and finding out whether anything of value is actually buried down there.\n\nWe want to find the truth of how to make our business succeed. We need to dig for it—and dig deep—but every question we ask carries the very real possibility of biasing the person we’re talking to and rendering the whole exercise pointless. It happens more than you’d ever imagine.\n\nThe truth is our goal and questions are our tools. But we must learn to wield them. It’s delicate work. And well worth learning. There’s treasure below.\n\n\n---\n\n\n# 7\n\n# A note on scope & terminology\n\nThis book isn’t a summary or description or re-interpretation of the process of Customer Development. That’s a bigger concept and something Steve Blank has covered comprehensively in 4 Steps to the E.piphany and The Startup Owner’s Manual.\n\nThis book is specifically about how to properly talk to customers and learn from them. Talking is one of the big aspects of Customer Development, but shouldn't be confused with the whole process. To keep the distinction clear, I’m going to refer to chatting with people as “customer conversation” (lowercase) instead of “Customer Development” (uppercase).\n\nFor the most part, I'm assuming you already agree that talking to customers is a good idea. I’m not trying to convince you again, so this book is more “how” than “why”.\n\nLet’s get involved.\n\n\n---\n\n\n# CHAPTER ONE\n\n# The Mom Test\n\nPeople say you shouldn’t ask your mom whether your business is a good idea. That’s technically true, but it misses the point. You shouldn’t ask anyone whether your business is a good idea. At least not in those words. Your mom will lie to you the most (just ‘cuz she loves you), but it’s a bad question and invites everyone to lie to you at least a little.\n\nIt’s not anyone else’s responsibility to show us the truth. It’s our responsibility to find it. We do that by asking good questions.\n\nThe Mom Test is a set of simple rules for crafting good questions that even your mom can't lie to you about.\n\nBefore we get there, let's look at two conversations with mom and see what we can learn about our business idea: digital cookbooks for the iPad.\n\n# Failing the mom test\n\nSon: “Mom, mom, I have an idea for a business — can I run it by you?” I am about to expose my ego — please don’t hurt my feelings.\n\nMom: “Of course, dear.” You are my only son and I am ready to lie to protect you.\n\n\n---\n\n\nSon: “You like your iPad, right? You use it a lot?”\n\nMom: “Yes.” You led me to this answer, so here you go.\n\nSon: “Okay, so would you ever buy an app which was like a cookbook for your iPad?” I am optimistically asking a hypothetical question and you know what I want you to say.\n\nMom: “Hmmm.” As if I need another cookbook at my age.\n\nSon: “And it only costs $40 — that’s cheaper than those hardcovers on your shelf.” I’m going to skip that lukewarm signal and tell you more about my great idea.\n\nMom: “Well...” Aren’t apps supposed to cost a dollar?\n\nSon: “And you can share recipes with your friends, and there’s an iPhone app which is your shopping list. And videos of that celebrity chef you love.” Please just say “yes.” I will not leave you alone until you do.\n\nMom: “Oh, well yes honey, that sounds amazing. And you’re right, $40 is a good deal. Will it have pictures of the recipes?” I have rationalised the price outside of a real purchase decision, made a non-committal compliment, and offered a feature request to appear engaged.\n\nSon: “Yes, definitely. Thanks mom — love you!” I have completely misinterpreted this conversation and taken it as validation.\n\nMom: “Won’t you have some lasagna?” I am concerned that you won’t be able to afford food soon. Please eat something.\n\nOur misguided entrepreneur has a few more conversations like this, becomes increasingly convinced he’s right, quits his job, and sinks his savings into the app. Then he wonders why nobody (even his mom) buys the app, especially since he had been so rigorous.\n\n\n---\n\n\nDoing it wrong is worse than doing nothing at all. When you know you’re clueless, you tend to be careful. But collecting a fistful of false positives is like convincing a drunk he’s sober: not an improvement.\n\nLet’s fix the conversation and show that if we do it right, even mom can help us figure out whether our business is a good idea.\n\n# Passing the mom test\n\nSon: “Hey mom, how’s that new iPad treating you?”\n\nMom: “Oh - I love it! I use it every day.”\n\nSon: “What do you usually do on it?” Whoops — we asked a generic question, so answer to this probably won’t be terribly valuable.\n\nMom: “Oh, you know. Read the news, play sudoku, catch up with my friends. The usual.”\n\nSon: “What’s the last thing you did on it?” Get specific about examples in the past to get real, concrete data.\n\nMom: “You know your father and I are planning that trip? I was figuring out where we could stay.” She uses it for both entertainment and utility, which didn’t come up during the “usually” answer.\n\nSon: “Did you use an app for that?” A slightly leading question, but sometimes we need to nudge to get to the topic we’re interested in.\n\nMom: “No, I just used Google. I didn’t know there was an app. What’s it called?” Younger folks use the App Store as a search engine, whereas your mom waits for a specific recommendation. If that’s true more broadly, finding a reliable\n\n\n---\n\n\nmarketing channel outside the App Store is going to be crucial.\n\nSon: “Where did you find out about the other ones you use?” Dig into interesting and unexpected answers to understand the behaviours and motivations behind them.\n\nMom: “The Sunday paper has a section on the apps of the week.” You can’t remember the last time you cracked open a paper, but it sounds like traditional PR might be a viable option for reaching customers like your mom.\n\nSon: “Makes sense. Hey, by the way, I saw a couple new cookbooks on the shelf — where did those come from?” Business ideas usually have several failure points. Here it’s both the medium of an iPad app and the content of a cookbook.\n\nMom: “They’re one of those things you just end up getting at Christmas. I think Marcy gave me that one. Haven’t even opened it. As if I need another lasagna recipe at my age!” Aha! This answer is gold dust for 3 reasons: 1. Old people don’t need another generic set of recipes. 2. The gift market may be strong. 3. Younger cooks may be a better customer segment since they don’t yet know the basics.\n\nSon: “What’s the last cookbook you did buy for yourself?” Attack generic answers like “I don’t buy cookbooks” by asking for specific examples.\n\nMom: “Now that you mention it, I bought a vegan cookbook about 3 months ago. Your father is trying to eat healthier and thought my veggies could benefit from a pinch more zazz.” More gold: experienced chefs may still buy specialised or niche cookbooks.\n\nThe conversation continues. If it’s going well, I would raise the topics of whether she ever thought to look for recipes on the iPad or for cooking videos on YouTube.\n\nOverall, your mom can’t remember the last time she had such an enjoyable conversation with you. You were so interested in her life for once! You thank her\n\n\n---\n\n\nfor the lasagna, pet the dog, and head home. You’ve learned that building an app and waiting for people to find it on the App Store probably isn’t a good plan. But you’ve got some good insight about your customer segment and a few promising leads to look into. That was a useful conversation.\n\n# A useful conversation\n\nThe measure of usefulness of an early customer conversation is whether it gives us concrete facts about our customers' lives and world views. These facts, in turn, allow us to improve our business.\n\nOur original idea looked like this: old people like cookbooks and iPads. Therefore, we will build a cookbook for the iPad. It’s generic. There are a thousand possible variations of this premise.\n\nWith an idea this vague, we can’t answer any of the difficult questions like which recipes to include or how people will hear about it. Until we get specific, it always seems like a good idea.\n\nAfter just one conversation (with our mom, of all people), we have a higher fidelity vision. We now see that there are at least 2 specific customer segments we might serve, each of which needs a slightly different product. We’ve also identified some major risks to address before we commit too heavily.\n\n1. We could offer niche recipes (ethnic, diets) which experienced cooks may not already know. Our biggest question is how to reach them when they don’t search for apps. We have a possible lead with newspaper and magazine PR.\n2. Alternately, we might make generic recipes for younger cooks who are easier to reach via the App Store and who haven’t memorised all their favourites yet. We haven’t talked to any, so we have loads of questions, but one big one is whether a customer segment who isn’t already in the habit of buying expensive cookbooks will pay a premium for ours.\n\n\n---\n\n\nThe first conversation gave us rope to hang ourselves. The second gave us actionable insight. Why? What was different about the second conversation?\n\nMom was unable to lie to us because we never talked about our idea.\n\nThat’s kind of weird, right? We find out if people care about what we’re doing by never mentioning it. Instead, we talk about them and their lives.\n\nThe point is a bit more subtle than this. Eventually you do need to mention what you’re building and take people’s money for it. However, the big mistake is almost always to mention your idea too soon rather than too late.\n\nIf you just avoid mentioning your idea, you automatically start asking better questions. Doing this is the easiest (and biggest) improvement you can make to your customer conversations.\n\n# The Mom Test:\n\n1. Talk about their life instead of your idea\n2. Ask about specifics in the past instead of generics or opinions about the future\n3. Talk less and listen more\n\nIt’s called The Mom Test because it leads to questions that even your mom can’t lie to you about. When you do it right, they won’t even know you have an idea.\n\nThere are some other important tools and tricks that we’ll introduce throughout the rest of the book. But first, let’s let’s put The Mom Test to work on some questions.\n\nRule of thumb: Customer conversations are bad by default. It’s your job to fix them.\n\n\n---\n\n\n# Good question / bad question\n\nLet’s play a game. Are the following questions good or bad? Do they pass or fail The Mom Test? If they fail it, why? And how could we improve them? Work your way through the list and then read on for some discussion.\n\n- “Do you think it’s a good idea?”\n- “Would you buy a product which did X?”\n- “How much would you pay for X?”\n- “What would your dream product do?”\n- “Why do you bother?”\n- “What are the implications of that?”\n- “Talk me through the last time that happened.”\n- “Talk me through your workflow.”\n- “What else have you tried?”\n- “Would you pay X for a product which did Y?”\n- “How are you dealing with it now?”\n- “Where does the money come from?”\n- “Who else should I talk to?”\n- “Is there anything else I should have asked?”\n\n\n---\n\n\n15\n\n\"Do you think it's a good idea?\"\n\nAwful question! Here’s the thing: only the market can tell if your idea is good. Everything else is just opinion. Unless you’re talking to a deep industry expert, this is self-indulgent noise with a high risk of false positives.\n\nLet’s fix it: Say you’re building an app to help construction companies manage their suppliers. You might ask them to show you how they currently do it. Talk about which parts they love and hate. Ask which other tools and processes they tried before settling on this one. Are they actively searching for a replacement? If so, what’s the sticking point? If not, why not? Where are they losing money with their current tools? Is there a budget for better ones? Now, take all that information and decide for yourself whether it’s a good idea.\n\nRule of thumb: Opinions are worthless.\n\n\"Would you buy a product which did X?\"\n\nBad question. You’re asking for opinions and hypotheticals from overly optimistic people who want to make you happy. The answer to a question like this is almost always “yes”, which makes it worthless.\n\nLet’s fix it: Ask how they currently solve X and how much it costs them to do so. And how much time it takes. Ask them to talk you through what happened the last time X came up. If they haven’t solved the problem, ask why not. Have they tried searching for solutions and found them wanting? Or do they not even care enough to have Googled for it?\n\nRule of thumb: Anything involving the future is an over-optimistic lie.\n\n\n---\n\n\n# 16\n\n\"How much would you pay for X?\"\n\nBad question. This is exactly as bad as the last one, except it’s more likely to trick you because the number makes it feel rigorous and truthy.\n\nHow to fix it: Just like the others, fix it by asking about their life as it already is. How much does the problem cost them? How much do they currently pay to solve it? How big is the budget they’ve allocated? I hope you’re noticing a trend here.\n\nRule of thumb: People will lie to you if they think it’s what you want to hear.\n\n\"What would your dream product do?\"\n\nSort-of-okay question, but only if you ask good follow-ups. Otherwise it’s a bad question. A question like this is like the “set” before the spike in a volleyball game: not too helpful on its own, but it puts you in a good position as long as you’re ready to exploit it.\n\nLet’s improve it: The value comes from understanding why they want these features. You don’t want to just collect feature requests. You aren’t building the product by committee. But the motivations and constraints behind those requests are critical.\n\nRule of thumb: People know what their problems are, but they don’t know how to solve those problems.\n\n\"Why do you bother?\"\n\nGood question. I love this sort of question. It’s great for getting from the perceived problem to the real one.\n\n\n---\n\n\nFor example, some founders I knew were talking to finance guys spending hours each day sending emails about their spreadsheets. The finance guys were asking for better messaging tools so they could save time. The “why do you bother” question led to “so we can be certain that we’re all working off the latest version.” Aha. The solution ended up being less like the requested messaging tool and more like Dropbox. A question like “why do you bother” points toward their motivations. It gives you the why.\n\n# Rule of thumb:\n\nYou're shooting blind until you understand their goals.\n\n# \"What are the implications of that?\"\n\nGood question. This distinguishes between I-will-pay-to-solve-that problems and thats-kind-of-annoying-but-I-can-deal-with-it “problems”. Some problems have big, costly implications. Others exist but don’t actually matter. It behooves you to find out which is which. It also gives you a good pricing signal.\n\nI once had someone keep describing the workflow we were fixing with emotionally loaded terms like “DISASTER”, accompanied by much yelling and arm waving. But when I asked him what the implications were, he sort of shrugged and said “Oh, we just ended up throwing a bunch of interns at the problem—it’s actually working pretty well.”\n\n# Rule of thumb:\n\nSome problems don’t actually matter.\n\n# \"Talk me through the last time that happened.\"\n\nGood question. Your high school writing teacher may have told you that good stories are meant to “show, not tell”. Whenever possible, you want to be shown, not told by your customers. Learn through their actions instead of their opinions. If you ran a burger joint, it would be stupid to survey your customers.\n\n\n---\n\n\nabout whether they prefer cheeseburgers or hamburgers. Just watch what they buy (but if you’re trying to understand why they prefer one over the other, you’ll have to talk to them).\n\nFolks can’t be wishy-washy when you’re watching them do the task in question. Get as close to the real action as you can. Seeing it first hand can provide unique insight into murky situations. But if you can’t get in there, asking them to talk you through the last time it happened still offers many of the benefits.\n\nBeing walked through their full workflow answers many questions in one fell swoop: how do they spend their days, what tools do they use, and who do they talk to? What are the constraints of their day and life? How does your product fit into that day? Which other tools, products, software, and tasks does your product need to integrate with?\n\nRule of thumb: Watching someone do a task will show you where the problems and inefficiencies really are, not where the customer thinks they are.\n\n# \"What else have you tried?\"\n\nGood question. What are they using now? How much does it cost and what do they love and hate about it? How much would those fixes be worth and how big of a pain would it be for them to switch to a new solution?\n\nI was checking out an idea with a potential customer and they excitedly said, “Oh man, that happens all the time. I would definitely pay for something which solved that problem.”\n\nThat’s a future-promise statement without any commitment to back it up, so I needed to learn whether it was true or not. I asked, “When’s the last time this came up?” Turns out, it was pretty recent. That’s a great sign. To dig further, I asked, “Can you talk me through how you tried to fix it?” He looked at me blankly, so I nudged him further.\n\n\n---\n\n\n“Did you google around for any other ways to solve it?” He seemed a little bit like he’d been caught stealing from the cookie jar and said, “No… I didn’t really think to. It’s something I’m used to dealing with, you know?”\n\nIn the abstract, it’s something he would “definitely” pay to solve. Once we got specific, he didn't even care enough to search for a solution (which do exist, incidentally).\n\nIt’s easy to get someone emotional about a problem if you lead them there. “Don’t you hate when your shoelaces come untied while you’re carrying groceries?” “Yeah, that’s the worst!” And then I go off and design my special never-come-untied laces without realising that if you actually cared, you would already be using a double-knot.\n\nRule of thumb: If they haven't looked for ways of solving it already, they're not going to look for (or buy) yours.\n\n\"Would you pay X for a product which did Y?\" Bad question. The fact that you’ve added a number doesn’t help. This is bad for the same reasons as the others: people are overly optimistic about what they would do and want to make you happy. Plus, it’s about your idea instead of their life.\n\nLet’s fix it: As always, ask about what they currently do now, not what they believe they might do in the future. Common wisdom is that you price your product in terms of value to the customer rather than cost to you. That's true. And you can't quantify the value received without prodding their financial worldview.\n\nAnother way to fix it, if you’re far enough along, is to literally ask for money. If you have the deposit or pre-order in hand, you know they were telling the truth.\n\n\n---\n\n\n\"How are you dealing with it now?\"\n\nGood question. Beyond workflow information, this gives you a price anchor. If they’re paying £100/month for a duct-tape workaround, you know which ballpark you're playing in. On the other hand, they may have spent £120,000 this year on agency fees to maintain a site you're replacing. If that's the case, you don't want to be having the £100 conversation.\n\nSometimes, both of the above will be happening simultaneously and you get to choose how you present yourself. Do you want to be a replacement for the web app at a yearly value of £1.2k or for the agency at 100x that?\n\nRule of thumb: While it’s rare for someone to tell you precisely what they’ll pay you, they’ll often show you what it’s worth to them.\n\n\"Where does the money come from?\"\n\nGood question. This isn't something you would necessarily ask a consumer (though you might), but in a B2B context it’s a must-ask. It leads to a conversation about whose budget the purchase will come from and who else within their company holds the power to torpedo the deal.\n\nOften, you'll find yourself talking to someone other than the budget owner. Your future pitches will hit unseen snags unless you learn who else matters and what they care about. This knowledge of their purchasing process will eventually turn into a repeatable sales roadmap.\n\n\"Who else should I talk to?\"\n\nGood question. Yes! End every conversation like this. Lining up the first few\n\n\n---\n\n\nConversations can be challenging, but if you’re onto something interesting and treating people well, your leads will quickly multiply via intros.\n\nIf someone doesn’t want to make intros, that’s cool too. Just leave them be. You’ve learned that you’re either screwing up the meeting (probably by being too formal, pitchy, or clingy) or they don’t actually care about the problem you’re solving. Take anything nice they say with an extra grain of salt.\n\n\"Is there anything else I should have asked?\"\n\nGood question. Usually, by the end of the meeting, people understand what you’re trying to do. Since you don’t know the industry, they’ll often be sitting there quietly while you completely miss the most important point.\n\nAsking this question gives them a chance to politely “fix” your line of questioning. And they will!\n\nThis question is a bit of a crutch: you’ll discard it as you get better at asking good questions and as you get to know the industry.\n\nRule of thumb: People want to help you, but will rarely do so unless you give them an excuse to do so.\n\n# Using the mom test\n\nYou’ll notice that none of the good questions were about asking what you should build. One of the recurring “criticisms” about talking to customers is that you’re abdicating your creative vision and building your product by committee. Given that people don’t know what they want, that wouldn’t be a terribly effective approach. Deciding what to build is your job.\n\n\n---\n\n\n22\n\nThe questions to ask are about your customers’ lives: their problems, cares, constraints, and goals. You humbly and honestly gather as much information about them as you can and then take your own visionary leap to a solution. Once you’ve taken the leap, you confirm that it’s correct (and refine it) through Commitment & Advancement, which we’ll look at in Chapter 5.\n\nIt boils down to this: you aren’t allowed to tell them what their problem is, and in return, they aren’t allowed to tell you what to build. They own the problem, you own the solution.\n\nBefore we move look at ways to confirm that you’re building the right product to fit your customers’ lives, we’re going to look at fixing some of the ways conversations go wrong.\n\n\n---\n\n\n# CHAPTER TWO\n\n# Avoiding bad data\n\nThey say that to bankrupt a fool, give him information. Practically everyone I’ve seen talk to customers (including myself) has been giving themselves bad information. You probably are too. Bad data gives us false negatives (thinking the idea is dead when it’s not) and—more dangerously—false positives (convincing yourself you’re right when you’re not).\n\nThere are 3 types of bad data to watch out for:\n\n1. Compliments\n2. Fluff (generics, hypotheticals, and the future)\n3. Ideas\n\nSometimes we invite the bad data ourselves by asking the wrong questions, but even when you try to follow The Mom Test, conversations still go off track. It could happen because you got excited and started pitching, because you had to talk about your idea to explain the reason for the meeting, or because the conversation is just stuck in hypothetical la-la-land.\n\nThese things will happen. Once you start to notice the noise, it’s easy to get back on track by deflecting compliments, anchoring fluff, and digging beneath ideas.\n\n\n---\n\n\n# Deflect compliments\n\nMost of your meetings will end with a compliment. It feels good. They said they liked it!\n\nUnfortunately, they’re almost certainly lying. Not necessarily intentionally. They might want to be supportive or to protect your feelings. Or your excitement might be rubbing off on them.\n\nEven if they really do like it, that data is still worthless. For example, venture capitalists (professional judges of the future) are wrong far more than right. If even a VC's opinion is probably wrong, what weight could that of some random guy's possibly have?\n\nWith the exception of industry experts who have built very similar businesses, opinions are worthless. You want facts and commitments, not compliments.\n\nThe best way to escape the misinformation of compliments is to avoid them completely by not mentioning your idea. If they happen anyway, you need to deflect the compliment and get on with the business of gathering facts and commitments.\n\nBefore we look at how to properly deflect compliments, here's what happens when you take them at face value:\n\n# A bad conversation:\n\nYou: “…And that’s it. It’s like X for Y, but better because of Z.” Bam! Totally nailed that pitch.\n\nThem: “That’s really cool. I love it.” How is this even relevant to me? (Compliment)\n\n\n---\n\n\nYou: “It’s going to totally change the way you work. We’re predicting cost savings of 35%.” I am so great.\n\nThem: “Sounds terrific. Keep me in the loop.” I can’t believe I keep agreeing to these startup pitches. (Compliment + stalling tactic)\n\nYou: “Awesome, thanks.” I’m just like Steve Jobs. Except more handsome.\n\nYou: (Back at the office) “That meeting went really well. They said they loved it! In fact, everybody loves it. I really think we’ve finally found our big idea. We’ve found something people want.” It’s margarita time!\n\nYour Team: (6 months later) “Why do we have zero customers? I thought you said everybody loved it?” Wasn’t this your job?\n\nYou: “I don’t know, I talked to like a thousand people. I must have missed one of their buying criteria. Don’t worry, I’ll go talk to them some more and we’ll get it next time.” Doooooomed.\n\n# Let’s try that again while properly deflecting the confounding compliments:\n\n# A good conversation:\n\nYou: “…And that’s it. It’s like X for Y, but better because of Z.” Rats, I just slipped into pitch mode. Let’s try to recover this and learn something.\n\nThem: “That’s really cool. I love it.” How is this even relevant to me? (Compliment)\n\nYou: “Whoops — really sorry about that — I got excited and started pitching. Listen: you guys seem to be doing a good job in this space — do you mind if I ask how you’re dealing with this stuff at the moment?” That compliment made me suspicious. Let's deflect it and find out whether they're a potential customer or are just trying to get rid of me.\n\nThem: “What? Oh, well, sure. We’ve got a couple people who manage\n\n\n---\n\n\nthe process just to make sure we’re all in sync, and then we use Excel and a lot of emails to keep it all moving. Anyway, I really like your idea. I’m sure it will do well.” If you want facts, here they are, but your idea still isn’t a good fit for me and there’s no way I’m going to express an interest in buying (notice the sneaky compliment at the end).\n\nYou: “I haven’t heard of anyone solving it quite like that — that’s interesting. Can you talk me through how it actually all fits together?” Let's ignore & deflect that compliment to focus on the fact that they’re spending a lot of money to solve this. Two full time staff!? I didn’t know it was worth this much.\n\nThem: (More delicious workflow data)\n\nYou: “What sort of difficulties have come up with that solution?” This is a bit generic and isn’t the world’s greatest question, but I’m trying to find an anchor to learn about workflow inefficiencies and bumps. When I find one, I’ll dig around that signal with more follow-ups.\n\nThem: (Even more workflow and alternate solution data)\n\nIf we’re early in the learning process, the meeting could end here quite happily. We have the learning we came for. If we were slightly later-stage and already had a product, we might continue by zooming in and pushing for commitments or sales.\n\nRemember though: you don’t need to end up with what you wanted to hear in order to have a good conversation. You just need to get to the truth. Here’s a good conversation with a solid negative result.\n\nA good (negative) conversation:\n\nThem: “That’s really cool. I love it.” Compliment.\n\nYou: “How are you dealing with this stuff at the moment?” Deflect that compliment and get to the real facts.\n\n\n---\n\n\nThem:\n\n“Oh, it’s really not that big of a deal for us. We kind of just ignore it.” The implications of the problem are non-existent so I’m not in the market for a solution.\n\nYou can always be happy with a conversation like the above. You saw through the false compliment and found the facts behind the mirage. If the conversation is going well, I’d try to have them talk me through their process anyway so I can try to figure out whether it’s an industry wide non-problem or something specific to their particular situation.\n\nDid you notice that in the conversations above, practically every response contains a sneaky compliment? They are pervasive, constantly trying to trick us into thinking the conversation “went well”.\n\nIgnoring compliments should be easy, but it’s not. We so desperately want to hear them that we are often tricked into registering them as positive data points instead of vacuous fibs. Sometimes it’s easier to spot the symptoms than to notice the original compliment.\n\n# Symptoms (in the meeting):\n\n- “Thanks!”\n- “I’m glad you like it.”\n\n# Symptoms (back at the office):\n\n- “That meeting went really well.”\n- “We’re getting a lot of positive feedback.”\n- “Everybody I’ve talked to loves the idea.”\n\nAll of these are warning signs. If you catch yourself or your teammates saying something like this, try to get specific. Why did that person like the idea? How much money would it save him? How would it fit into his life? What else has he tried which failed to solve his problem? If you don’t know, then you’ve got a compliment instead of real data.\n\nRule of thumb: Compliments are the fool’s gold of customer learning: shiny,\n\n\n---\n\n\ndistracting, and entirely worthless.\n\n# Anchor fluff\n\nFluff comes in 3 cuddly shapes:\n\n- Generic claims (“I usually”, \"I always\", \"I never\")\n- Future-tense promises (“I would”, \"I will\")\n- Hypothetical maybes (\"I might\", \"I could\")\n\nWhen someone starts talking about what they “always” or “usually” or “never” or “would” do, they are giving you generic and hypothetical fluff. Just follow The Mom Test and bring them back to specifics in the past. Ask when it last happened, for them to talk you through it, how they solved it, and what else they tried.\n\nThe world’s most deadly fluff is: “I would definitely buy that.”\n\nIt just sounds so concrete. As a founder, you desperately want to believe it’s money in the bank. But folks are wildly optimistic about what they would do in the future. They’re always more positive, excited, and willing to pay in the imagined future than they are once it arrives.\n\nThe first startup I worked at fell for the “I would definitely buy that” trap and subsequently lost about 10 million bucks. They mistook fluffy future promises and excited compliments for commitment, wrongly believed they had proven themselves right, and wildly over-invested.\n\nThe worst type of fluff-inducing question you can ask is, “Would you ever?” Of course they might. Someday. That doesn't mean they will. Fluff-inducing questions include:\n\n- “Do you ever…”\n\n\n---\n\n\n29\n\n- “Would you ever…”\n- “What do you usually…”\n- “Do you think you…”\n- “Might you…”\n- “Could you see yourself…”\n\nYou don’t need to avoid these questions 100% of the time. They aren’t exactly toxic. It’s just that the responses to them are useless. The mistake is in valuing the answers, not in asking the questions. In fact, sometimes these questions can help the tempo when you’re transitioning into more concrete questioning. Here’s an example.\n\nTransitioning from a fluffy question to a concrete one:\n\nYou: “Do you ever X?” A fluff-inducing question.\n\nThem: “Oh yeah, all the time.” A fluffy answer which has no value in itself, but which we can anchor from.\n\nYou: “When’s the last time that happened?” We use the Mom Test and ask for concrete examples in the past.\n\nThem: “Two weekends ago.” We’ve successfully anchored the fluff and are ready to get real facts now instead of generics and hypotheticals.\n\nYou: “Can you talk me through that?” Back to asking good questions.\n\nTo use a more tangible example, let’s say you’re designing some sort of inbox management tool:\n\nA good conversation, anchoring generic fluff:\n\nThem: “I’m an ‘Inbox 0’ zealot. It’s totally changed my life.” A generic (e.g. fluffy) claim.\n\nYou: “Haha, nice. I’m an ‘Inbox 0’ failure. What’s your inbox at right\n\n\n---\n\n\nnow?” Let’s get specific to see if this fluff holds up.\n\nThem: “Looks like about ten that have come in since this morning.”\n\nFacts!\n\nYou: “Okay wow, so you are on top of things. I have like 200 right now. When’s the last time it totally fell apart for you?”\n\nHe’s still claiming to be on top of his email, so I’m going to look for concrete examples where he wasn’t.\n\nThem: “Ug, 3 weeks ago. I was travelling and the internet at the hotel totally didn’t work. It took me like 10 days to get back on track.”\n\nYou: “Can you talk me through how you handled it?” Successfully anchored — now we’re talking about what actually happens instead of what “usually” happens.\n\nIn this case, we took the generic claim, “My inbox is always under control” and added the important caveat: “Except when it’s not, in which case it’s a total nightmare to recover from.” While using generics, people describe themselves as who they want to be, not who they actually are. You need to get specific to bring out the edge cases.\n\nLet’s say you’re building a mobile loyalty app to help stores give deals and discounts to their most loyal customers and you hear the guy in line in front of you complaining:\n\n# A bad conversation (pitching and accepting fluff):\n\nThem: “Which idiot decided it was a good idea to make me carry around a thousand cafe loyalty cards?”\n\nYou: “Whoa! Hey! I’m building a mobile app to help stores give out discounts to their most loyal customers so you’d never need to carry paper cards again. Do you think you would use something like that?” This is pretty much as bad of a question as you can find. You’ve revealed your ego and asked a “would you ever” question. You’re begging for a false positive.\n\n\n---\n\n\nThem:\n\n“Heck yes, it's about time! I would definitely use that.”\n\nFluffy hypothetical future promise!\n\nBy switching into pitch mode, we just wasted a perfectly good opportunity for learning and instead got a fistful of fluff. Let’s try again.\n\n# A good conversation:\n\nThem:\n\n“What idiot decided it was a good idea to make me carry around a thousand cafe loyalty cards?”\n\nYou: “It’s crazy, right? My wallet is like two feet thick. Hey — have you ever tried any of those loyalty apps for your phone?”\n\nThem:\n\n“Those exist?” Perhaps my rage is misplaced…\n\nYou: “Yeah, I’m sure you’ve seen the little signs for that one in the campus cafe.”\n\nThem:\n\n“Oh yeah, I remember that. I’m always kind of in a rush.” This is a nice bit of customer insight about their state of mind and circumstances when you’re trying to advertise to them.\n\nYou: “Why don’t you download it now?” If someone’s being flaky, put them to a decision. If they don’t care enough to try solving their problem already, they aren’t going to care about your solution.\n\nThem:\n\n“I’ll do it next time.” Not a real problem.\n\nYou can’t help but laugh when you hear this one. “Someone should definitely make an X!” “Have you looked for an X?” “No, why?” “There are like 10 different kinds of X.” “Well I didn't really need it anyway.”\n\nLong story short, that person is a complainer, not a customer. They’re stuck in\n\n\n---\n\n\nthe la-la-land of imagining they’re the sort of person who finds clever ways to solve the petty annoyances of their day.\n\nBeyond rousting some poor soul’s consumeristic hypocrisy, anchoring the fluff can also yield useful signals:\n\nYou: “…Have you ever tried any of those loyalty apps for your phone?”\n\nThem: “Yeah, I downloaded a couple of them. You need a different one for every chain. I don’t want a hundred apps clogging up my phone any more than I want a bunch of cards in my wallet.”\n\nSo he’s an actively searching potential user, but we’d need to get critical mass with the stores he goes to before he'll be happy. Maybe we could take over a small university town first. Or he might say:\n\nThem: “I looked into it, but you only end up getting like a 10% discount. That seems less like a loyalty reward and more like a cheap way for them to collect a bunch of data about me.”\n\nSo he was on the fence, but needs better perks. Maybe we could find a way to force merchants into deeper discounts like Groupon was able to do. He also has privacy concerns. Or he could respond with:\n\nThem: “Have you ever actually tried using that app? It's abysmal. It takes me longer to find the stupid button than to buy my coffee.”\n\nSo all we need to do (for this particular user) is to out-execute and simplify. We could try to be the Instagram to their flickr.\n\nThe list goes on. There are tons of useful responses you can get. Even learning that the person is a non-customer is useful. To get toward this truth, you just need to reject their generic claims, incidental complaints, and fluffy promises. Instead, anchor them toward the life they already lead and the actions they’re already taking.\n\n\n---\n\n\n# 33\n\nDig beneath ideas\n\nEntrepreneurs are always drowning in ideas. We have too many ideas, not too few. Still, folks adore giving us more. At some point during a good conversation, the person you’re talking to may “flip” to your side of the table. This is good news. They are excited and see the potential, so they’ll start listing tons of ideas, possibilities and feature requests.\n\nWrite them down, but don’t rush to add them to your todo list. Startups are about focusing and executing on a single, scalable idea rather than jumping on every good one which crosses your desk.\n\nLet’s say you’re mid-conversation when this idea drops:\n\nThem: “Are you guys going to be able to sync to Excel? I really think that’s the a killer feature.”\n\nWhat do you do here? The wrong response is to write “sync to Excel” on your todo list and then move on. That’s the fast-lane to feature-creep. Instead, take a moment to dig into the motivations behind the request.\n\nYou: “What would syncing to Excel allow you to do?” Maybe there’s an easier way I can help you achieve the same thing.\n\nThem: “We’ve got all these legacy reports and we need to go through them every now and then. It would be nice to have everything in one place, you know?” Don’t worry, it’s not a key buying criteria.\n\nOr they might say:\n\nThem: “We’ve tried a bunch of these things and it’s always the syncing that kills it.” They’re actively searching for solutions which are all missing a must-have feature — this could be your major differentiator if it’s important enough.\n\n\n---\n\n\nto the segment and difficult enough for your competitors to emulate.\n\nOr:\n\nThem: “We have a decent workaround, as you saw. But it takes nearly a week at the end of each month to pull all the reports together in one place. It’s a big pain and totally stalls our work.” They’ve cobbled together a home-brew solution, know it’s costing them money, and are ideally suited to become an early customer.\n\nAt my first company Habit, we were adapting our product to sell to enterprise companies. MTV told me they needed analytics and reports for their campaigns.\n\nI made a big mistake by accepting the feature request at face value and beginning the next meeting with a demo of our shiny new analytics dashboard (custom-built to solve their request, of course). They “ooh’ed” and “ahh’ed” appropriately and I left thinking we’d nailed it. It offered a zillion options and could carve up your data every which way. It was technically and aesthetically lovely.\n\nUnfortunately, 90% of what we had built was irrelevant. We just didn’t know that yet.\n\nThey started calling every Friday asking me to email over a CSV (data file) of the week’s stats, so we added CSV export to the dashboard. Later, they asked for the report as a PDF instead of a CSV, so we obediently built PDF export. That took longer.\n\nSalt was rubbed in the wound when, weeks later, they were still calling me every Friday and asking me to export and send over the same stupid analytics report. And every week, I would do so while politely explaining that, you know, we built this awesome self-serve dashboard so they could have their data whenever they wanted. And then, the next Friday, they’d call me.\n\nIt turned out we had entirely missed the real reason they’d been excited about\n\n\n---\n\n\nour analytics demo. In fact, we'd missed their whole motivation for wanting analytics.\n\nThe memory of being burned by feature requests was still fresh in my mind when they asked if we could add their logo and colours to the reports. I asked a couple incredulous questions about why in the world they wanted this feature when they didn’t even use the ones I had already built, like an exasperated Dad at Christmas: “But you don’t even play with the toys I bought for your birthday!”\n\nSo, I finally—and inadvertently—did the smart thing when I asked, “Why do you want this feature? What do branded reports get you that unbranded ones don’t? It’s the same data, right?” She replied, “Oh yeah, of course. I mean, nobody even reads these. Our clients just like to get something emailed to them at the end of every week and we think they’d be happier if it was a bit fancier, you know?” I knew exactly.\n\nThey had asked for analytics. We had jumped to the conclusion that they wanted to better understand their data. But they had really wanted a way to keep their own clients happy. If we had properly understood that, we would have built a totally different (and much simpler) set of features.\n\nConsider how much easier our lives would have been if we’d understood the motivation behind the request. Instead of enabling the exploration and export of all campaign data, we could have just always exported the few high-level numbers a big brand manager would be interested in. And instead of a self-serve dashboard, we could set up a little scheduler to send it to them every Friday. In fact, we didn’t even need to build a dashboard at all. And instead of coding up a layout and branding system for the reports, we could have had an intern hand-build them each week. All wasted because I didn’t ask the right question. I sure wish I had those 3 months back!\n\nWhen you hear a request, it’s your job to understand the motivations which led to it. You do that by digging around the question to find the root cause. Why do they bother doing it this way? Why do they want the feature? How are they currently coping without the feature? Dig.\n\n\n---\n\n\nYou should dig in the same way around emotional signals to understand where they’re coming from. Just like feature requests, any strong emotion is worth exploring. Is someone angry? Dig. Embarrassed? Dig. Overjoyed? Dig!\n\nI once overheard a founder interviewing someone at a cafe table next to me. The founder mentioned a problem and the guy responded, “Yeah, that’s pretty much the worst part of my day.” The founder jotted something down in his notebook, and then moved on to the next question. What!? It’s the worst part of his day and you’re not going to figure out why? That’s insane. You’ve got to dig.\n\n# Questions to dig into feature requests:\n\n- “Why do you want that?”\n- “What would that let you do?”\n- “How are you coping without it?”\n- “Do you think we should push back the launch and add that feature, or is it something we could add later?”\n- “How would that fit into your day?”\n\n# Questions to dig into emotional signals:\n\n- “Tell me more about that.”\n- “That seems to really bug you — I bet there’s a story here.”\n- “What makes it so awful?”\n- “Why haven’t you been able to fix this already?”\n- “You seem pretty excited about that — it’s a big deal?”\n- “Why so happy?”\n- “Go on.”\n\nThese nudges don’t need to be complicated. People love talking about their opinions and emotions. Digging into a signal is basically just giving them permission to do a brain dump.\n\nRule of thumb: Ideas and feature requests should be understood, but not obeyed.\n\n\n---\n\n\n# Stop seeking approval\n\nAs we’ve seen, compliments are dangerous and sneaky. So if we can nip them in the bud before they bloom, so much the better. The main source of compliment-creation is seeking approval, either intentionally or inadvertently.\n\nDoing it intentionally is fishing for compliments. You aren’t looking for contradictory information. You’ve already made up your mind, but need someone’s blessing to take the leap.\n\n# Symptoms of Fishing For Compliments:\n\n- “I’m thinking of starting a business... so, do you think it will work?”\n- “I had an awesome idea for an app — do you like it?”\n\nAccidental approval-seeking is what I call “The Pathos Problem.” It happens when you expose your ego, leading people to feel they ought to protect you by saying nice things.\n\nThis comes up when you tell someone about an idea you obviously care about (which is pretty much always, since otherwise you wouldn’t be asking). Even if you give folks permission to be honest and ask for criticism, they’re still going to pull their punches.\n\n# Symptoms of The Pathos Problem:\n\n- “So here’s that top-secret project I quit my job for... what do you think?”\n- “I can take it — be honest and tell me what you really think!”\n\nTo deal with The Pathos Problem, keep the conversation focused on the other person and ask about specific, concrete cases and examples. Once someone detects that your ego is on the line, they’ll give you fluffy mis-truths and extra compliments. Disregard that data and use The Mom Test to re-focus on the person, their life, and their goals. People rarely lie about specific stuff that’s.\n\n\n---\n\n\nalready happened, regardless of your ego. Some famous entrepreneurs don’t suffer the effects of The Pathos Problem, but you should ignore their advice since it’s not reproducible if you aren’t them. Guys like Elon Musk, Reid Hoffman, and Gordon Ramsey are all notorious for actively seeking negative feedback. It evidently works for them. But nobody is worried about hurting Elon, Reid, or Gordon’s feelings. You and I must be more circumspect.\n\nIn short, remember that compliments are worthless and people’s approval doesn’t make your business better. Keep your idea and your ego out of the conversation until you’re ready to ask for commitments.\n\n# Rule of thumb:\n\nIf you’ve mentioned your idea, people will try to protect your feelings.\n\n# Cut off pitches\n\nBeing pitchy is the dark side of the “seeking approval” coin. Instead of inviting compliments by being vulnerable, you’re demanding them by being annoying. It’s when you hold someone hostage and won’t let them leave until they’ve said they like your idea. Normally, compliments are well-intentioned. In this case, they’re just trying to get you out of their office.\n\n“Won’t-take-no-for-an-answer” is generally a good quality for a founder to have. But when it creeps into a conversation that’s meant to be about learning, it works against you.\n\n# Symptoms:\n\n- “No no, I don’t think you get it...”\n- “Yes, but it also does this!”\n\nIf you slip into pitch mode, just apologise. You’re excited about your idea.\n\n\n---\n\n\nThat’s good! Otherwise you wouldn’t have taken this crazy leap in the first place. But suddenly, you find yourself five minutes into an enthusiastic monologue while the other person nods politely. That’s bad. Once you start talking about your idea, they stop talking about their problems. Cut yourself off and say something like:\n\n“Whoops—I just slipped into pitch mode. I’m really sorry about that—I get excited about these things. Can we jump back to what you were just saying? You were telling me that…”\n\nIf they say they really want to hear about what you’re working on, promise that you’ll tell them at the end of the meeting or loop them in for an early demo, and that you just want to talk a bit more about their stuff before biasing them with your idea.\n\nRule of thumb: Anyone will say your idea is great if you’re annoying enough about it.\n\n# Talk less\n\nYou can’t learn anything useful unless you’re willing to spend a few minutes shutting up (even if you have something really smart to say).\n\nAfter you introduce your idea (either intentionally or accidentally), they’re going to begin a sentence with something like “So it’s similar to…” or “I like it but…”. It’s tempting (and common) to interrupt and “fix” their understanding about how it’s totally different than that competitor or it actually does do that thing they want.\n\nAlternately, they’ll raise a topic you have a really good answer to. For example, they’ll mention how important security is, and you’ll want to cut in and tell them how you’ve thought about all that already. This is also a mistake.\n\n\n---\n\n\nIn both cases, the listener was about to give you a privileged glimpse into their mental model of the world. Losing that learning is a shame. You’ll have the chance to fill them in later. Plus, it’s annoying to people if they start trying to help you and you cut them off to correct them. Nobody likes a know-it-all!\n\nRule of thumb: The more you’re talking, the worse you’re doing.\n\n\n---\n\n\n# CHAPTER THREE\n\n# Asking important questions\n\nOnce we know about The Mom Test and start trying to ask non-biasing questions, sometimes we over-compensate and ask completely trivial ones. Asking someone how old they are isn’t biasing, but it also doesn’t move your business forward. You have to apply The Mom Test to the questions which matter. Otherwise you’re just spinning your wheels.\n\nIn addition to ensuring that you aren’t asking trivialities, you also need to look for the world-rocking scary questions you’re shrinking from. The best way to find them is to run thought experiments. Imagine that the company has failed and ask why that happened. Then imagine it as a huge success and ask what had to be true to get there. Find ways to learn about those critical pieces.\n\nYou can tell it’s an important question when the answer to it could completely change (or disprove) your business. If you get an unexpected answer to a question and it doesn’t affect what you’re doing, it wasn’t a terribly important question.\n\nEvery time you talk to someone, you should be asking a question which has the potential to completely destroy your currently imagined business.\n\n\n---\n\n\nOne of my companies had some legal ambiguities around content ownership. It was okay in theory, but lacked strong precedents. I was always a bit nervous we would get “found out.” Their execs were excited, their creatives were thrilled. We had even brought the stubborn tech team around to our side. But in all my early customer conversations, I never asked to talk to their lawyers. For whatever reason, that was an important question which I shrunk from, and not asking it cost us at least half a million bucks.\n\nThere’s no easy solution to making yourself face and ask these questions. I once heard the general life advice that, for unpleasant tasks, you should imagine what you would have someone else do if you were delegating it. Then do that.\n\nAnd remember, you’re allowed to ask about money. You're a startup. It's okay.\n\n# Rule of thumb:\n\nYou should be terrified of at least one of the questions you’re asking in every conversation.\n\n# Love bad news\n\nOne of the reasons we avoid important questions is because asking them is scary. It can bring us the upsetting realization that our favourite idea is fundamentally flawed. Or that the major client is never going to buy. Although it seems unfortunate, this we need to learn to love bad news. It’s solid learning and is getting us closer to the truth.\n\nIf you’ve only got one shot, then bad news is bad news. If your bungee jump doesn’t work, that’s bad. If you’ve sunk your retirement savings into opening a cafe and it doesn’t work, that’s bad. If you hustle together $50k to start your business and spend all $50k on your first idea only to see it fail, that’s bad.\n\nOn the other hand, if you have $50k and spend $5k to learn you’re running down a dead end, that’s awesome. You can use the rest to find a viable path to your goal.\n\n\n---\n\n\nSimilarly, if you have an exciting idea for a new product and go talk to a couple customers who don’t actually care about it, then that’s a great result. You just saved yourself however much time and money it would have cost to try building and selling it.\n\nWe go through the futile process of asking for opinions and fish for compliments because we crave approval. We want to believe that the support and sign-off of someone we respect means our venture will succeed. But really, that person’s opinion doesn’t matter. They have no idea if the business is going to work. Only the market knows.\n\nYou’re searching for the truth, not trying to be right. And you want to do it as quickly and cheaply as possible. Learning that your beliefs are wrong is frustrating, but it’s progress. It’s bringing you ever closer to the truth of a real problem and a good market.\n\nThe worst thing you can do is ignore the bad news while searching for some tiny grain of validation to celebrate. You want the truth, not a gold star.\n\nSome of the most informative (and thus best) responses you can get are along the lines of, “Umm, I’m not so sure about that” and \"That's pretty neat.\" Both are lukewarm responses which tell you they don’t care.\n\nIn this context, “best” means learning, not selling. If you’re a sales guy going door to door selling gadgets and someone doesn’t care, then that is a bad result: you’re not getting paid. But if you’re trying to decide whether to invest your time and money in developing, building and promoting that gadget, then lukewarm is a terrific response. It gives you a crystal clear signal that this person does not care. It’s perfectly reliable information you can take to the bank.\n\nThe classic error in response to a lukewarm signal is to “up your game” and pitch them until they say something nice. Unless they’re holding a check, the only thing to gain from “convincing” them are false positives. You’re not here to collect compliments; you’re trying to learn the truth. Their lukewarm response already gave you that.\n\n\n---\n\n\nIf they’re still engaged in the conversation, it’s worth asking a couple follow-up questions to understand the nature of their apathy. Is the “problem” not actually that big of a deal? Are they fundamentally different from your ideal customers? Do they not care about the specific implementation? Are they worn out and skeptical from hearing too many pitches, like cafe owners in the aftermath of Groupon? Are they just plain tired today?\n\nAfter that, say a big thanks and leave them to their day. They’ve probably helped you more than the guy who said he loved it.\n\nRule of thumb: There’s more reliable information in a “meh” than a “Wow!” You can’t build a business on a lukewarm response.\n\n# Look before you zoom\n\nAnother way we miss the important questions is by instead spending our time on ultimately unimportant details. This can happen when we get stuck in the details before understanding the big picture.\n\nMost people have lots of problems which they don’t actually care enough about to fix, but which they’ll happily tell you the details of if you ask them. Before you have solid evidence that you’re fixing a meaningful problem for your customer segment, you can really mess yourself up by zooming in too quickly.\n\n# A (really, really) bad conversation:\n\nYou:\n\n“Hello. Thanks for taking the time. We’re building phone and tablet apps to help people stay in shape and just wanted to understand how you stay fit.” This isn’t a terrible opening, but I’d generally avoid mentioning the idea immediately since it gives them a good idea of which answers you’re hoping to hear.\n\nThem:\n\n“Okay.” I never exercise, so this should be quick.\n\n\n---\n\n\nYou: “How often do you go to the gym?” This sort of demographic data doesn’t give you any new insight, but can still be useful at the start of a conversation to figure out what sort of person you’re talking to so you can ask relevant follow-ups.\n\nThem: “Not really ever.” Well, looks like we’re done here then!\n\nYou: “What would you say your biggest problem with going to the gym is?” This is where the conversation goes horribly wrong. Instead of figuring out whether staying fit is actually a real problem, we’re prematurely zooming in on it. Any response we get is going to be dangerously misleading.\n\nThem: “I guess the time it takes to get there. I’m always kind of busy, you know?” Wait, who says I have a problem with going to the gym? I thought I just told you I don’t care about the gym! But if I had to choose one, I guess I’d go with convenience. Not that I’ve done a pushup in 5 years. Pushups are pretty convenient.\n\nYou: “Perfect. That’s great. And could you rank these 4 in terms of which is most important to you in a fitness program: convenience, personalisation, novelty, or cost?” Note that we’re still assuming we’re talking to a person who actually cares about getting in shape. Questions like this don’t actually tell you if the person cares about any of it at all.\n\nThem: “Probably convenience, then cost, then personalisation, then novelty.” Since you asked, I’ll answer. Hypothetically speaking, of course.\n\nYou: “Okay. Awesome. Thanks so much. We’re working on an app to help you exercise in the convenience of your own home. I think it’s going to be a great fit for what you care about.” Totally missing the point and mis-interpreting the conversation as validation. Now fishing for compliments.\n\nThem: “Cool. I’d love to try it when it launches.” Half-hearted compliment plus non-committal stalling tactic.\n\nYou: “Great — I’ll send over one of our beta keys so you can check it\n\n\n---\n\n\nout.” We got a user!\n\nThem: “Thanks.” I am literally never going to type that in.\n\nThe reason this conversation is so very bad is because, if you aren’t paying attention, it seems like it went well. If you focus the conversation too quickly on one problem area, you can think you’ve validated a “top” problem when you haven’t. You just led them there.\n\nIf you ask me what my biggest problem with staying fit is, I’ll probably tell you it’s the time cost of going to the gym. But then, if you build me a workout-at-home app, I’m going to ignore it. Even though commute time is the biggest problem with getting in shape, the whole area of fitness just isn’t something I care about enough to act on. My #1 fitness problem is still an unimportant one.\n\nLet’s start the conversation in the same way and fix it when it starts to go off track:\n\n# A good conversation\n\nYou: “How often do you go to the gym?”\n\nThem: “Um. Not really ever.” Looks like we’re done here.\n\nYou: “Why not?” Instead of taking for granted that staying fit is one of their top priorities, let’s dig into the motivations.\n\nThem: “I don’t know, it’s just not something I’m that worried about, you know?” Not trying to fix this, so unlikely to buy or use an app.\n\nYou: “When’s the last time you did try? Have you ever joined a gym or taken up jogging or anything?” Let’s anchor the generic just to make sure…\n\nThem: “Oh yeah, I used to be into sports in high school. It just hasn’t been a big deal since I settled down. Running around after the kids gives me all the cardio I need!”\n\n\n---\n\n\nYou: “Haha, gotcha. Thanks for the time!” This was a pleasant conversation and we learned what we came for, so we can abandon ship and leave him to his day.\n\nThe premature zoom is a real problem because it leads to data which seems like validation, but is actually worthless. In other words, it’s a big source of false positives.\n\nLet’s re-run the same conversation, but instead of immediately zooming in on exercise, we’ll start more generic, since we aren’t sure that fitness is a must-solve problem:\n\n# A good conversation:\n\nYou: “What are your big goals and focuses right now?” Products which solve problems on this list are infinitely more likely to get bought. We might alternately ask for major annoyances, costs, or joys.\n\nThem: “The big one is finalising that promotion at work. And we just bought our first house, so I’ve got to get that all fixed up and ready to go. Exciting times. And I want to find a bit more time for the missus, you know? Things have been pretty busy lately.” Work, house, and marriage. Not looking good for us!\n\nYou: “You’re buying a new house and expect to be less busy?”\n\nThem: “Can’t blame a guy for hoping.”\n\nYou: “Is getting healthier on that list?” We probably already know the answer, but it doesn’t hurt to ask leading questions when you’re about to abort the conversation anyway. If they come back with a positive, just be a little extra careful in making sure they aren’t lying.\n\nThem: “I’m actually feeling pretty good at the moment.” Not a customer.\n\nHowever, we don’t always need to start the conversation from the square one of\n\n\n---\n\n\ndo-they-care-at-all. Sometimes we know the problem exists as a top priority and we can safely zoom in immediately.\n\nFor example, let’s say we help drive qualified leads to small business websites. We know that marketing is always a top 3 problem for small businesses, so we can focus on it and start the conversation by zooming in with a question like:\n\nYou: What are your big problems with marketing? We can immediately zoom in on the problem if we are 100% certain it’s a must-solve problem which people are ready to pay for.\n\nVersus:\n\nYou: What are your big problems right now? If we aren’t sure it’s a must-solve problem, we start more generic to see if they care at all about the problem category, in which case they’ll mention it.\n\nNow imagine you’ve built the aforementioned marketing tool for small businesses and realise it could also be used to help bloggers get more attention. You’re wondering if you have another strong customer segment. However, since blogs have a harder time monetising traffic than small businesses, we can’t necessarily assume that they’re also going to happily pay for traffic.\n\nFor example, I have a blog which I quite like (but which I don’t take seriously as a business) at thestartuptoolkit.com. If you’re talking to me and you ask, “Hey Rob, what are your top problems with marketing your blog?” Then you’ve just prematurely zoomed on a non-problem.\n\nI’m going to tell you some sort of answer which sounds legit but is actually misleading. I might say that my keywords are all kind of generic, so it’s hard to attract the right people. Or that I walk a fine line between writing beginner and advanced articles, so it’s tough to attract the right people. Whatever. Problems exist with my blog marketing, but the whole space just isn’t something I’m too fussed about. I write because it’s fun, not because it’s how I pay my rent.\n\nTo have a useful conversation, you need to zoom back out to ask about my blog\n\n\n---\n\n\nin general, rather than marketing my blog.\n\n# A good conversation:\n\nYou:\n\n“Hey Rob, what are the top problems with your blog?”\n\nMe:\n\n“I’m pissed that Google Reader is disappearing — I feel that I’m going to lose like half my followers. And this book is consuming all of my interest in writing, so I haven’t really posted in months. And Wordpress seems so slow these days.” Of the topics here, one of them (Google Reader and audience size) is related to marketing, so you can anchor on that and figure out whether I’m a customer or just a complainer.\n\nYou:\n\n“That Google Reader thing is a mess. What are you doing about it?” Now that you’ve let me raise the topic, you know it’s on my mind and can more safely zoom in to talk about that specifically. As before, try to figure out what I’m already spending time and money on.\n\nMe:\n\n“Nothing, really. I don’t know what to do. But it sucks.” I’m not appearing terribly motivated, but the fact that I don’t know what to do could give you hope.\n\nYou:\n\n“Have you looked into what your options are?” Continue anchoring and digging.\n\nMe:\n\n“No, I just caught the drama on Hacker News.” I knew the reader-pocalypse was coming and didn’t even search around to properly understand the implications and my options. This just isn’t a big deal for me, despite how “annoyed” I claim to be.\n\nYou:\n\n“Are you going to make a serious effort to build your audience back up?” You are digging into the audience size signal, since it’s relevant to your space. It’s a fluff-inviting question (hypothetical future-tense), so you should be skeptical of the answer, but it’s hard to see a better way to get at the information you want from here. Not every question can be perfect, sadly.\n\nMe:\n\n“Probably just keep on writing when I have something to say. It’s\n\n\n---\n\n\nmore of a hobby than a business, really.\n\nAt this point, you might be suspicious about how much I actually care about my blog, despite going out of my way to mention it twice (hint hint: thestartuptoolkit.com). When it’s not clear whether a problem is a must-solve-right-now (e.g. you’re selling a painkiller) or a nice-to-have (you’re selling a vitamin), you can get some clarity by asking cost/value questions like the following.\n\n# “Does-this-problem-matter” questions:\n\n- “How seriously do you take your blog?”\n- “Do you make money from it?”\n- “Have you tried making more money from it?”\n- “How much time do you spend on it each week?”\n- “Do you have any major aspirations for your blog?”\n- “Which tools and services do you use for it?”\n- “What are you already doing to improve this?”\n- “What are the 3 big things you’re trying to fix or improve right now?”\n\nSome of these questions are generic, but give us signals that we can anchor on and dig around. The bulk of them are about finding out whether the person we’re talking to is taking this space seriously. Are they spending money or making money? Is it in their top 3? Are they actively looking for solutions?\n\nWhen you fall into a premature zoom, you can waste a ton of time figuring out the minutia of a trivial problem. Even if you learn everything there is to know about that particular problem, you still haven’t got a business.\n\nRule of thumb: Start broad and don't zoom in until you’ve found a strong signal, both with your whole business and with every conversation.\n\nGaze upon the elephant\n\n\n---\n\n\nLastly, sometimes we comfort ourselves by asking questions which don’t actually de-risk the business or resolve those critical, big, scary, lurking questions. We ignore the elephant in the room.\n\nLet’s say we suspect that teachers from the poorest schools are completely overloaded, and that our tools would save them time so they could better educate their students. We go talk to them and confirm that yes, they are completely overloaded. We then spend weeks with them, figuring out exactly what their dream tool would do. Unfortunately, we've missed the elephant, which is that the poorest schools may not have the budgets available to pay us what we need. We're liable to spend a huge amount of time exploring a real and urgent problem, only to hop into the deadpool due to our customer's budgeting issues.\n\nSuccessful startups tend to depend on multiple failure points. In this case it is both the needs of the teachers and the ability of the schools to pay us. If any of these conditions doesn't exist, we have to significantly overhaul our idea. It's tempting to obsess over the most interesting of several failure points and ignore the others. It's a great way to miss important questions.\n\nBeyond the risks of our customers and market, we also have challenges with our own product. Overlooking the product risks is just as deadly as overlooking the goals and constraints of our customers. Take the following conversation with a professional public speaker. Is it full of good data or bad data?\n\n# An ambiguous conversation:\n\nThem:\n“…I get paid 2 or 3 grand per talk. Sometimes more if it’s corporate work.” Some good pricing and value signals.\n\nYou:\n“Where do you get your gigs? Do you have an agent?” Trying to understand the alternatives.\n\nThem:\n“Yeah. He kind of sucks though. Most of my work comes through people who just know me from my blog or have seen my other talks.” Hardly a must-solve problem since he has a reliable workaround, but at\n\n\n---\n\n\nleast it’s high value.\n\nYou: “What’s wrong with the agent? And why do you still work with him?” Dig.\n\nThem: “I’m one of the lowest-paid people they work with, so I get ignored a lot. But sometimes he brings in deals, so whatever. It’s free money.” Good information on his motivations and goals.\n\nAt this point, let’s say I’m confident that getting gigs is important to him. I also know what it’s worth and how he’s currently accomplishing it. So I zoom in to introduce the problem I’m solving and the way I want to approach it.\n\nYou: “I’m building a marketplace to cut out the agents and connect event organisers directly with speakers. It should help you get more gigs and keep the agent fees. How would that fit into your speaking life?”\n\nThem: “Man, that’s awesome. If you could get me more more gigs — or better paid ones — I’d happily drop my agent and pay you 20% of the boost. I know a bunch of other people who would love to as well.” This is the important bit — is it good?\n\nSo what’s the result? Beyond being excited, we got some concrete data about how valuable this could be to him. Plus, it involved a commitment to be one of our early users. It sure seems good.\n\nBut what did he actually tell us? He said that if we can get him more gigs, then he’ll pay a cut. Well, obviously. Who doesn’t want free money? His needs are clear: he wants to make more money by speaking. If we can send him work, he’ll share some of it with us. This was never really in doubt.\n\nThe key phrase of “if you could get me more gigs” is basically shifting the burden from the customer to your product. Even though you’ve found a pain, your success is dependent on a bunch of other factors, such as your ability to grow a healthy supply of paying gigs which are a good fit for him. Will you be\n\n\n---\n\n\nable to do that? It remains to be seen. This situation is easier to spot in the online advertising industry. Imagine running customer conversations with an advertiser to try to understand their pains so you can convince them to advertise on your site. They’d sort of look at you blankly and say, “Listen, if you can get enough page views, we’ll pay you for them.” In fact, it’s such a well established would-pay-to-solve-problem that you don’t even need to talk to them to set it up. You just plug in an ad network and you’re done.\n\nSimilarly with affiliate commissions. If you sell a company’s products, you get a cut. That’s just how it works. You don’t need to explore or validate or understand their problems. The risk resides in your ability to get lots of traffic and sell lots of products. If you can, they’ll pay you.\n\nIn all of these examples, the risk is in your product, not in the market or the customer. The customer will pay if your product gets big enough.\n\n- Product risk — Can I build it? Can I grow it? Will they keep using it?\n- Market risk — Do they want it? Will they pay? Are there enough of them?\n\nYou don’t want to overlook one or the other. I met a founder who had wasted 3 months on worthless customer conversations. He wanted to start a company building gadgets to track the fertility of farm animals, ultimately boosting birthrates and thus revenue. When he talked to farmers, he asked questions like, “Would you switch trackers if something cheaper and more effective was available?” That’s the same as asking someone whether they would like more money. The answer is always “Yes.” The farmers responded along the lines of, “If you can build what you say you can build, I’ll equip my whole herd.” The problem is, he couldn’t build it. The risk was in the product.\n\nI’ve also seen this strike several of the recent companies who want to use mobile/realtime deals to drive foot traffic to bars and clubs. They run customer conversations with bar owners who confirm that: yes, they would like more customers on the slow nights; and yes, they would pay you if you could send\n\n\n---\n\n\ncustomers on demand. The founders take this as strong validation (“They have the problem and committed to pay!”) without recognising that the vast majority of the risk is in the product, not the market. Bars will pay, but only if you can amass a huge audience of consumers. Then the founders talk to consumers and ask if they would use an app which always pointed them to booming parties with cheap booze. Again, obviously yes. But that doesn’t tell us whether we can actually get to that critical mass of users.\n\nVideo games are pure product risk. What sort of question could you ask to validate your game idea? “Do you like having fun?” “Would you like to have even more fun?” Practically 100% of the risk is in the product and almost none is in the customer. You know people buy games. If yours is good and you can find a way to make them notice it, they’ll buy it. You don’t need to rediscover people’s desire to play video games.\n\nThis isn’t to say that you shouldn’t talk to anyone if you’re building something with product risk. In the case of the farm fertility monitor, it’s good to know that the farmer isn’t opposed to switching tech once he’s already got something installed, for example. For the nightclubs, it’s good to know that they’re at least theoretically willing to pay for promotion. It would be tragic to succeed at the hard work of creating the technology or community only to learn nobody will pay for it.\n\nWhat all this does mean is that if you’ve got heavy product risk (as opposed to pure market risk), then you’re not going to be able to prove as much of your business through conversations alone. The conversations give you a starting point, but you’ll have to start building product earlier and with less certainty than if you had pure market risk.\n\n\n---\n\n\n\n# Signs that you’re just going through the motions:\n\n- You’re talking more than they are\n\n\n---\n\n\n109\n\n- They are complimenting you or your idea\n- You told them about your idea and don’t know what’s happening next\n- You don’t have notes\n- You haven’t looked through your notes with your team\n- You got an unexpected answer and it didn’t change your idea\n- You weren’t scared of any of the questions you asked\n- You aren’t sure which big question you’re trying to answer by doing this\n\nThe persistent presence of any of these problems suggests that you’re doing something wrong and wasting your time.\n\nHere are the steps I go through to keep on track. Feel free to ignore or tweak as needed given your situation and company. It’s as light-weight as I’ve been able to get it and should reduce rather than increase the amount of time you need to spend on conversations.\n\n\n\n\n# Cheatsheet\n\n# The Mom Test:\n\n1. Talk about their life instead of your idea\n2. Ask about specifics in the past instead of generics or opinions about the future\n3. Talk less and listen more\n\n# Getting back on track (avoiding bad data)\n\n- Deflect compliments\n- Anchor fluff\n- Dig beneath opinions, ideas, requests, and emotions\n\n# Mistakes and symptoms\n\n1. Fishing for compliments\n\n---\n\n\n# 2. Exposing your ego (aka The Pathos Problem)\n\n“So here’s that top-secret project I quit my job for... what do you think?”\n\n“I can take it — be honest and tell me what you really think!”\n\n# 3. Being pitchy\n\n“No no, I don’t think you get it...”\n\n“Yes, but it also does this!”\n\n# 4. Being too formal\n\n“So, first off, thanks for agreeing to this interview. I just have a few questions for you and then I’ll let you get back to your day…”\n\n“On a scale of 1 to 5, how much would you say you…”\n\n“Let’s set up a meeting.”\n\n# 5. Being a learning bottleneck\n\n“You just worry about the product. I’ll learn what we need to know.”\n\n“Because the customers told me so!”\n\n“I don’t have time to talk to people — I need to be coding!\n\n# 7. Collecting compliments instead of facts and commitments\n\n“We’re getting a lot of positive feedback.”\n\n“Everybody I’ve talked to loves the idea.”\n\n\n# Signs that you’re just going through the motions:\n\n- You’re talking more than they are\n- They are complimenting you or your idea\n- You told them about your idea and don’t know what’s happening next\n- You don’t have notes\n- You haven’t looked through your notes with your team\n- You got an unexpected answer and it didn’t change your idea\n- You weren’t scared of any of the questions you asked\n- You aren’t sure which big question you’re trying to answer by doing this\n- You aren’t sure why you’re having the meeting\n</sample_questions>",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        480,
        0
      ],
      "id": "f7a57698-48bb-4d08-952d-9fbe655a0266",
      "name": "Load Sample Questions"
    },
    {
      "parameters": {
        "modelName": "models/gemini-1.5-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        2720,
        220
      ],
      "id": "276801aa-b866-4509-9836-9f2c268a0fab",
      "name": "Google Gemini Chat Model1",
      "credentials": {
        "googlePalmApi": {
          "id": "flZ3VabFlV6wrHU6",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "65e26d81-0e9a-4f86-91ed-16f3f9c11c07",
              "name": "success",
              "value": "=true",
              "type": "boolean"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        5080,
        0
      ],
      "id": "2499848a-b678-4a3e-a728-6e72140f06b9",
      "name": "Edit Fields1"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "15771f84-de31-4984-89fb-ec166b38568c",
        "responseMode": "lastNode",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -320,
        0
      ],
      "id": "96b43f96-81d3-4f69-973e-b107cc66683d",
      "name": "Webhook",
      "webhookId": "15771f84-de31-4984-89fb-ec166b38568c"
    },
    {
      "parameters": {
        "operation": "get",
        "tableId": "transcriptions",
        "filters": {
          "conditions": [
            {
              "keyName": "id",
              "keyValue": "={{ $json.body.transcription_id }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        -60,
        0
      ],
      "id": "d9cce4f1-c20c-4c1a-9dc6-bc9166a8c987",
      "name": "Supabase",
      "alwaysOutputData": false,
      "credentials": {
        "supabaseApi": {
          "id": "sH3BELFwd99Zg2dt",
          "name": "Presto"
        }
      }
    },
    {
      "parameters": {
        "tableId": "documents",
        "fieldsUi": {
          "fieldValues": [
            {
              "fieldId": "type",
              "fieldValue": "interview_feedback"
            },
            {
              "fieldId": "content",
              "fieldValue": "={{ $('Interview Coach').item.json.text }}"
            },
            {
              "fieldId": "title",
              "fieldValue": "Interview Coaching"
            },
            {
              "fieldId": "transcription_id",
              "fieldValue": "={{ $('Webhook').item.json.body.transcription_id }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        3040,
        0
      ],
      "id": "f6a375ec-1f62-4d9c-a69f-b8cc1db7a219",
      "name": "Supabase1",
      "credentials": {
        "supabaseApi": {
          "id": "sH3BELFwd99Zg2dt",
          "name": "Presto"
        }
      }
    },
    {
      "parameters": {
        "tableId": "documents",
        "fieldsUi": {
          "fieldValues": [
            {
              "fieldId": "type",
              "fieldValue": "suggested_content"
            },
            {
              "fieldId": "content",
              "fieldValue": "={{ $json.output }}"
            },
            {
              "fieldId": "title",
              "fieldValue": "Recommended Readings"
            },
            {
              "fieldId": "transcription_id",
              "fieldValue": "={{ $('Webhook').item.json.body.transcription_id }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        4880,
        0
      ],
      "id": "6d7511c9-5015-4081-9ab5-39cfb65f47a8",
      "name": "Supabase2",
      "credentials": {
        "supabaseApi": {
          "id": "sH3BELFwd99Zg2dt",
          "name": "Presto"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "5b283b1e-b118-45cb-a49a-48e8ed0ed314",
              "leftValue": "={{ $('Webhook').item.json.body.agent }}",
              "rightValue": "summary",
              "operator": {
                "type": "string",
                "operation": "notEquals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        220,
        0
      ],
      "id": "58f0cb10-6e5b-40a1-9d7e-300742b7b80f",
      "name": "If"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.0-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        100,
        780
      ],
      "id": "966afc40-63da-4b3a-81e4-a7afdc70f19c",
      "name": "Google Gemini Chat Model2",
      "credentials": {
        "googlePalmApi": {
          "id": "flZ3VabFlV6wrHU6",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "tableId": "documents",
        "fieldsUi": {
          "fieldValues": [
            {
              "fieldId": "type",
              "fieldValue": "interview_summary"
            },
            {
              "fieldId": "content",
              "fieldValue": "={{ $('Interview Summarizer').item.json.text }}"
            },
            {
              "fieldId": "title",
              "fieldValue": "={{ $json.text }}"
            },
            {
              "fieldId": "transcription_id",
              "fieldValue": "={{ $('Webhook').item.json.body.transcription_id }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        740,
        600
      ],
      "id": "41d88c2f-dee2-4bde-bb70-1d30470484dc",
      "name": "Supabase3",
      "credentials": {
        "supabaseApi": {
          "id": "sH3BELFwd99Zg2dt",
          "name": "Presto"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "65e26d81-0e9a-4f86-91ed-16f3f9c11c07",
              "name": "success",
              "value": "=true",
              "type": "boolean"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1700,
        600
      ],
      "id": "96906980-3ad8-4d44-a336-4b27adb08689",
      "name": "Edit Fields"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<transcript>\n{{ $('Supabase').item.json.final_text }}\n</transcript>",
        "messages": {
          "messageValues": [
            {
              "message": "=You are a highly experienced product researcher providing feedback to a junior researcher. Your goal is to provide constructive and actionable feedback in markdown format to help improve their customer discovery interview skills. Focus on providing supportive, encouraging, specific, and actionable guidance, not just criticism. Use the *interviewing_users* document, *laddering_technique* document, and *sample_questions* document as your primary knowledge base and rubric; score and evaluate the interview transcript provided. \n\nDo not reference the word \"The Mom Test\" in your output text as we just want to reference the concepts, but not the actual name of that content as a source.\n\nSince this is a transcript-only analysis, focus your feedback on the *verbal content* of the interview. Do not make assumptions about body language or tone that are not explicitly stated in the text. Pay particular attention to the overall sentiment of the conversation and any shifts in sentiment. Comment on how effectively the interviewer acknowledged or responded to any emotional cues or sentiment changes.\n\n{{ $json.rubric }}\n\n# Provide your feedback in the following structured format:\n\n##Interview top level take-away (a short and punchy title)\n\n1.  **Overall Impression and Score (1-10):** Provide a *single* overall score from 1-10 representing your holistic assessment of the interview, *informed by* the rubric categories. Include a brief (1-2 sentence) justification for your score.\n\n2.  **Category-Specific Feedback:**\n    *   For *each* of the rubric categories, provide bulletized list that includes:\n        *   A rating (from the rubric scale: 1-10)\n        *   A brief (2-3 sentence) justification, citing specific examples from the transcript.  Connect your assessment to the descriptions in the rubric.\n\n3.  **Positive Feedback (Specific Examples):** Identify *at least* three specific things the interviewer did well. Cite the specific parts of the transcript that demonstrate these strengths. Connect the strengths to best practices from the \"Interviewing Users\" document or the rubric.\n\n4.  **Areas for Improvement (Prioritized, Specific Examples):**\n    *   Identify *at least* three important areas where the interviewer could improve. Include more if the rubric scoring is not high.\n    *   For *each* area, provide:\n        *   **The specific issue:** (Cite the relevant part of the transcript)\n        *   **Why it's a problem:** (Connect it to the principles in the reference documents or rubric)\n        *   **A specific, actionable suggestion:** (Give an example of *how* they could have rephrased the question or followed up, using techniques like JTBD, laddering, or open-ended questions. Go beyond just saying \"ask why more.\")\n        *   **Further Reading** (Cite chapters *only* from the Interviewing Users document to reference for additional help. Make sure to cite the book title and chapter.)\n    *   Prioritize feedback if the interviewer used leading questions or didn't dig into areas where the user expressed strong emotions without sufficient follow-up\n\n5.  **\"Digging Deeper\" Analysis:**\n    *   Focus specifically on how well the interviewer explored the underlying motivations and \"whys\" behind the user's answers. Did they uncover the root causes and desired outcomes *beyond* what's already covered in the rubric ratings?\n    *   Provide *at least one* example where they *could* have dug deeper, and suggest *how*, using techniques beyond just \"why\" (e.g., \"Tell me more about that...\", \"What led you to that decision?\", \"What were you hoping to achieve?\").  Consider laddering techniques and open-ended follow-up questions. \n    *   Prioritize digging deeper into areas relevant to the product's potential value or the user's core needs.\n\n6.  **Jobs to Be Done Specific Feedback:**\n    *   Analyze the interview for evidence of the *circumstances, functional, social, and emotional dimensions* of this Job to Be Done. Where did the interviewer succeed or miss opportunities to explore these dimensions? Be specific.\n    *  Include a Jobs to be Done (or JTBD for short) analysis using the *JTBD_framework* document. Propose possible jobs using the When __ (situation), I want to __ (motivation), so I can __ (expected outcome) language.\n\n7. **Sentiment Analysis and Response:**\n    * Evaluate how effectively the interviewer acknowledged and responded to emotional cues or changes in sentiment from the interviewee. Provide specific examples.\n    * If applicable, suggest ways the interviewer could have better handled or responded to the interviewee's emotions.\n\n8.  **Overall Recommendations and Encouragement:** Summarize your key suggestions and provide a final, positive comment to encourage the interviewer.\n\n# Documents for context\n{{ $('Load Laddering Technique').item.json.laddering_technique }} \n{{ $('Load Interviewing Users').item.json.interviewing_users }} \n{{ $('Load JTBD').item.json.jobs_framework }}\n{{ $('Load Sample Questions').item.json.sample_quesitons }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        2340,
        0
      ],
      "id": "3c9647e2-34f9-4525-890e-ded46e1ce527",
      "name": "Interview Coach"
    },
    {
      "parameters": {
        "modelName": "models/gemini-1.5-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        420,
        780
      ],
      "id": "567e1cd3-b7b8-4939-a1cc-d8f5283437fe",
      "name": "Google Gemini Chat Model4",
      "credentials": {
        "googlePalmApi": {
          "id": "flZ3VabFlV6wrHU6",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "modelName": "models/gemini-1.5-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        920,
        780
      ],
      "id": "51c67d79-6b96-4974-aad8-9bde0b387c5d",
      "name": "Google Gemini Chat Model6",
      "credentials": {
        "googlePalmApi": {
          "id": "flZ3VabFlV6wrHU6",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "text": "={{ $('Interview Summarizer').item.json.text }}",
        "schemaType": "fromJson",
        "jsonSchemaExample": "[{\n  \"quote\":\n  {\n    \"text\": \"The prep is more involved than the actual cooking\", \n    \"context\": \"This highlights the importance of streamlining the preparation process\"\n  }\n}]  ",
        "options": {
          "systemPromptTemplate": "=You are an expert extraction algorithm. Extract the quotes from the analysis along with the explanation/context for why it was selected.\n\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "typeVersion": 1,
      "position": [
        940,
        600
      ],
      "id": "2b2f9ce7-78e5-487a-8819-5f3ccdb0a8f2",
      "name": "Quote Extractor"
    },
    {
      "parameters": {
        "tableId": "key_quotes",
        "fieldsUi": {
          "fieldValues": [
            {
              "fieldId": "transcription_id",
              "fieldValue": "={{ $('Webhook').item.json.body.transcription_id }}"
            },
            {
              "fieldId": "quote_text",
              "fieldValue": "={{ $json.output.quote.text }}"
            },
            {
              "fieldId": "context",
              "fieldValue": "={{ $json.output.quote.context }}"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.supabase",
      "typeVersion": 1,
      "position": [
        1500,
        600
      ],
      "id": "749da12b-a131-40d6-b152-a61cf58fb4d6",
      "name": "Supabase4",
      "credentials": {
        "supabaseApi": {
          "id": "sH3BELFwd99Zg2dt",
          "name": "Presto"
        }
      }
    },
    {
      "parameters": {
        "fieldToSplitOut": "output",
        "include": "allOtherFields",
        "options": {}
      },
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [
        1300,
        600
      ],
      "id": "60bdfd2c-5fb0-4309-a4de-6961be758aff",
      "name": "Split Out"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $('Supabase').item.json.final_text }}",
        "messages": {
          "messageValues": [
            {
              "message": "=You are a Customer Interview Analysis Assistant. Your task is to analyze customer interview transcripts and produce insightful, concise, and actionable topline reports. You should synthesize information, infer meaning beyond surface-level statements, and identify underlying needs, emotional cues, and unspoken desires.  Emulate the combined expertise of a seasoned UX researcher and a strategic business consultant.  Do *not* simply repeat what was said; *interpret* the data.\n\n**Input:** A single customer interview transcript.\n\n**Output:**  A structured Interview Summary: A detailed analysis, formatted *exactly* as follows (use markdown for formatting):\n\n## [Catchy and short One-Sentence Summary of the Interview]\n\n### 1. Executive Summary\n\n*   Provide a single-paragraph executive summary. This is a high-level overview for a busy executive, highlighting the *most critical* findings and their *potential business implications*. Focus on the \"So What?\" – explain *why* these findings matter and what their impact might be. This should be self-contained and understandable without reading the rest of the report.\n\n### 2. Key Problems & Pains (Prioritized)\n\n*   List key customer problems, pains, obstacles, or workarounds mentioned in the interview.\n*   **Prioritization:** Order the problems from *most significant* to *least significant*. Base this prioritization on the user's:\n    *   Emotional intensity (expressed or inferred)\n    *   Frequency of mention\n    *   Potential impact on the business (your informed judgment)\n*   **Format:** Use bullet points.\n*   **Emotional Emphasis:** For problems associated with strong emotions (frustration, anger, delight, etc.), **bold** the problem statement.  Immediately after the bolded statement, include a short phrase in parentheses describing the emotion and its intensity (e.g., \"**Cannot find help documentation** (extreme frustration)\").\n*   **Underlying needs**: Identify the underlying need associated to the *each* problem. Be specific. Don't say \"needs better navigation.\" Say \"needs to quickly locate specific product information without extensive searching.\"\n\n### 3. Themes and Insights (with Actionable Implications)\n\n*   Identify and summarize 2-4 key themes that emerge from the interview. A theme is a recurring idea, concern, behavior pattern, or underlying need.\n*   For *each* theme:\n    *   **Theme Name:** A concise, descriptive name for the theme.\n    *   **Description:** Briefly describe the theme (1-2 sentences).\n    *   **Key Insights:** List 2-3 *specific* insights related to the theme. Insights are *interpretations* – go beyond the obvious and explain the \"why\" behind the theme.  These should be non-obvious deductions.\n    *   **Actionable Implications:** For *each insight*, state a *concrete, specific, and actionable* implication for product development, service design, marketing, or business strategy.  Be prescriptive.  Don't say \"Improve X.\" Say *how* it could be improved, grounded in the insight. (e.g., \"Insight: Users are overwhelmed by the number of options. Implication:  Reduce the number of initial choices presented to the user on the landing page and implement a guided filtering system to help them narrow down their options based on their specific needs.\")\n\n### 4. User Emotions (with Context)\n\n*   List significant emotions expressed or inferred during the interview.\n*   **Emotion Tags:** Use clear, consistent emotion tags (e.g., frustrated, excited, anxious, satisfied, disappointed, neutral, confused, confident).\n*   **Context is Crucial:** *Always* provide context for *each* emotion. Explain *what specifically* triggered the emotion.  (e.g., \"Anxious *about providing personal information during the registration process*\").\n*   **Intensity:** Indicate the intensity of the emotion (e.g., slightly, moderately, extremely).\n\n### 5. Jobs to Be Done (JTBD) - Detailed Analysis\n\n*   Identify *at least one* core \"Job to Be Done\" (JTBD) that the user is trying to accomplish. Focus on the underlying *goal* or *desired outcome*, not the specific task or feature.\n*   For *each* identified JTBD:\n    *   **Job Statement:** Write a complete JTBD statement using this *exact* format: \"When [Situation/Context], I want to [Motivation/Need], so I can [Expected Outcome].\"  Fill in the blanks accurately based on the interview content.\n    *   **Circumstances:** Describe the specific circumstances or context that trigger the need for this job. When does this job arise for the user? Be detailed.\n    *   **Functional Dimension:** What is the practical, functional task the user is trying to accomplish?\n    *   **Social Dimension:** How does the user want to be *perceived* by others while doing or after completing this job? (e.g., competent, efficient, helpful, innovative, resourceful).\n    *   **Emotional Dimension:** How does the user want to *feel* while doing or after completing this job? (e.g., confident, secure, relaxed, in control, satisfied, happy).\n    *   **Supporting Quotes:** Include 1-2 *direct quotes* from the transcript that *strongly support* your JTBD analysis. These quotes should provide clear evidence for your interpretation. Explain *briefly* why each quote was chosen.\n\n### 6. Sentiment Analysis and Response (with Shift Detection)\n\n*   **Overall Sentiment:** Analyze the overall sentiment of the transcript (positive, negative, or neutral). Be precise; if it's slightly positive, say so.\n*   **Sentiment Shifts:** Identify and describe any *significant shifts* in sentiment during the interview.\n    *   **Shift Description:** Describe the nature of the shift (e.g., \"Positive to negative,\" \"Neutral to very positive\").\n    *   **Trigger:** Identify the *specific topic or event* that triggered the shift.\n*   **Overall Tone:** Describe the overall *tone* of the interview (e.g., formal, informal, conversational, tense, enthusiastic, frustrated, sarcastic).\n\n### 7. Direct Quotes (Key Statements)\n\n*   Provide a maximum of 15 of the *most impactful and insightful direct quotes* from the user. These should be quotes that:\n    *   Reveal underlying needs or motivations.\n    *   Express strong emotions.\n    *   Highlight key problems or frustrations.\n    *   Offer unique perspectives.\n    *   Clearly illustrate a theme or insight.\n*   For *each* quote, briefly explain (1 sentence) *why* it was selected and what it reveals. (e.g., \"This quote highlights the user's frustration with the lack of clear instructions.\")\n\n### 8. Potential Biases\n\n*   Identify and briefly describe any potential biases that might have influenced the interview or the responses. Consider:\n    *   **Interviewer Bias:** Leading questions, unconscious assumptions, or reactions from the interviewer.\n    *   **Respondent Bias:** Social desirability bias (wanting to appear in a good light), recall bias (difficulty remembering details), acquiescence bias (agreeing with the interviewer).\n    *   **Sampling Bias:** Whether the interviewee is truly representative of the target user group.\n    *   **Confirmation Bias:** If the analysis itself may have been influenced in confirming pre-existing notions\n"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        100,
        600
      ],
      "id": "c0b78be0-3122-4cfc-aac5-995479422e61",
      "name": "Interview Summarizer"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.text }}",
        "messages": {
          "messageValues": [
            {
              "message": "Create a short, few-word concise title that describes the interview. "
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        420,
        600
      ],
      "id": "d9f140dd-8e12-4f35-908b-191ca59c2cfa",
      "name": "Create a title"
    },
    {
      "parameters": {
        "text": "={{ $json.text }}",
        "schemaType": "fromJson",
        "jsonSchemaExample": "{\n  \"areas_for_improvement\": [\n    \"Reduce leading questions, dig deeper into emotional cues\",\n    \"Apply probing techniques like laddering to uncover user motivations\"\n  ],\n  \"interview_scores\": {\n    \"overall\": 7,\n    \"establishing_rapport\": 5,\n    \"uncovering_needs\": 8,\n    \"active_listening\": 5,\n    \"leading_questions\": 4,\n    \"guiding_conversation\": 9,\n    \"learns_solution_space\": 3\n  }\n}",
        "options": {
          "systemPromptTemplate": "You are an expert extraction algorithm.\nExtract relevant information from the text. \nIf you do not know the value of an attribute asked to extract, you may omit the attribute's value."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.informationExtractor",
      "typeVersion": 1,
      "position": [
        2680,
        0
      ],
      "id": "851eafa7-37cd-4496-bd37-de3888d4b246",
      "name": "Extract structured data"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.firecrawl.dev/v1/scrape",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer fc-99efabccee814d0fb304484f39a7279c"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"url\": \"{{ $('Workflow Input Trigger').item.json.urls[0] }}\",\n  \"formats\": [\n    \"markdown\"\n  ]\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2820,
        -260
      ],
      "id": "69befcce-9384-4b8f-bb63-3908d5d24904",
      "name": "HTTP Request2",
      "executeOnce": false,
      "retryOnFail": false,
      "waitBetweenTries": 2000
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "7ccbc669-3931-4e64-bdc2-61b04828a4e5",
              "name": "title",
              "value": "={{ $json.data.metadata.title }}",
              "type": "string"
            },
            {
              "id": "b1e0f0b6-79a1-4e3f-b20f-a5848ac91a83",
              "name": "url",
              "value": "={{ $json.data.metadata.url }}",
              "type": "string"
            },
            {
              "id": "4cb9a89b-37f8-455a-9033-0a05f19d965b",
              "name": "text",
              "value": "={{ $json.data.markdown }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        3060,
        -260
      ],
      "id": "78b7a465-1d91-46a5-9da7-cb3fef786dba",
      "name": "Edit Fields4"
    },
    {
      "parameters": {
        "fieldsToSummarize": {
          "values": [
            {
              "field": "urls"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.summarize",
      "typeVersion": 1,
      "position": [
        2300,
        -400
      ],
      "id": "08ae8f84-e94e-43eb-bfcb-2d4bf28273c2",
      "name": "Summarize"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "4d9bd56f-f47e-4d1f-9829-d2f4267c8977",
              "leftValue": "={{ $json.count_urls }}",
              "rightValue": 1,
              "operator": {
                "type": "number",
                "operation": "gt"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2480,
        -400
      ],
      "id": "1f45372d-8429-4e67-842e-105893343eb7",
      "name": "If1"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.firecrawl.dev/v1/batch/scrape",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer fc-99efabccee814d0fb304484f39a7279c"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"urls\": {{ $('Start').item.json.urls }},\n  \"proxy\": \"basic\",\n  \"ignoreInvalidURLs\": true,\n  \"formats\": [\n    \"markdown\"\n  ]\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2760,
        -560
      ],
      "id": "35d51e91-4e10-4d8f-99de-6cd7c94d66da",
      "name": "HTTP Request",
      "executeOnce": false,
      "retryOnFail": false,
      "waitBetweenTries": 2000
    },
    {
      "parameters": {
        "fieldToSplitOut": "urls",
        "options": {}
      },
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [
        2140,
        -400
      ],
      "id": "ec117211-16f9-4754-a1b8-9d16dc0c5d20",
      "name": "Split Out1"
    },
    {
      "parameters": {
        "url": "={{ $('HTTP Request').item.json.url }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer fc-99efabccee814d0fb304484f39a7279c"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2960,
        -560
      ],
      "id": "9c4df7c6-2959-403b-b679-c12551febaff",
      "name": "HTTP Request3",
      "executeOnce": false,
      "retryOnFail": false,
      "waitBetweenTries": 2000
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "94dd33dd-8724-4690-bf94-d76ebeb27b37",
                    "leftValue": "={{ $json.status }}",
                    "rightValue": "=completed",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "completed"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "c2ce2a1d-fe56-4f1e-a44d-7775bd3eea27",
                    "leftValue": "={{ $json.status }}",
                    "rightValue": "=error",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "error"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "63a58ad9-92aa-4a93-901e-e732e4adb2f7",
                    "leftValue": "={{ $json.status }}",
                    "rightValue": "scraping",
                    "operator": {
                      "type": "string",
                      "operation": "equals",
                      "name": "filter.operator.equals"
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "scraping"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        3180,
        -640
      ],
      "id": "41fe70a8-cd54-4643-bf4e-69446045add3",
      "name": "Switch"
    },
    {
      "parameters": {
        "amount": 2
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        3400,
        -480
      ],
      "id": "bff4a549-3908-42cf-ba07-e9c7bc390c94",
      "name": "Wait",
      "webhookId": "fd8e2d4e-a802-4b44-8926-5917fa89b5b4"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "7ccbc669-3931-4e64-bdc2-61b04828a4e5",
              "name": "title",
              "value": "={{ $('SplitMarkdown').item.json.metadata.title }}",
              "type": "string"
            },
            {
              "id": "b1e0f0b6-79a1-4e3f-b20f-a5848ac91a83",
              "name": "url",
              "value": "={{ $('SplitMarkdown').item.json.metadata.url }}",
              "type": "string"
            },
            {
              "id": "4cb9a89b-37f8-455a-9033-0a05f19d965b",
              "name": "text",
              "value": "={{ $json.text }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4040,
        -860
      ],
      "id": "d27976c6-7652-49c5-9a3b-b9ff64405eb7",
      "name": "Edit Fields5"
    },
    {
      "parameters": {
        "aggregate": "aggregateAllItemData",
        "options": {}
      },
      "type": "n8n-nodes-base.aggregate",
      "typeVersion": 1,
      "position": [
        4240,
        -860
      ],
      "id": "8ce5cef1-72d6-41a0-a2d4-4f5eaf5042ed",
      "name": "Aggregate1"
    },
    {
      "parameters": {
        "jsCode": "// Method 1: Using JSON.parse() (Recommended)\nconst inputItems = $input.all(); // Fetches all input items\n\nconsole.log(inputItems);\n\n// Method 1: Using JSON.parse() (Recommended)\nconst myArray = JSON.parse(inputItems[0].json.urls);\nconsole.log(myArray); // Output: [\"apple\", \"banana\", \"cherry\"]\nconsole.log(typeof myArray); // Output: \"object\" (which is correct for an array)\n\nreturn [{ json: { urls: myArray } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1980,
        -400
      ],
      "id": "ddfea027-9d2e-4014-b1f2-231111c69891",
      "name": "Code"
    },
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            {
              "name": "urls",
              "type": "any"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        1740,
        -400
      ],
      "id": "cd22b379-36a7-44dc-ae4c-6d8f0b88f420",
      "name": "Start"
    },
    {
      "parameters": {
        "fieldToSplitOut": "data",
        "options": {}
      },
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [
        3420,
        -860
      ],
      "id": "b3100d66-a5b1-4b2a-9905-3cc75ab548b8",
      "name": "SplitMarkdown"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.markdown }}",
        "messages": {
          "messageValues": [
            {
              "message": "Summarize the content into one concise and short paragraph"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        3660,
        -860
      ],
      "id": "3bd93501-39f5-44c6-b9c3-7aaeb647d502",
      "name": "Basic LLM Chain"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.0-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        3680,
        -660
      ],
      "id": "97c72cf8-0b95-4fca-a398-3cd767dfa910",
      "name": "Google Gemini Chat Model3",
      "credentials": {
        "googlePalmApi": {
          "id": "flZ3VabFlV6wrHU6",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "name": "Content_Extractor_Tool",
        "description": "Content Extractor Tool. Get markdown texts content from a URL by scraping the website. The input is an array of various URLs that need extraction.\n\n##Example Input\n[\"https://www.cnn.com\", \"https://www.example.com\"]",
        "workflowId": {
          "__rl": true,
          "value": "HsWXhVky3D0fzY36",
          "mode": "id"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "urls": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('urls', `Array of URLs`, 'string') }}"
          },
          "matchingColumns": [
            "urls"
          ],
          "schema": [
            {
              "id": "urls",
              "displayName": "urls",
              "required": false,
              "defaultMatch": false,
              "display": true,
              "canBeUsedToMatch": true,
              "removed": false
            }
          ],
          "attemptToConvertTypes": false,
          "convertFieldsToString": false
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "typeVersion": 2,
      "position": [
        4740,
        220
      ],
      "id": "66454dd4-91d3-4798-acbc-c789de7643d8",
      "name": "Call n8n Workflow Tool1"
    },
    {
      "parameters": {
        "jsonSchemaExample": "[\n\n      {\n        \"AreaForImprovement\": \"Reduce leading questions\",\n        \"SearchQuery\": \"Best practices for reducing leading questions in customer interviews\"\n      },\n      {\n        \"AreaForImprovement\": \"Dig deeper into emotional cues\",\n        \"SearchQuery\": \"how to recognize emotional cues while conducting user interviews research\"\n     \n  }\n]"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        3440,
        220
      ],
      "id": "9d22d928-38e4-42cb-bc6a-a5ef7adf092f",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.0-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        3220,
        220
      ],
      "id": "917d531c-74a5-4453-8f69-2e77f2c5fa8a",
      "name": "Google Gemini Chat Model5",
      "credentials": {
        "googlePalmApi": {
          "id": "flZ3VabFlV6wrHU6",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "fieldToSplitOut": "output",
        "options": {}
      },
      "type": "n8n-nodes-base.splitOut",
      "typeVersion": 1,
      "position": [
        3580,
        0
      ],
      "id": "2f2c7c27-e67a-4876-a85f-0fd4cfb4158f",
      "name": "Split Out2"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "4aab98c1-3fa7-4f69-99b0-a3c12ac23918",
              "name": "organic_results",
              "value": "={{ $json.organic_results }}",
              "type": "array"
            },
            {
              "id": "6d05e89c-bf5f-4b87-ad44-e6523f6123d2",
              "name": "AreaForImprovement",
              "value": "={{ $('Split Out2').item.json.AreaForImprovement }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4040,
        0
      ],
      "id": "6bbc4a11-19e6-4142-9c3f-8ce9d195c51a",
      "name": "Edit Fields2"
    },
    {
      "parameters": {
        "aggregate": "aggregateAllItemData",
        "options": {}
      },
      "type": "n8n-nodes-base.aggregate",
      "typeVersion": 1,
      "position": [
        4260,
        0
      ],
      "id": "8d0e88d8-3e65-4b75-9f99-eab5c952fa5e",
      "name": "Aggregate"
    },
    {
      "parameters": {
        "model": "claude-3-5-sonnet-20241022",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.2,
      "position": [
        4440,
        260
      ],
      "id": "b521417e-1dc2-4b7a-922e-7382b619bd21",
      "name": "Anthropic Chat Model1",
      "credentials": {
        "anthropicApi": {
          "id": "yD7a7X4b0kV9PiXh",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<transcript>\n{{ $('Supabase').item.json.final_text }}\n</transcript>",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "=You are a product researcher analyzing customer interview transcripts. Your task is to determine if a physical or digital prototype was shown to the interviewee during the interview. Respond with a JSON object containing the following keys:\n\n*   `prototype_shown`: A boolean value (true or false) indicating whether a prototype was shown.\n*   `rationale`: A concise explanation supporting your decision. Include specific quotes or references from the transcript that led you to your conclusion. If no prototype was shown, explain why you believe that to be the case.  If the transcript is unclear, explain what further information would be needed to make a determination.\n\n**Definition of a Prototype:** For the purposes of this analysis, a prototype is defined as a tangible or interactive representation of a product or feature, intended to elicit feedback. This includes:\n\n*   Functional prototypes (working models)\n*   Non-functional prototypes (mockups, physical representations)\n*   Interactive digital prototypes (clickable demos, simulations)\n\n**Examples of Prototypes:**  A physical 3D printed model, a paper mockup, a Figma prototype, a coded demo, a Wizard-of-Oz prototype.\n\n**Definition of NOT a Prototype:** The following do *not* qualify as prototypes:\n\n*   Storyboards\n*   Sketches (unless presented as a physical mockup)\n*   Screensharing of productivity or collaboration apps (Google Docs, Miro, Figjam, etc.) to demonstrate stimulus, such as card sorting.  Note: Sharing a *prototype* within these tools is acceptable, but simply using the tools for other purposes is not.\n*   Purely conceptual discussions\n*   Static images or slide decks\n*   Recordings of previous user sessions\n\n**Important Considerations:**\n\n*   **Context is key:**  Pay close attention to the language used in the transcript.  Look for words like \"prototype,\" \"mockup,\" \"demo,\" \"interactive,\" \"clickable,\" \"physical model,\" etc.  However, the absence of these words doesn't necessarily mean a prototype wasn't shown.  Consider the overall description of what was shown to the participant.\n*   **Clarity:** If the transcript is ambiguous, explain what additional information is needed to make a definitive determination.  For example, \"The transcript mentions 'a visual,' but it's unclear whether this was a static image or an interactive prototype.  More context is needed.\"\n*   **Conciseness:** Keep the `rationale` concise and to the point. Focus on the most relevant evidence from the transcript.\n"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        1220,
        0
      ],
      "id": "9a052ebf-3426-4cdc-a9e6-c5c73b49407e",
      "name": "Basic LLM Chain2"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n\t\"prototype_shown\": true,\n\t\"rationale\": \"When talking to the customer, a software application was shown at 20:45 in the transcript and the interviewer demoed a variety of features including onboarding and reports\"\n}"
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.2,
      "position": [
        1400,
        220
      ],
      "id": "99fa5984-1521-4a0c-9fd7-83385e86e94a",
      "name": "Structured Output Parser1"
    },
    {
      "parameters": {
        "modelName": "models/gemini-2.0-flash",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "typeVersion": 1,
      "position": [
        1220,
        220
      ],
      "id": "f369bbba-e6ac-4408-9470-c6c3f9451e37",
      "name": "Google Gemini Chat Model7",
      "credentials": {
        "googlePalmApi": {
          "id": "flZ3VabFlV6wrHU6",
          "name": "Google Gemini(PaLM) Api account"
        }
      }
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "leftValue": "={{ $json.output.prototype_shown }}",
                    "rightValue": "",
                    "operator": {
                      "type": "boolean",
                      "operation": "true",
                      "singleValue": true
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "prototype_shown"
            },
            {
              "conditions": {
                "options": {
                  "caseSensitive": true,
                  "leftValue": "",
                  "typeValidation": "strict",
                  "version": 2
                },
                "conditions": [
                  {
                    "id": "6e528ca1-8f07-4144-9636-d3719606b299",
                    "leftValue": "={{ $json.output.prototype_shown }}",
                    "rightValue": "",
                    "operator": {
                      "type": "boolean",
                      "operation": "false",
                      "singleValue": true
                    }
                  }
                ],
                "combinator": "and"
              },
              "renameOutput": true,
              "outputKey": "discovery_only"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.switch",
      "typeVersion": 3.2,
      "position": [
        1660,
        0
      ],
      "id": "b69a9d99-1749-4f1d-aa82-d8327ea0dea1",
      "name": "Switch1"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "7284827d-48fc-4314-98a5-42275fb3c9c5",
              "name": "rubric",
              "value": "=# Rubric for User Interview Evaluation\n\n**Instructions:** Evaluate the user interview based on the following categories. The final score (1-10) is a holistic judgment, *not* a simple average. Use the following scale when determining the value of the holistic judgement, with 1 being the most important and 5 being the least important. If the user uses a significant number of leading questions and does not do a good job uncovering needs and motifications, this should not allow a total score of higher than 6.\n\n##Weighted Scale for Final Scoring\n*Establishing Rapport: 5 (least imporant)\n*Uncovering Needs and Motivations: 1 (most important)\n*Active Listening: 3\n*Guiding the Conversation: 4\n*Use of Leading Questions: 2 (very important)\n\n| Category | Amazing (10) | Excellent (9) | Great (8) | Good (7) | Fair (6) | Poor (5) | Very Poor (3-4) | Terrible (1-2) |\n|---|---|---|---|---|---|---|---|---|\n| **Establishing Rapport** | Creates an *immediate* and deep connection, fostering *exceptional* trust and *profound* exploration.  Interviewee feels genuinely understood and valued. | Establishes a strong and *warm* rapport, encouraging open and *detailed* communication.  Creates a highly comfortable and safe space. | Builds a positive rapport, creating a comfortable and safe space for sharing.  Demonstrates genuine interest and empathy. | Establishes a *consistently* good rapport, allowing for a comfortable and open conversation.  Listens attentively and responds thoughtfully, demonstrating clear understanding.  *May occasionally miss opportunities for deeper connection.* | Creates a satisfactory rapport, but misses opportunities to deepen the connection or build stronger trust.  Conversation may feel slightly surface-level at times. | Struggles to establish rapport; interviewee appears somewhat uncomfortable or hesitant. | Fails to establish rapport; interviewee appears uneasy and reluctant to share. | Interviewee appears highly uncomfortable, or the interviewer is inappropriate. |\n| **Uncovering Needs & Motivations (JTBD, Laddering, 5-Whys)** | *Masterfully* uncovers *all* relevant job dimensions (functional, emotional, social, related, consumption chain), demonstrating a *deep* understanding of JTBD. *Skillfully* uses laddering and 5-Whys (or other advanced techniques) to reveal *nuanced* insights and *unconscious* motivations. | *Effectively* uncovers *most* relevant job dimensions, demonstrating a strong understanding of JTBD.  Uses laddering and 5-Whys to uncover *key* motivations and needs. | Identifies *core* functional job, desired outcomes, and *several* related/emotional/social jobs. Shows good understanding and *effective application* of JTBD, laddering, and 5-Whys. | Uncovers the *core* functional job and *key* desired outcomes, and explores *some* related/emotional jobs.  Demonstrates a solid understanding of JTBD, laddering, and 5-Whys, but application may have *occasional inconsistencies or miss some nuances*. | Identifies core functional job and *some* desired outcomes, but misses key areas or deeper motivations. Limited use of laddering/5-Whys. | Struggles to identify the core functional job and desired outcomes. Shows limited understanding of the techniques. | Fails to uncover core job or outcomes. Demonstrates a lack of understanding of the frameworks. | Questions are confusing/irrelevant, or interviewer's behavior is inappropriate. |\n| **Active Listening** | Demonstrates *exceptional* active listening, deeply understanding and *subtly* reflecting perspectives, emotions, and *unspoken* needs. *Seamlessly* paraphrases and summarizes, demonstrating complete comprehension. | Listens attentively and reflects responses, demonstrating *clear* and *thoughtful* understanding.  Paraphrases and summarizes effectively. | Actively listens and responds thoughtfully, showing *genuine* empathy and understanding.  Good paraphrasing/summarizing. | Listens carefully and responds appropriately, demonstrating engagement.  Paraphrasing/summarizing is generally good, but *may occasionally miss subtle cues or nuances*. | Listens and responds, but misses opportunities for deeper reflection or nuanced paraphrasing. | Appears somewhat disengaged, with inconsistent listening and limited reflection. | Struggles to listen actively, interrupting frequently or dominating the conversation. | Fails to listen actively, showing disinterest or interrupting inappropriately. |\n| **Guiding the Conversation** | *Masterfully* guides the conversation, creating a *natural* and *engaging* flow while ensuring *comprehensive* exploration of all key areas. Uses *insightful* open-ended questions and *subtle* follow-ups. | *Skillfully* guides the conversation, maintaining focus while allowing for natural tangents and deeper dives. Uses open-ended questions *effectively* and adapts to the interviewee's responses. | *Effectively* guides the conversation, ensuring all key areas are covered in a logical order. Good use of open-ended questions and appropriate follow-ups. | Maintains good control of the conversation, covering key topics. Uses open-ended questions and generally appropriate follow-ups.  *May occasionally allow for minor, unproductive tangents or miss opportunities to probe deeper.* | Guides the conversation satisfactorily, but misses some opportunities for deeper exploration or allows for minor, unproductive tangents. Open-ended question use is inconsistent. | Struggles to maintain control; conversation is somewhat disjointed or unfocused. Limited use of open-ended questions or follow-ups. | Fails to guide the conversation effectively; becomes rambling and unproductive. Few open-ended questions or relevant follow-ups. | Attempts to guide are clumsy/inappropriate, or complete loss of control. |\n| **Use of Leading Questions** | Avoids leading questions *entirely*, allowing the interviewee to drive the narrative and reveal unbiased insights. Asks *only* clarifying questions without *any* influence on responses. |  Rarely uses leading questions, and when used, they are carefully phrased to minimize bias.  Focuses *primarily* on open-ended exploration and neutral follow-ups. |  Minimizes leading questions, primarily using open-ended and neutral clarifying questions.  Occasionally uses neutral prompts to clarify or redirect without influencing the response. |  Uses a mix of open-ended and neutral clarifying questions.  Leading questions are present but don't *significantly* skew responses.  Aware of potential bias. *May occasionally use leading questions that subtly influence responses.* |  Uses some leading questions, which may subtly influence interviewee responses.  Could benefit from more open-ended and neutral questions. |  Relies *somewhat* on leading questions, which may shape interviewee responses and potentially bias insights.  Needs to focus on open-ended questioning. |  Relies *heavily* on leading questions, significantly shaping interviewee responses and potentially biasing insights.  Overuse of leading questions. |  Overuses leading questions, effectively putting words in the interviewee's mouth and invalidating the data.  Leading questions are aggressive or manipulative. |\n",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1960,
        120
      ],
      "id": "dafaeae7-1585-4128-9c9a-483963caddc2",
      "name": "Edit Fields3"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "7284827d-48fc-4314-98a5-42275fb3c9c5",
              "name": "rubric",
              "value": "=# Rubric for User Interview Evaluation\n\n**Instructions:** Evaluate the user interview based on the following categories. The final score (1-10) is a holistic judgment, *not* a simple average. Use the following scale when determining the value of the holistic judgement, with 1 being the most important and 5 being the least important. If the user uses a significant number of leading questions and does not do a good job uncovering needs and motifications, this should not allow a total score of higher than 6.\n\n##Weighted Scale for Final Scoring\n*Establishing Rapport: 5 (least imporant)\n*Uncovering Needs and Motivations: 1 (extremely important)\n*Active Listening: 3\n*Guiding the Conversation: 4\n*Use of Leading Questions: 1 (extremely important)\n*Learns about solution space: 4\n\n| Category | Amazing (10) | Excellent (9) | Great (8) | Good (7) | Fair (6) | Poor (5) | Very Poor (3-4) | Terrible (1-2) |\n|---|---|---|---|---|---|---|---|---|\n| **Establishing Rapport** | Creates an immediate and deep connection, fostering openness and trust. | Establishes a strong and warm rapport, encouraging comfort. | Builds a positive rapport, creating a comfortable environment. | Establishes a consistently good rapport, allowing for open dialogue. | Creates a satisfactory rapport, but misses opportunities for depth. | Struggles to establish rapport; interviewee appears hesitant. | Fails to establish rapport; interviewee appears uncomfortable or detached. | Interviewee appears highly uncomfortable, or the interview is adversarial. |\n| **Uncovering Needs & Motivations (JTBD, Laddering)** | Masterfully uncovers all relevant job dimensions and motivations. | Effectively uncovers most relevant job dimensions and motivations. | Identifies core functional job, desired outcomes, and motivations. | Uncovers the core functional job and key desired outcomes. | Identifies core functional job and some desired outcomes, but lacks depth. | Struggles to identify the core functional job and key outcomes. | Fails to uncover core job or outcomes. Demonstrates limited understanding. | Questions are confusing/irrelevant, or interviewee does not engage. |\n| **Active Listening** | Demonstrates exceptional active listening, deeply engaging in responses. | Listens attentively and reflects responses, demonstrating understanding. | Actively listens and responds thoughtfully, showing comprehension. | Listens carefully and responds appropriately, with occasional lapses. | Listens and responds, but misses opportunities for deeper engagement. | Appears somewhat disengaged, with inconsistent responses. | Struggles to listen actively, interrupting frequently or appearing inattentive. | Fails to listen actively, showing disinterest or frequent interruptions. |\n| **Guiding the Conversation** | Masterfully guides the conversation, creating a seamless flow. | Skillfully guides the conversation, maintaining structure. | Effectively guides the conversation, ensuring smooth transitions. | Maintains good control of the conversation, covering key points. | Guides the conversation satisfactorily, but misses opportunities for depth. | Struggles to maintain control; conversation is disorganized. | Fails to guide the conversation effectively; becomes disjointed. | Attempts to guide are clumsy/inappropriate, or conversation derails. |\n| **Use of Leading Questions** | Avoids leading questions entirely, allowing the interviewee to express freely. | Rarely uses leading questions, and when used, they are neutral. | Minimizes leading questions, primarily using open-ended inquiries. | Uses a mix of open-ended and neutral clarifying questions. | Uses some leading questions, which may subtly influence responses. | Relies somewhat on leading questions, which may affect authenticity. | Relies heavily on leading questions, significantly shaping responses. | Overuses leading questions, effectively putting words into interviewee’s mouth. |\n| **Learns About Solution Space** | Thoroughly explores the solution space, gaining deep insights into user behaviors and needs. | Effectively explores the solution space, uncovering valuable insights. | Understands key aspects of the solution space, engaging meaningfully. | Gains a general understanding of the solution space, but lacks depth. | Explores the solution space superficially, missing key details. | Struggles to engage with the solution space meaningfully. | Shows little to no interest in the solution space, failing to gain insights. | Completely ignores the solution space, missing all relevant insights. |\n\n",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1960,
        -100
      ],
      "id": "60f0cd9c-db4b-411f-8585-e108cf8b7678",
      "name": "Edit Fields6"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=Come up with relevant Google search queries for the following areas of improvement. Each area to research is separated by a comma:\n\n<areas_for_improvement>\n{{ $('Extract structured data').item.json.output.areas_for_improvement }}\n</areas_for_improvement>",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "=You are a **research assistant** tasked with finding high-quality learning resources for a student looking to improve their **customer interview techniques** in product development. Your task is to come up with a Google Search query to obtain **the most relevant resources** for each \"Area For Improvement\" that is provided.\n"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        3240,
        0
      ],
      "id": "b379511f-0253-4b0a-9605-9f59a8cd6de8",
      "name": "Google Query Generator"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=<areas_for_improvement>\n{{ $('Extract structured data').item.json.output.areas_for_improvement }}\n</areas_for_improvement>\n<search_results>\n{{ $json.data.toJsonString() }}\n</search_results>",
        "options": {
          "systemMessage": "=You are a **research assistant** tasked with providing high-quality learning resources for a student looking to improve their **customer interview techniques** in product development. Your role is to find and summarize **the most relevant resources** for each \"Area For Improvement\" that is provided.\n\n## **Instructions**\n### **1️⃣ Identify and Select High-Quality Resources**\n- **Use the provided search_results** to find at least **three** high-quality URLs per \"Area For Improvement\"\n- Prioritize well-regarded sources (e.g., **research-backed articles, expert blogs, educational resources**).\n- **Do not recommend** URLs that are behind a paywall (e.g., LinkedIn, subscription-based sites).\n- **Ensure each URL is distinct** (no duplicates) and **skip low-quality sources** if needed.\n- **Do not recommend** URLs that link to PDFs or non HTML/native web content\n\n### **2️⃣ Batch Summarization of Selected URLs**\n- **Only send URLs you are recommending** to the Content Extractor tool, not every URL provided by the search_results.\n- **Submit all URLs in a single batch request.**  \n  ❌ **Incorrect:** Sending multiple requests for different URLs.  \n  ✅ **Correct:** Collect all URLs first, then send them in one request.\n- Each summary should be **concise (3-4 sentences)** and highlight **key actionable insights**.\n\n### **3️⃣ Present Findings in Markdown Format**\n- **Begin with a quick summary** of the user's areas for improvement. There is no need for any preamble or explanation before providing the output.\n- Group the findings by category, listing each **URL** with a **brief summary**.\n- Follow the structured example below.\n\n---\n\n## **Example Output** (Replace placeholders with actual results):\n\n### **Areas for Improvement**\n1) *Lack of probing for underlying motivations.* For example, at 4:44, the interviewer doesn’t explore why the interviewee chose accounting beyond “versatility.”\n2) *Use of leading questions when introducing the prototype.* For example, at 25:11, the interviewer frames the app as a tool to \"alleviate some of the confusion [and] frustration and help build confidence.\"\n3) *Not effectively using silence to encourage more detailed responses.* Throughout the interview, the interviewer often jumps in with another question immediately after the interviewee finishes speaking.\n\n### **Formulating Effective Interview Questions**\n- [https://www.example.com/question1](https://www.example.com/question1)  \n  *This article explains how open-ended questions lead to richer insights. It includes practical phrasing techniques and examples to help avoid leading questions.*\n- [https://www.example.com/question2](https://www.example.com/question2)  \n  *This resource explores advanced questioning techniques like the “5 Whys” method to uncover deeper customer needs.*\n- [https://www.example.com/question3](https://www.example.com/question3)  \n  *A framework for structuring interview questions based on research goals, with downloadable templates.*\n\n### **Building Rapport with Interviewees**\n- [https://www.example.com/rapport1](https://www.example.com/rapport1)  \n  *Strategies for creating a comfortable interview environment, emphasizing active listening and trust-building.*\n- [https://www.example.com/rapport2](https://www.example.com/rapport2)  \n  *Tips for adapting communication styles and using nonverbal cues to enhance rapport.*\n- [https://www.example.com/rapport3](https://www.example.com/rapport3)  \n  *A discussion on ethical considerations in customer interviews, including informed consent guidelines.*\n\n---\n\n## **Tool Usage Guidelines**\n### **Content Extractor Tool (Summarization)**\n- **Only summarize URLs you are recommending**, not every URL retrieved.\n- **Batch all selected URLs into one request.**  \n  - If there are 4 areas of improvement, each with 3 URLs, send **one request with 12 URLs** (not 4 separate requests).\n- Ensure **each summary is unique, clear, and actionable**.\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [
        4500,
        0
      ],
      "id": "feaca0b5-df96-4502-aff3-1a14766e0ce2",
      "name": "Deep Researcher",
      "retryOnFail": true,
      "maxTries": 2
    },
    {
      "parameters": {
        "url": "https://serpapi.com/search",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "q",
              "value": "={{ $json.SearchQuery }}"
            },
            {
              "name": "api_key",
              "value": "93b06fbc144ef03f95cb2d2150c850783d6fffad66157abb12e2f69456ad4300"
            },
            {
              "name": "device",
              "value": "desktop"
            },
            {
              "name": "location",
              "value": "Chicago, IL, United States"
            },
            {
              "name": "hl",
              "value": "en"
            },
            {
              "name": "gl",
              "value": "us"
            }
          ]
        },
        "options": {
          "batching": {
            "batch": {
              "batchSize": 5
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        3800,
        0
      ],
      "id": "cbb8606b-bf2e-4c51-af3a-defbe3cea871",
      "name": "Google Search"
    }
  ],
  "pinData": {
    "Start": [
      {
        "json": {
          "urls": "[\"https://maze.co/blog/leading-questions/\",\"https://www.indeed.com/career-advice/interviewing/leading-questions-in-interview-examples\"]"
        }
      }
    ],
    "Webhook": [
      {
        "json": {
          "headers": {
            "host": "jrenaldi.app.n8n.cloud",
            "user-agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36",
            "content-length": "124",
            "accept": "application/json",
            "accept-encoding": "gzip, br",
            "accept-language": "en-US,en;q=0.9",
            "cdn-loop": "cloudflare; loops=1; subreqs=1",
            "cf-connecting-ip": "2600:1700:1fd8:1ebf:9cd2:966b:9709:6f71",
            "cf-ew-via": "15",
            "cf-ipcountry": "US",
            "cf-ray": "914898cd3531e812-ORD",
            "cf-visitor": "{\"scheme\":\"https\"}",
            "cf-worker": "n8n.cloud",
            "content-type": "application/json",
            "origin": "https://prestoai.netlify.app",
            "priority": "u=1, i",
            "referer": "https://prestoai.netlify.app/",
            "sec-ch-ua": "\"Not(A:Brand\";v=\"99\", \"Google Chrome\";v=\"133\", \"Chromium\";v=\"133\"",
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": "\"macOS\"",
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "cross-site",
            "x-forwarded-for": "2600:1700:1fd8:1ebf:9cd2:966b:9709:6f71, 172.71.255.44",
            "x-forwarded-host": "jrenaldi.app.n8n.cloud",
            "x-forwarded-port": "443",
            "x-forwarded-proto": "https",
            "x-forwarded-server": "traefik-prod-users-gwc-6-58b64db885-7d8sz",
            "x-is-trusted": "yes",
            "x-real-ip": "2600:1700:1fd8:1ebf:9cd2:966b:9709:6f71"
          },
          "params": {},
          "query": {},
          "body": {
            "transcription_id": "a2dd4068-b2b8-42ec-ae40-4f538858f60c",
            "user_id": "80591056-8902-42e9-a590-f199c225c628",
            "agent": "coach"
          },
          "webhookUrl": "https://jrenaldi.app.n8n.cloud/webhook/15771f84-de31-4984-89fb-ec166b38568c",
          "executionMode": "production"
        }
      }
    ]
  },
  "connections": {
    "Load Laddering Technique": {
      "main": [
        [
          {
            "node": "Load Interviewing Users",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Load Interviewing Users": {
      "main": [
        [
          {
            "node": "Load JTBD",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Load JTBD": {
      "main": [
        [
          {
            "node": "Basic LLM Chain2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Interview Coach",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Load Sample Questions": {
      "main": [
        [
          {
            "node": "Load Laddering Technique",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Extract structured data",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Supabase": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "Supabase",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Supabase1": {
      "main": [
        [
          {
            "node": "Google Query Generator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Supabase2": {
      "main": [
        [
          {
            "node": "Edit Fields1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Load Sample Questions",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Interview Summarizer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Interview Summarizer",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Supabase3": {
      "main": [
        [
          {
            "node": "Quote Extractor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Interview Coach": {
      "main": [
        [
          {
            "node": "Extract structured data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model4": {
      "ai_languageModel": [
        [
          {
            "node": "Create a title",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model6": {
      "ai_languageModel": [
        [
          {
            "node": "Quote Extractor",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Quote Extractor": {
      "main": [
        [
          {
            "node": "Split Out",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Supabase4": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Out": {
      "main": [
        [
          {
            "node": "Supabase4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Interview Summarizer": {
      "main": [
        [
          {
            "node": "Create a title",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create a title": {
      "main": [
        [
          {
            "node": "Supabase3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract structured data": {
      "main": [
        [
          {
            "node": "Supabase1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request2": {
      "main": [
        [
          {
            "node": "Edit Fields4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields4": {
      "main": [
        []
      ]
    },
    "Summarize": {
      "main": [
        [
          {
            "node": "If1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If1": {
      "main": [
        [
          {
            "node": "HTTP Request",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "HTTP Request2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Out1": {
      "main": [
        [
          {
            "node": "Summarize",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request": {
      "main": [
        [
          {
            "node": "HTTP Request3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Request3": {
      "main": [
        [
          {
            "node": "Switch",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch": {
      "main": [
        [
          {
            "node": "SplitMarkdown",
            "type": "main",
            "index": 0
          }
        ],
        [],
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "HTTP Request3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields5": {
      "main": [
        [
          {
            "node": "Aggregate1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Code": {
      "main": [
        [
          {
            "node": "Split Out1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Start": {
      "main": [
        [
          {
            "node": "Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SplitMarkdown": {
      "main": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model3": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain": {
      "main": [
        [
          {
            "node": "Edit Fields5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call n8n Workflow Tool1": {
      "ai_tool": [
        [
          {
            "node": "Deep Researcher",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Google Query Generator",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model5": {
      "ai_languageModel": [
        [
          {
            "node": "Google Query Generator",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Split Out2": {
      "main": [
        [
          {
            "node": "Google Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields2": {
      "main": [
        [
          {
            "node": "Aggregate",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate": {
      "main": [
        [
          {
            "node": "Deep Researcher",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Anthropic Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Deep Researcher",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain2": {
      "main": [
        [
          {
            "node": "Switch1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser1": {
      "ai_outputParser": [
        [
          {
            "node": "Basic LLM Chain2",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Google Gemini Chat Model7": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Switch1": {
      "main": [
        [
          {
            "node": "Edit Fields6",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Edit Fields3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields6": {
      "main": [
        [
          {
            "node": "Interview Coach",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields3": {
      "main": [
        [
          {
            "node": "Interview Coach",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Query Generator": {
      "main": [
        [
          {
            "node": "Split Out2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Deep Researcher": {
      "main": [
        [
          {
            "node": "Supabase2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Search": {
      "main": [
        [
          {
            "node": "Edit Fields2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "3910395c-9eda-4fbf-b7ef-81a371e01bba",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "417d01568d9442a381ed5a25872e7ff95f9968a65187a65045ed8e625988b26f"
  },
  "id": "HsWXhVky3D0fzY36",
  "tags": []
}